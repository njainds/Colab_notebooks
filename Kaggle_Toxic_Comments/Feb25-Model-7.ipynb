{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments/Feb25-Model-7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oYZkU7ZN3CL0",
        "outputId": "407ff638-1af8-4e33-ad8b-3982f3bc6fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BAFlm8xPHpyc",
        "colab_type": "code",
        "outputId": "9e1a51ae-f90f-4957-9bb6-ad1958ec5d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext import data\n",
        "import spacy\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "import zipfile\n",
        "import gzip\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "from nltk import word_tokenize\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D, Conv2D, Input, SpatialDropout1D, Embedding, Dense, Activation, Bidirectional, LSTM,CuDNNLSTM, CuDNNGRU, GlobalMaxPooling1D,GlobalAveragePooling1D, concatenate, Dropout\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.models import Model\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.engine import Layer\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.model_selection import StratifiedKFold,KFold\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from unidecode import unidecode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "D-lZ41oqDYTC",
        "colab_type": "code",
        "outputId": "322a394f-5dcd-46bf-9409-c13bf4477081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/kaggle_toxic_comments\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "best_model.hdf5\t\t\t   test.csv\n",
            "ext_fasttextwiki_embeddings.npy    test_features.npy\n",
            "ext_glove_embeddings.npy\t   test_labels.csv\n",
            "ext_lexvec_embeddings.npy\t   toxic_lookup_en_wiki_fasttext_300d.npy\n",
            "features.npy\t\t\t   train.csv\n",
            "inputed_lexvec_embeddings.npy\t   word_index.npy\n",
            "local_fasttextwiki_embeddings.npy  x_test.npy\n",
            "Model-runs\t\t\t   x_train.npy\n",
            "sample_submission.csv\t\t   y_train.npy\n",
            "submission_baseline_lr.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ETSksPDYFps2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector) ##sum([word[1] for word in vocab[:120000]])=92%##\n",
        "maxlen = 250 # max number of words in a question to use ## train.num_words.quantile(q=0.96, interpolation='nearest')=258 ##\n",
        "batch_size = 512 # how many samples to process at once\n",
        "n_epochs = 5 # how many times to iterate over all samples\n",
        "n_splits = 5 # Number of K-fold Splits\n",
        "\n",
        "hidden_size = 60\n",
        "gru_len = hidden_size\n",
        "\n",
        "Routings = 4 \n",
        "Num_capsule = 5\n",
        "Dim_capsule = 5\n",
        "dropout_p = 0.25\n",
        "rate_drop_dense = 0.28\n",
        "LR = 0.001\n",
        "T_epsilon = 1e-7\n",
        "num_classes = 30\n",
        "\n",
        "SEED = 2019\n",
        "def seed_everything(seed=2019):\n",
        "    random.seed(seed)\n",
        "    \n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2hyLLFNIHoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/My Drive/kaggle_toxic_comments/\")\n",
        "x_train = np.load(\"x_train.npy\")\n",
        "x_test = np.load(\"x_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "features = np.load(\"features.npy\")\n",
        "test_features = np.load(\"test_features.npy\")\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "embedding_matrix = np.load(\"ext_lexvec_embeddings.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iq26bM0m4YGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4ac0656-5bcf-4446-97ec-740379efb2bd"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159571, 250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "8jwc1rMTeyDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train simple LSTM using different embeddings\n",
        "# Top compeitions- QIQC and Toxic comments\n",
        "# ensembles (stacking and blending)\n",
        "# Pretrained models- ULMFit and BERT\n",
        "# Gensim and fasttext text classification\n",
        "# Other SOTAs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wdi_9dQMkT2G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://www.kaggle.com/c/quora-insincere-questions-classification/kernels?sortBy=scoreDescending&group=everyone&pageSize=20&competitionId=10737\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxiqwQ77Tivr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "            \n",
        "#file_path = \"best_model.hdf5\"\n",
        "#check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "#ra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n",
        "#early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
        "#######################################################################################################################################################################################################\n",
        "class CyclicLR(object):\n",
        "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
        "                 step_size=2000, mode='triangular', gamma=1.,\n",
        "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
        "\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
        "            if len(base_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(base_lr)))\n",
        "            self.base_lrs = list(base_lr)\n",
        "        else:\n",
        "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
        "            if len(max_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(max_lr)))\n",
        "            self.max_lrs = list(max_lr)\n",
        "        else:\n",
        "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        self.step_size = step_size\n",
        "\n",
        "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
        "                and scale_fn is None:\n",
        "            raise ValueError('mode is invalid and scale_fn is None')\n",
        "\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "\n",
        "        if scale_fn is None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = self._triangular_scale_fn\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = self._triangular2_scale_fn\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = self._exp_range_scale_fn\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "\n",
        "        self.batch_step(last_batch_iteration + 1)\n",
        "        self.last_batch_iteration = last_batch_iteration\n",
        "\n",
        "    def batch_step(self, batch_iteration=None):\n",
        "        if batch_iteration is None:\n",
        "            batch_iteration = self.last_batch_iteration + 1\n",
        "        self.last_batch_iteration = batch_iteration\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    def _triangular_scale_fn(self, x):\n",
        "        return 1.\n",
        "\n",
        "    def _triangular2_scale_fn(self, x):\n",
        "        return 1 / (2. ** (x - 1))\n",
        "\n",
        "    def _exp_range_scale_fn(self, x):\n",
        "        return self.gamma**(x)\n",
        "\n",
        "    def get_lr(self):\n",
        "        step_size = float(self.step_size)\n",
        "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
        "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
        "\n",
        "        lrs = []\n",
        "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
        "        for param_group, base_lr, max_lr in param_lrs:\n",
        "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
        "            if self.scale_mode == 'cycle':\n",
        "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
        "            else:\n",
        "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
        "            lrs.append(lr)\n",
        "        return lrs\n",
        "#######################################################################################################################################################################################################\n",
        "\n",
        "class Caps_Layer(nn.Module):\n",
        "    def __init__(self, input_dim_capsule=gru_len * 2, num_capsule=Num_capsule, dim_capsule=Dim_capsule, \\\n",
        "                 routings=Routings, kernel_size=(9, 1), share_weights=True,\n",
        "                 activation='default', **kwargs):\n",
        "        super(Caps_Layer, self).__init__(**kwargs)\n",
        "\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.kernel_size = kernel_size  # \n",
        "        self.share_weights = share_weights\n",
        "        if activation == 'default':\n",
        "            self.activation = self.squash\n",
        "        else:\n",
        "            self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "        if self.share_weights:\n",
        "            self.W = nn.Parameter(\n",
        "                nn.init.xavier_normal_(t.empty(1, input_dim_capsule, self.num_capsule * self.dim_capsule)))\n",
        "        else:\n",
        "            self.W = nn.Parameter(\n",
        "                t.randn(BATCH_SIZE, input_dim_capsule, self.num_capsule * self.dim_capsule))  # 64即batch_size\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.share_weights:\n",
        "            u_hat_vecs = t.matmul(x, self.W)\n",
        "        else:\n",
        "            print('add later')\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        input_num_capsule = x.size(1)\n",
        "        u_hat_vecs = u_hat_vecs.view((batch_size, input_num_capsule,\n",
        "                                      self.num_capsule, self.dim_capsule))\n",
        "        u_hat_vecs = u_hat_vecs.permute(0, 2, 1, 3)  # 转成(batch_size,num_capsule,input_num_capsule,dim_capsule)\n",
        "        b = t.zeros_like(u_hat_vecs[:, :, :, 0])  # (batch_size,num_capsule,input_num_capsule)\n",
        "\n",
        "        for i in range(self.routings):\n",
        "            b = b.permute(0, 2, 1)\n",
        "            c = F.softmax(b, dim=2)\n",
        "            c = c.permute(0, 2, 1)\n",
        "            b = b.permute(0, 2, 1)\n",
        "            outputs = self.activation(t.einsum('bij,bijk->bik', (c, u_hat_vecs)))  # batch matrix multiplication\n",
        "            # outputs shape (batch_size, num_capsule, dim_capsule)\n",
        "            if i < self.routings - 1:\n",
        "                b = t.einsum('bik,bijk->bij', (outputs, u_hat_vecs))  # batch matrix multiplication\n",
        "        return outputs  # (batch_size, num_capsule, dim_capsule)\n",
        "\n",
        "    # text version of squash, slight different from original one\n",
        "    def squash(self, x, axis=-1):\n",
        "        s_squared_norm = (x ** 2).sum(axis, keepdim=True)\n",
        "        scale = t.sqrt(s_squared_norm + T_epsilon)\n",
        "        return x / scale\n",
        "#####################################################################################################################################################################################################      \n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.bias = bias\n",
        "        self.feature_dim = feature_dim\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        \n",
        "        weight = torch.zeros(feature_dim, 1)\n",
        "        nn.init.xavier_uniform_(weight)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        \n",
        "        if bias:\n",
        "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
        "        \n",
        "    def forward(self, x, mask=None):\n",
        "        feature_dim = self.feature_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = torch.mm(\n",
        "            x.contiguous().view(-1, feature_dim), \n",
        "            self.weight\n",
        "        ).view(-1, step_dim)\n",
        "        \n",
        "        if self.bias:\n",
        "            eij = eij + self.b\n",
        "            \n",
        "        eij = torch.tanh(eij)\n",
        "        a = torch.exp(eij)\n",
        "        \n",
        "        if mask is not None:\n",
        "            a = a * mask\n",
        "\n",
        "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
        "\n",
        "        weighted_input = x * torch.unsqueeze(a, -1)\n",
        "        return torch.sum(weighted_input, 1)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YEPJ623BlR17",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        \n",
        "        fc_layer = 16\n",
        "        fc_layer1 = 16\n",
        "\n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        \n",
        "        self.embedding_dropout = nn.Dropout2d(0.1)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.gru = nn.GRU(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.lstm2 = nn.LSTM(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.lstm_attention = Attention(hidden_size * 2, maxlen)\n",
        "        self.gru_attention = Attention(hidden_size * 2, maxlen)\n",
        "        self.bn = nn.BatchNorm1d(16, momentum=0.5)\n",
        "        self.linear = nn.Linear(hidden_size*8+5, fc_layer1) #643:80 - 483:60 - 323:40\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(fc_layer**2,fc_layer)\n",
        "        self.out = nn.Linear(fc_layer, 6)\n",
        "        self.lincaps = nn.Linear(Num_capsule * Dim_capsule, 1)\n",
        "        self.caps_layer = Caps_Layer()\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        h_embedding = self.embedding(x[0])\n",
        "        h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))\n",
        "        \n",
        "        h_lstm, _ = self.lstm(h_embedding)\n",
        "        h_gru, _ = self.gru(h_lstm)\n",
        "\n",
        "        ##Capsule Layer        \n",
        "        content3 = self.caps_layer(h_gru)\n",
        "        content3 = self.dropout(content3)\n",
        "        batch_size = content3.size(0)\n",
        "        content3 = content3.view(batch_size, -1)\n",
        "        content3 = self.relu(self.lincaps(content3))\n",
        "\n",
        "        ##Attention Layer\n",
        "        h_lstm_atten = self.lstm_attention(h_lstm)\n",
        "        h_gru_atten = self.gru_attention(h_gru)\n",
        "        \n",
        "        # global average pooling\n",
        "        avg_pool = torch.mean(h_gru, 1)\n",
        "        # global max pooling\n",
        "        max_pool, _ = torch.max(h_gru, 1)\n",
        "        \n",
        "        f = torch.tensor(x[1], dtype=torch.float).cuda()\n",
        "\n",
        "                #[512,160]\n",
        "        conc = torch.cat((h_lstm_atten, h_gru_atten,content3, avg_pool, max_pool,f), 1)\n",
        "        conc = self.relu(self.linear(conc))\n",
        "        conc = self.bn(conc)\n",
        "        conc = self.dropout(conc)\n",
        "\n",
        "        out = self.out(conc)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vAegUwOJ1Juw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self,dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data, target = self.dataset[index]\n",
        "\n",
        "        return data, target, index\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "   \n",
        "  \n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# matrix for the out-of-fold predictions\n",
        "train_preds = np.zeros(y_train.shape)\n",
        "# matrix for the predictions on the test set\n",
        "test_preds = np.zeros((x_test.shape[0],6))\n",
        "\n",
        "# always call this before training for deterministic results\n",
        "seed_everything()\n",
        "\n",
        "x_test_cuda = torch.tensor(x_test, dtype=torch.long).cuda()\n",
        "test = torch.utils.data.TensorDataset(x_test_cuda)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "avg_losses_f = []\n",
        "avg_val_losses_f = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mvLm6KfK-vAq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "splits = list(KFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(x_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ngNuKxFWn7Xp",
        "colab_type": "code",
        "outputId": "d5681a8e-6e22-4b91-f28c-852e2173989b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "cell_type": "code",
      "source": [
        "for i, (train_idx, valid_idx) in enumerate(splits):    \n",
        "\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "    features = np.array(features)\n",
        "    \n",
        "    x_train_fold = torch.tensor(x_train[train_idx.astype(int)], dtype=torch.long).cuda()\n",
        "    y_train_fold = torch.tensor(y_train[train_idx.astype(int)], dtype=torch.float32).cuda()\n",
        "    \n",
        "    kfold_X_features = features[train_idx.astype(int)]\n",
        "    kfold_X_valid_features = features[valid_idx.astype(int)]\n",
        "    x_val_fold = torch.tensor(x_train[valid_idx.astype(int)], dtype=torch.long).cuda()\n",
        "    y_val_fold = torch.tensor(y_train[valid_idx.astype(int)], dtype=torch.float32).cuda()\n",
        "    \n",
        "    train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
        "    valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
        "    \n",
        "    train = MyDataset(train)\n",
        "    valid = MyDataset(valid)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    model = NeuralNet()\n",
        "    model.cuda()\n",
        "    loss_fn = torch.nn.MultiLabelSoftMarginLoss(reduction='sum')\n",
        "\n",
        "    step_size = 623 #159571*0.8/512*(5/2)\n",
        "    base_lr, max_lr = 0.001, 0.003   \n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr=max_lr)\n",
        "    scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr,step_size=step_size, mode='exp_range', gamma=0.99994)\n",
        "\n",
        "    print(f'Fold {i + 1}')\n",
        "    for epoch in range(n_epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.  \n",
        "        for i, (x_batch, y_batch, index) in enumerate(train_loader):          \n",
        "            f = kfold_X_features[index]\n",
        "            y_pred = model([x_batch,f])\n",
        "            \n",
        "            if scheduler:\n",
        "                scheduler.batch_step()\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "            \n",
        "        model.eval()\n",
        "\n",
        "        valid_preds_fold = np.zeros(y_val_fold.size())\n",
        "        test_preds_fold = np.zeros((x_test.shape[0],6))\n",
        "        \n",
        "        avg_val_loss = 0.\n",
        "        for i, (x_batch, y_batch, index) in enumerate(valid_loader):\n",
        "            f = kfold_X_valid_features[index]\n",
        "            y_pred = model([x_batch,f]).detach()\n",
        "            \n",
        "            avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "            valid_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())\n",
        "        \n",
        "        elapsed_time = time.time() - start_time \n",
        "        val_auc = roc_auc_score(y_val_fold.cpu().numpy(),valid_preds_fold)\n",
        "        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t val_auc={:.4f} \\t time={:.2f}s'.format(epoch + 1, n_epochs, avg_loss, avg_val_loss, val_auc, elapsed_time))\n",
        "    avg_losses_f.append(avg_loss)\n",
        "    avg_val_losses_f.append(avg_val_loss) \n",
        "    # predict all samples in the test set batch per batch\n",
        "    for i, (x_batch,) in enumerate(test_loader):\n",
        "        f = test_features[i * batch_size:(i+1) * batch_size]\n",
        "        y_pred = model([x_batch,f]).detach()\n",
        "\n",
        "        test_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())\n",
        "        \n",
        "    train_preds[valid_idx] = valid_preds_fold\n",
        "    test_preds += test_preds_fold / len(splits)\n",
        "\n",
        "print('All \\t loss={:.4f} \\t val_loss={:.4f} \\t '.format(np.average(avg_losses_f),np.average(avg_val_losses_f)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Epoch 1/5 \t loss=185.3088 \t val_loss=49.2196 \t val_auc=0.9465 \t time=87.36s\n",
            "Epoch 2/5 \t loss=38.2932 \t val_loss=30.2078 \t val_auc=0.9746 \t time=86.90s\n",
            "Epoch 3/5 \t loss=30.4291 \t val_loss=24.3325 \t val_auc=0.9811 \t time=87.09s\n",
            "Epoch 4/5 \t loss=28.0305 \t val_loss=21.9305 \t val_auc=0.9846 \t time=86.99s\n",
            "Epoch 5/5 \t loss=26.4843 \t val_loss=21.9319 \t val_auc=0.9845 \t time=86.75s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 2\n",
            "Epoch 1/5 \t loss=197.5157 \t val_loss=47.7594 \t val_auc=0.9550 \t time=87.03s\n",
            "Epoch 2/5 \t loss=39.2967 \t val_loss=25.7504 \t val_auc=0.9638 \t time=87.20s\n",
            "Epoch 3/5 \t loss=30.6716 \t val_loss=23.2928 \t val_auc=0.9814 \t time=87.19s\n",
            "Epoch 4/5 \t loss=28.2971 \t val_loss=21.9444 \t val_auc=0.9837 \t time=86.98s\n",
            "Epoch 5/5 \t loss=26.9260 \t val_loss=22.8028 \t val_auc=0.9844 \t time=86.72s\n",
            "Fold 3\n",
            "Epoch 1/5 \t loss=191.8602 \t val_loss=48.2457 \t val_auc=0.9502 \t time=86.41s\n",
            "Epoch 2/5 \t loss=39.1700 \t val_loss=31.6645 \t val_auc=0.9679 \t time=86.63s\n",
            "Epoch 3/5 \t loss=29.9548 \t val_loss=22.9748 \t val_auc=0.9804 \t time=86.81s\n",
            "Epoch 4/5 \t loss=27.3652 \t val_loss=22.5392 \t val_auc=0.9823 \t time=87.06s\n",
            "Epoch 5/5 \t loss=25.9221 \t val_loss=21.3577 \t val_auc=0.9850 \t time=87.62s\n",
            "Fold 4\n",
            "Epoch 1/5 \t loss=203.6939 \t val_loss=48.8854 \t val_auc=0.9713 \t time=87.59s\n",
            "Epoch 2/5 \t loss=40.4306 \t val_loss=26.7721 \t val_auc=0.9742 \t time=87.35s\n",
            "Epoch 3/5 \t loss=31.2141 \t val_loss=26.3894 \t val_auc=0.9744 \t time=88.05s\n",
            "Epoch 4/5 \t loss=28.7867 \t val_loss=25.1228 \t val_auc=0.9819 \t time=87.34s\n",
            "Epoch 5/5 \t loss=27.2801 \t val_loss=24.2860 \t val_auc=0.9844 \t time=87.29s\n",
            "Fold 5\n",
            "Epoch 1/5 \t loss=199.2992 \t val_loss=52.0495 \t val_auc=0.9638 \t time=87.36s\n",
            "Epoch 2/5 \t loss=39.6219 \t val_loss=27.0141 \t val_auc=0.9717 \t time=87.64s\n",
            "Epoch 3/5 \t loss=30.7038 \t val_loss=25.0644 \t val_auc=0.9763 \t time=87.37s\n",
            "Epoch 4/5 \t loss=28.3922 \t val_loss=24.5623 \t val_auc=0.9822 \t time=87.55s\n",
            "Epoch 5/5 \t loss=26.4777 \t val_loss=25.7751 \t val_auc=0.9844 \t time=87.62s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All \t loss=26.6180 \t val_loss=23.2307 \t \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vep6bR7etg4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"./sample_submission.csv\")\n",
        "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = (test_preds)\n",
        "submission.to_csv(\"submission_model7_Mar3_auc_9844.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7c_QyY9ytW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}