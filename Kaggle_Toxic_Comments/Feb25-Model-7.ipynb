{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments_Feb23/Feb25-Model-7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oYZkU7ZN3CL0",
        "outputId": "73005f78-1dff-4d04-ef21-2ee308114699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BAFlm8xPHpyc",
        "colab_type": "code",
        "outputId": "e0c06667-9b6b-4ee0-ff17-d34888b7dd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "import torch\n",
        "from torchtext import data\n",
        "import spacy\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "import zipfile\n",
        "import gzip\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "from nltk import word_tokenize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D, Conv2D, Input, SpatialDropout1D, Embedding, Dense, Activation, Bidirectional, LSTM,CuDNNLSTM, CuDNNGRU, GlobalMaxPooling1D,GlobalAveragePooling1D, concatenate, Dropout\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.models import Model\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.engine import Layer\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from unidecode import unidecode"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "D-lZ41oqDYTC",
        "colab_type": "code",
        "outputId": "3ae6ac36-c56d-4c89-90e8-841ce32bf07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/kaggle_toxic_comments\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "best_model.hdf5\t\t\t   test.csv\n",
            "ext_fasttextwiki_embeddings.npy    test_features.npy\n",
            "ext_glove_embeddings.npy\t   test_labels.csv\n",
            "ext_lexvec_embeddings.npy\t   toxic_lookup_en_wiki_fasttext_300d.npy\n",
            "features.npy\t\t\t   train.csv\n",
            "inputed_lexvec_embeddings.npy\t   word_index.npy\n",
            "local_fasttextwiki_embeddings.npy  x_test.npy\n",
            "Model-runs\t\t\t   x_train.npy\n",
            "sample_submission.csv\t\t   y_train.npy\n",
            "submission_baseline_lr.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ETSksPDYFps2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector) ##sum([word[1] for word in vocab[:120000]])=92%##\n",
        "maxlen = 250 # max number of words in a question to use ## train.num_words.quantile(q=0.96, interpolation='nearest')=258 ##\n",
        "batch_size = 512 # how many samples to process at once\n",
        "n_epochs = 5 # how many times to iterate over all samples\n",
        "n_splits = 5 # Number of K-fold Splits\n",
        "\n",
        "SEED = 2019\n",
        "def seed_everything(seed=2019):\n",
        "    random.seed(seed)\n",
        "    \n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2hyLLFNIHoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/My Drive/kaggle_toxic_comments/\")\n",
        "x_train = np.load(\"x_train.npy\")\n",
        "x_test = np.load(\"x_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "features = np.load(\"features.npy\")\n",
        "test_features = np.load(\"test_features.npy\")\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "ext_lexvec_embeddings = np.load(\"ext_lexvec_embeddings.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jwc1rMTeyDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train simple LSTM using different embeddings\n",
        "# Top compeitions- QIQC and Toxic comments\n",
        "# ensembles (stacking and blending)\n",
        "# Pretrained models- ULMFit and BERT\n",
        "# Gensim and fasttext text classification\n",
        "# Other SOTAs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wdi_9dQMkT2G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://www.kaggle.com/c/quora-insincere-questions-classification/kernels?sortBy=scoreDescending&group=everyone&pageSize=20&competitionId=10737\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIUW0jz1Wh0F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxiqwQ77Tivr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "            \n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
        "\n",
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=4590., mode='triangular',gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):     \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v) \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YEPJ623BlR17",
        "colab_type": "code",
        "outputId": "1620d0c3-52a2-4599-d49e-ca673f98f90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(maxlen,))\n",
        "x   = Embedding(max_features, embed_size, weights=[ext_lexvec_embeddings], trainable=False)(inp)\n",
        "x   = SpatialDropout1D(rate=0.2)(x)\n",
        "x   = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n",
        "x   = Conv1D(64, kernel_size=1, padding='valid', kernel_initializer='glorot_normal')(x)\n",
        "x1  = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
        "x1   = Conv1D(64, kernel_size=1, padding='valid', kernel_initializer='glorot_normal')(x1)\n",
        "x_max   = GlobalMaxPooling1D()(x)\n",
        "x_avg   = GlobalAveragePooling1D()(x)\n",
        "x1_max  = GlobalMaxPooling1D()(x1)\n",
        "x1_avg  = GlobalAveragePooling1D()(x1)\n",
        "c   = concatenate([x_max,x_avg,x1_max,x1_avg])\n",
        "y   = Dense(64, activation='relu')(c)\n",
        "y   = Dropout(0.2)(y)\n",
        "out = Dense(6, activation='sigmoid')(y)\n",
        "model=Model(inputs=inp,outputs=out)\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 250)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 250, 300)     36000000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 250, 300)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 250, 256)     330240      spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 250, 64)      16448       bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 250, 256)     198656      conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 250, 64)      16448       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 64)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 64)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 64)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_average_pooling1d_1[0][0] \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_average_pooling1d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           16448       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            390         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 36,578,630\n",
            "Trainable params: 578,630\n",
            "Non-trainable params: 36,000,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vAegUwOJ1Juw",
        "colab_type": "code",
        "outputId": "17cb6e5a-c31a-4877-9a58-c45f9dfc5694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "cell_type": "code",
      "source": [
        "# for one cycle policy: step_size=(len(X_train)/batch_size)*n_ecpochs/2\n",
        "clr = CyclicLR(base_lr=1e-6, max_lr=1e-3,step_size=2805., mode='exp_range',gamma=0.99994)\n",
        "model.fit(X_train, Y_train, batch_size = 128, epochs = 5, validation_data = (X_valid, Y_valid), verbose = 1, callbacks = [clr, ra_val, check_point, early_stop])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/5\n",
            "143613/143613 [==============================] - 286s 2ms/step - loss: 0.0659 - acc: 0.9774 - val_loss: 0.0473 - val_acc: 0.9819\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.974741\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.04727, saving model to best_model.hdf5\n",
            "Epoch 2/5\n",
            "143613/143613 [==============================] - 284s 2ms/step - loss: 0.0496 - acc: 0.9816 - val_loss: 0.0453 - val_acc: 0.9826\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.979609\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.04727 to 0.04528, saving model to best_model.hdf5\n",
            "Epoch 3/5\n",
            "143613/143613 [==============================] - 284s 2ms/step - loss: 0.0460 - acc: 0.9824 - val_loss: 0.0424 - val_acc: 0.9832\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.985083\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.04528 to 0.04239, saving model to best_model.hdf5\n",
            "Epoch 4/5\n",
            "143613/143613 [==============================] - 284s 2ms/step - loss: 0.0431 - acc: 0.9831 - val_loss: 0.0404 - val_acc: 0.9841\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.987628\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.04239 to 0.04041, saving model to best_model.hdf5\n",
            "Epoch 5/5\n",
            "143613/143613 [==============================] - 284s 2ms/step - loss: 0.0413 - acc: 0.9837 - val_loss: 0.0403 - val_acc: 0.9841\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.988480\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.04041 to 0.04028, saving model to best_model.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f12b9495358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "ngNuKxFWn7Xp",
        "colab_type": "code",
        "outputId": "0231019a-34b6-4c44-d506-b9570ff86948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test, batch_size = 1024, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 50s 323us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vep6bR7etg4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"./sample_submission.csv\")\n",
        "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = (pred)\n",
        "submission.to_csv(\"submission_model3_Feb23_auc_988480.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0eB1ufDwzxLr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Next tries:\n",
        "#https://www.kaggle.com/tunguz/bi-gru-cnn-poolings-gpu-kernel-version\n",
        "#https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80568 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8aIfgmw0uwZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7lPbxkVy07A4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cogJ7mAj26-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w7096K_ZnsNC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAbN93Z7nSxg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vcvd_PdAoY--",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOiL1lHD6Ffu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lIS3AizP9vdR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7c_QyY9ytW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}