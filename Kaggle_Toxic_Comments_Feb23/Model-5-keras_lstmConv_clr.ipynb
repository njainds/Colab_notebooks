{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments_Feb23/Model-5-keras_lstmConv_clr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oYZkU7ZN3CL0",
        "outputId": "73005f78-1dff-4d04-ef21-2ee308114699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BAFlm8xPHpyc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "import torch\n",
        "from torchtext import data\n",
        "import spacy\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "import zipfile\n",
        "import gzip\n",
        "import keras.backend as K\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "from nltk import word_tokenize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D, Conv2D, Input, SpatialDropout1D, Embedding, Dense, Activation, Bidirectional, LSTM,CuDNNLSTM, CuDNNGRU, GlobalMaxPooling1D,GlobalAveragePooling1D, concatenate, Dropout\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.models import Model\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.engine import Layer\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from unidecode import unidecode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D-lZ41oqDYTC",
        "colab_type": "code",
        "outputId": "3ae6ac36-c56d-4c89-90e8-841ce32bf07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/kaggle_toxic_comments\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "best_model.hdf5\t\t\t   test.csv\n",
            "ext_fasttextwiki_embeddings.npy    test_features.npy\n",
            "ext_glove_embeddings.npy\t   test_labels.csv\n",
            "ext_lexvec_embeddings.npy\t   toxic_lookup_en_wiki_fasttext_300d.npy\n",
            "features.npy\t\t\t   train.csv\n",
            "inputed_lexvec_embeddings.npy\t   word_index.npy\n",
            "local_fasttextwiki_embeddings.npy  x_test.npy\n",
            "Model-runs\t\t\t   x_train.npy\n",
            "sample_submission.csv\t\t   y_train.npy\n",
            "submission_baseline_lr.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ETSksPDYFps2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector) ##sum([word[1] for word in vocab[:120000]])=92%##\n",
        "maxlen = 250 # max number of words in a question to use ## train.num_words.quantile(q=0.96, interpolation='nearest')=258 ##\n",
        "batch_size = 512 # how many samples to process at once\n",
        "n_epochs = 5 # how many times to iterate over all samples\n",
        "n_splits = 5 # Number of K-fold Splits\n",
        "\n",
        "SEED = 2019\n",
        "def seed_everything(seed=2019):\n",
        "    random.seed(seed)\n",
        "    \n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2hyLLFNIHoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/My Drive/kaggle_toxic_comments/\")\n",
        "x_train = np.load(\"x_train.npy\")\n",
        "x_test = np.load(\"x_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "features = np.load(\"features.npy\")\n",
        "test_features = np.load(\"test_features.npy\")\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "ext_lexvec_embeddings = np.load(\"ext_lexvec_embeddings.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jwc1rMTeyDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train simple LSTM using different embeddings\n",
        "# Top compeitions- QIQC and Toxic comments\n",
        "# ensembles (stacking and blending)\n",
        "# Pretrained models- ULMFit and BERT\n",
        "# Gensim and fasttext text classification\n",
        "# Other SOTAs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wdi_9dQMkT2G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Model-3: https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80568\n",
        "# One cycle learning\n",
        "# 10 fold CV with 10 model runs with different initializers/seeds/embeddings\n",
        "# Model with different embeddings and order of rows\n",
        "# Extra features\n",
        "# Pseudo labeling\n",
        "# use focal loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIUW0jz1Wh0F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxiqwQ77Tivr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "            \n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
        "\n",
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=4590., mode='triangular',gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):     \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v) \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YEPJ623BlR17",
        "colab_type": "code",
        "outputId": "9891cf88-cb15-483d-aec3-0ba22a29140d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(maxlen,))\n",
        "x   = Embedding(max_features, embed_size, weights=[ext_lexvec_embeddings], trainable=False)(inp)\n",
        "x   = SpatialDropout1D(rate=0.2)(x)\n",
        "x   = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n",
        "x   = Conv1D(64, kernel_size=1, padding='valid', kernel_initializer='glorot_normal')(x)\n",
        "x1  = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
        "x1   = Conv1D(64, kernel_size=1, padding='valid', kernel_initializer='glorot_normal')(x1)\n",
        "x_max   = GlobalMaxPooling1D()(x)\n",
        "x_avg   = GlobalAveragePooling1D()(x)\n",
        "x1_max  = GlobalMaxPooling1D()(x1)\n",
        "x1_avg  = GlobalAveragePooling1D()(x1)\n",
        "c   = concatenate([x_max,x_avg,x1_max,x1_avg])\n",
        "y   = Dense(64, activation='relu')(c)\n",
        "y   = Dropout(0.2)(y)\n",
        "out = Dense(6, activation='sigmoid')(y)\n",
        "model=Model(inputs=inp,outputs=out)\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 250)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 250, 300)     36000000    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_2 (SpatialDro (None, 250, 300)     0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 250, 256)     330240      spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 250, 64)      16448       bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 250, 256)     198656      conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 250, 64)      16448       bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 64)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_3 (Glo (None, 64)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 64)           0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_4 (Glo (None, 64)           0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256)          0           global_max_pooling1d_3[0][0]     \n",
            "                                                                 global_average_pooling1d_3[0][0] \n",
            "                                                                 global_max_pooling1d_4[0][0]     \n",
            "                                                                 global_average_pooling1d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           16448       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 6)            390         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 36,578,630\n",
            "Trainable params: 578,630\n",
            "Non-trainable params: 36,000,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vAegUwOJ1Juw",
        "colab_type": "code",
        "outputId": "f11fac7e-f021-4738-bef2-da185ad43667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "cell_type": "code",
      "source": [
        "# for one cycle policy: step_size=(len(X_train)/batch_size)*n_ecpochs/2\n",
        "clr = CyclicLR(base_lr=1e-6, max_lr=1e-3,step_size=5610., mode='exp_range',gamma=0.99994)\n",
        "model.fit(X_train, Y_train, batch_size = 128, epochs = 10, validation_data = (X_valid, Y_valid), verbose = 1, callbacks = [clr, ra_val, check_point, early_stop])\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/5\n",
            "143613/143613 [==============================] - 291s 2ms/step - loss: 0.0425 - acc: 0.9836 - val_loss: 0.0440 - val_acc: 0.9830\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.982293\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.04151\n",
            "Epoch 2/5\n",
            "143613/143613 [==============================] - 290s 2ms/step - loss: 0.0435 - acc: 0.9833 - val_loss: 0.0423 - val_acc: 0.9835\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.984566\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.04151\n",
            "Epoch 3/5\n",
            "143613/143613 [==============================] - 290s 2ms/step - loss: 0.0426 - acc: 0.9834 - val_loss: 0.0408 - val_acc: 0.9842\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.986356\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.04151 to 0.04081, saving model to best_model.hdf5\n",
            "Epoch 4/5\n",
            "143613/143613 [==============================] - 290s 2ms/step - loss: 0.0397 - acc: 0.9842 - val_loss: 0.0397 - val_acc: 0.9845\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.988139\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.04081 to 0.03974, saving model to best_model.hdf5\n",
            "Epoch 5/5\n",
            "143613/143613 [==============================] - 290s 2ms/step - loss: 0.0370 - acc: 0.9852 - val_loss: 0.0390 - val_acc: 0.9848\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.988317\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.03974 to 0.03899, saving model to best_model.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f12a3799320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "ngNuKxFWn7Xp",
        "colab_type": "code",
        "outputId": "a49db923-f292-42e0-b9a0-413c40c95622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test, batch_size = 1024, verbose = 1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 49s 323us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vep6bR7etg4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"./sample_submission.csv\")\n",
        "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = (pred)\n",
        "submission.to_csv(\"submission_model5_Feb23_auc_988317.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0eB1ufDwzxLr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sub1 = pd.read_csv(\"/content/drive/My Drive/kaggle_toxic_comments/Model-runs/submission_model5_Feb23_auc_988317.csv\")\n",
        "sub2 = pd.read_csv(\"/content/drive/My Drive/kaggle_toxic_comments/Model-runs/submission_model3_Feb23_auc_988480.csv\")\n",
        "df = pd.concat([sub1, sub2]).groupby(level=0).mean()\n",
        "df['id'] = sub1['id']\n",
        "df = df[[\"id\",\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
        "df.to_csv(\"submission_model5_Feb23_ensemble_988317+988480.csv\", index = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7lPbxkVy07A4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "362f77fd-a5c8-4c6c-abc0-7eb100be2bed"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.999421</td>\n",
              "      <td>4.815847e-01</td>\n",
              "      <td>0.977320</td>\n",
              "      <td>8.526233e-02</td>\n",
              "      <td>0.939398</td>\n",
              "      <td>0.382825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>2.682209e-07</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>3.576279e-07</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.000403</td>\n",
              "      <td>2.086163e-07</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>4.321337e-07</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.000503</td>\n",
              "      <td>8.940697e-08</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>5.811453e-07</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.000981</td>\n",
              "      <td>8.940697e-08</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>1.296401e-06</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id     toxic  severe_toxic   obscene        threat    insult  \\\n",
              "0  00001cee341fdb12  0.999421  4.815847e-01  0.977320  8.526233e-02  0.939398   \n",
              "1  0000247867823ef7  0.000972  2.682209e-07  0.000053  3.576279e-07  0.000098   \n",
              "2  00013b17ad220c46  0.000403  2.086163e-07  0.000065  4.321337e-07  0.000028   \n",
              "3  00017563c3f7919a  0.000503  8.940697e-08  0.000017  5.811453e-07  0.000038   \n",
              "4  00017695ad8997eb  0.000981  8.940697e-08  0.000028  1.296401e-06  0.000062   \n",
              "\n",
              "   identity_hate  \n",
              "0       0.382825  \n",
              "1       0.000005  \n",
              "2       0.000003  \n",
              "3       0.000003  \n",
              "4       0.000003  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "cogJ7mAj26-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w7096K_ZnsNC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAbN93Z7nSxg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vcvd_PdAoY--",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOiL1lHD6Ffu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lIS3AizP9vdR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7c_QyY9ytW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}