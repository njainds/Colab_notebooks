{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/CCP_ICD10_Searchengine/CNNmodelv2_v1.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QYpecTXf_H6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Builf train and evaluate\n",
        "# Save model for offline scoring on test\n",
        "# Model name: CCP_ICD10_Searchengine/CNNmodel_v1.0.ipynb\n",
        "# References\n",
        "#https://github.com/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments/Model-2-keras_lstmConv.ipynb\n",
        "#https://github.com/njainds/NLP/blob/master/kaggle/QIQC/22nd%20Place%20Solution%20-%206%20models%20%2B%20POS%20tagging.ipynb\n",
        "#https://github.com/Cheneng/DPCNN/blob/master/model/DPCNN.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AL5rrZqLghp",
        "colab_type": "code",
        "outputId": "caa2072d-d039-4487-ecac-bc7b35b4fb26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0zRdXN9yo6k3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import callbacks\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NhSwmpxVpCSx",
        "colab_type": "code",
        "outputId": "6c873229-3ea3-47cb-feb8-13585dcca3f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2\"\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "embedding_matrix.npy  model_data.csv  tokenizer.pickle\tword_index.npy\n",
            "icd_dict.npy\t      test_X.npy      train_X.npy\n",
            "mispell_dict.npy      test_y.npy      train_y.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OiHWhcY9SszU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"train_X.npy\")\n",
        "x_test = np.load(\"test_X.npy\")\n",
        "y_train = np.load(\"train_y.npy\")\n",
        "y_test = np.load(\"test_y.npy\")\n",
        "features = np.load(\"test_y.npy\")\n",
        "icd_dict = np.load(\"icd_dict.npy\").item()\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "embeddings = np.load(\"embedding_matrix.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwjoGzOR3m9H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "del check_point, ra_val, early_stop\n",
        "!rm ./best_model.hdf5\n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(x_test, y_test), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D5xLwVe9Bw91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "max_features = embeddings.shape[0]\n",
        "maxlen = x_train.shape[1]\n",
        "embed_size = embeddings.shape[1]\n",
        "n_class = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXiTe8F678Kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del model\n",
        "inp = Input(shape=(maxlen,))\n",
        "x   = Embedding(max_features, embed_size, weights=[embeddings], trainable=True)(inp)\n",
        "x   = SpatialDropout1D(rate=0.2)(x)\n",
        "x1  = Conv1D(128, kernel_size=1, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "x2  = Conv1D(128, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "x3  = Conv1D(128, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "x4  = Conv1D(128, kernel_size=4, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "x1  = GlobalMaxPooling1D()(x1)\n",
        "x2  = GlobalMaxPooling1D()(x2)\n",
        "x3  = GlobalMaxPooling1D()(x3)\n",
        "x4  = GlobalMaxPooling1D()(x4)\n",
        "c   = concatenate([x1,x2,x3,x4])\n",
        "y   = Dense(512, activation='relu')(c)\n",
        "y   = Dropout(0.2)(y)\n",
        "out = Dense(n_class, activation='softmax')(y)\n",
        "model=Model(inputs=inp,outputs=out)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=[\"accuracy\"])\n",
        "#print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Rej4RS8O1JF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Kfold training of model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VaWv1RBN7_ER",
        "colab_type": "code",
        "outputId": "6d80f960-d93e-49a2-8b9d-46364342bd48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1091
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size = 48, epochs = 10, validation_data = (x_test, y_test), verbose = 1, callbacks = [ra_val, check_point, early_stop])\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54151 samples, validate on 6017 samples\n",
            "Epoch 1/10\n",
            "54151/54151 [==============================] - 18s 328us/step - loss: 4.2336 - acc: 0.2365 - val_loss: 3.0324 - val_acc: 0.4032\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.938693\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.03239, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "54151/54151 [==============================] - 15s 281us/step - loss: 2.6996 - acc: 0.4426 - val_loss: 2.2320 - val_acc: 0.5292\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.967066\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.03239 to 2.23203, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "54151/54151 [==============================] - 15s 275us/step - loss: 2.1550 - acc: 0.5306 - val_loss: 1.9086 - val_acc: 0.5872\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.975070\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.23203 to 1.90865, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "54151/54151 [==============================] - 15s 272us/step - loss: 1.8786 - acc: 0.5835 - val_loss: 1.7370 - val_acc: 0.6197\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.978356\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.90865 to 1.73699, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "54151/54151 [==============================] - 15s 275us/step - loss: 1.7025 - acc: 0.6154 - val_loss: 1.6320 - val_acc: 0.6435\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.980535\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.73699 to 1.63202, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "54151/54151 [==============================] - 15s 274us/step - loss: 1.5764 - acc: 0.6428 - val_loss: 1.5565 - val_acc: 0.6570\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.981930\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.63202 to 1.55654, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "54151/54151 [==============================] - 15s 273us/step - loss: 1.4792 - acc: 0.6622 - val_loss: 1.5122 - val_acc: 0.6625\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.982607\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.55654 to 1.51222, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "54151/54151 [==============================] - 15s 275us/step - loss: 1.3992 - acc: 0.6783 - val_loss: 1.4691 - val_acc: 0.6726\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.983402\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.51222 to 1.46911, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "54151/54151 [==============================] - 15s 275us/step - loss: 1.3309 - acc: 0.6907 - val_loss: 1.4352 - val_acc: 0.6817\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.984165\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.46911 to 1.43518, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "54151/54151 [==============================] - 15s 279us/step - loss: 1.2753 - acc: 0.7035 - val_loss: 1.4135 - val_acc: 0.6839\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.984705\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.43518 to 1.41354, saving model to best_model.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1985940a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "YTzDAHadI8I6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c17f61de-d607-4467-f4a9-c98f3daf2f01"
      },
      "cell_type": "code",
      "source": [
        "# ROC scores on Test set for different codes\n",
        "\n",
        "y_pred = model.predict(x_test, batch_size = 16, verbose = 1)\n",
        "print(y_pred[:,395].shape)\n",
        "scores=[]\n",
        "for i in range(396):\n",
        "  score = roc_auc_score(y_test[:,i], y_pred[:,i])\n",
        "  scores.append(score)\n",
        "  #print(\"score for index %s is %d\" (i,score))\n",
        "\n",
        "low = list(np.argsort(scores)[:5])\n",
        "high = list(np.argsort(scores)[::-1][:250])\n",
        "print('high scores is {}'.format(np.mean([scores[i] for i in high])))\n",
        "print('low scores is {}'.format(np.mean([scores[i] for i in low])))\n",
        "# ROC is not a problem in multi-class prediction"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6017/6017 [==============================] - 1s 177us/step\n",
            "(6017,)\n",
            "high scores is 0.9967437630437778\n",
            "low scores is 0.8340337086591365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_weiorJZVhZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bbbd83f-23d6-4927-9053-db3ff943c11e"
      },
      "cell_type": "code",
      "source": [
        "# Top Codes with low accuracy on test set\n",
        "#test_pred = np.argmax(model.predict(x_test, batch_size = 16, verbose = 1), axis=1)\n",
        "#test_act = np.argmax(y_test, axis=1) \n",
        "#mdf = pd.DataFrame({'test_act':list(test_act),'test_pred':list(test_pred)})\n",
        "#acc = [len(mdf[(mdf['test_pred']==i) & (mdf['test_act']==i)])/len(mdf[mdf['test_act']==i]) for i in mdf['test_act'].values]\n",
        "#mdf2 = pd.DataFrame({'class_index': mdf['test_act'].values,'accuracy':acc})\n",
        "print(len(mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()))\n",
        "codes= mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()\n",
        "#codes"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OsS4MwoqOvLK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9489566a-c0ab-411c-cf1a-e637f67fd054"
      },
      "cell_type": "code",
      "source": [
        "# Accuracy on various condifence levels and sample coverage on Test set\n",
        "#p = model.predict(x_test, batch_size = 16, verbose = 1)\n",
        "#test_pred = np.argmax(p, axis=1)\n",
        "#test_pred_proba = np.max(p,axis=1)\n",
        "#mdf3 = pd.DataFrame({'test_act':list(test_act),'test_pred':list(test_pred), 'prob': list(test_pred_proba)})\n",
        "acc = len(mdf3[(mdf3['prob']>0.9) & (mdf3['test_act']==mdf3['test_pred'])])/len(mdf3[(mdf3['prob']>0.9)])\n",
        "print(\"Accuracy on Test dataset is {}\".format(acc))\n",
        "print(\"coverage with this accuracy level on Test dataset is {}\".format(len(mdf3[(mdf3['prob']>0.9)])/len(mdf3)))\n",
        "#mdf3.head()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Test dataset is 0.9438305709023941\n",
            "coverage with this accuracy level on Test dataset is 0.3609772311783281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dVM2EqgpX0Lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2567
        },
        "outputId": "ed4f3942-ca6b-4a96-ee94-4093404a161d"
      },
      "cell_type": "code",
      "source": [
        "# Steps- for re generating the Data for modeling\n",
        "\n",
        "#datasize for icd codes\n",
        "#strain = np.argmax(y_train, axis=1)\n",
        "#codesize = dict([(i,sum(strain==i)) for i in codes]) \n",
        "codesize"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 67,\n",
              " 3: 32,\n",
              " 5: 70,\n",
              " 8: 82,\n",
              " 9: 61,\n",
              " 16: 33,\n",
              " 17: 78,\n",
              " 21: 28,\n",
              " 22: 133,\n",
              " 31: 121,\n",
              " 32: 23,\n",
              " 34: 52,\n",
              " 35: 130,\n",
              " 36: 28,\n",
              " 37: 25,\n",
              " 39: 33,\n",
              " 41: 45,\n",
              " 42: 44,\n",
              " 43: 39,\n",
              " 44: 27,\n",
              " 46: 84,\n",
              " 48: 115,\n",
              " 50: 28,\n",
              " 55: 56,\n",
              " 57: 29,\n",
              " 59: 58,\n",
              " 63: 47,\n",
              " 64: 443,\n",
              " 66: 55,\n",
              " 69: 92,\n",
              " 71: 25,\n",
              " 73: 41,\n",
              " 76: 46,\n",
              " 78: 42,\n",
              " 81: 44,\n",
              " 82: 192,\n",
              " 85: 30,\n",
              " 86: 29,\n",
              " 87: 31,\n",
              " 89: 175,\n",
              " 90: 24,\n",
              " 91: 25,\n",
              " 94: 23,\n",
              " 95: 41,\n",
              " 99: 32,\n",
              " 101: 125,\n",
              " 103: 93,\n",
              " 113: 38,\n",
              " 114: 123,\n",
              " 116: 30,\n",
              " 117: 69,\n",
              " 119: 26,\n",
              " 120: 28,\n",
              " 121: 28,\n",
              " 125: 28,\n",
              " 127: 55,\n",
              " 128: 30,\n",
              " 130: 40,\n",
              " 131: 42,\n",
              " 133: 40,\n",
              " 138: 177,\n",
              " 142: 24,\n",
              " 143: 77,\n",
              " 146: 45,\n",
              " 147: 28,\n",
              " 149: 32,\n",
              " 155: 27,\n",
              " 159: 53,\n",
              " 160: 99,\n",
              " 164: 37,\n",
              " 172: 28,\n",
              " 173: 74,\n",
              " 175: 40,\n",
              " 182: 75,\n",
              " 183: 50,\n",
              " 188: 86,\n",
              " 192: 33,\n",
              " 194: 73,\n",
              " 195: 81,\n",
              " 196: 264,\n",
              " 197: 81,\n",
              " 200: 275,\n",
              " 205: 42,\n",
              " 208: 29,\n",
              " 210: 23,\n",
              " 217: 26,\n",
              " 220: 44,\n",
              " 223: 32,\n",
              " 224: 34,\n",
              " 226: 26,\n",
              " 234: 27,\n",
              " 237: 41,\n",
              " 240: 65,\n",
              " 242: 31,\n",
              " 245: 46,\n",
              " 248: 38,\n",
              " 249: 61,\n",
              " 250: 59,\n",
              " 254: 40,\n",
              " 255: 26,\n",
              " 256: 40,\n",
              " 259: 24,\n",
              " 261: 61,\n",
              " 263: 51,\n",
              " 265: 91,\n",
              " 266: 48,\n",
              " 267: 41,\n",
              " 271: 35,\n",
              " 272: 33,\n",
              " 277: 26,\n",
              " 280: 47,\n",
              " 285: 64,\n",
              " 287: 25,\n",
              " 288: 37,\n",
              " 289: 24,\n",
              " 293: 30,\n",
              " 294: 24,\n",
              " 300: 61,\n",
              " 302: 264,\n",
              " 303: 39,\n",
              " 304: 94,\n",
              " 307: 24,\n",
              " 309: 82,\n",
              " 313: 32,\n",
              " 319: 45,\n",
              " 320: 197,\n",
              " 330: 49,\n",
              " 331: 115,\n",
              " 333: 39,\n",
              " 335: 65,\n",
              " 337: 30,\n",
              " 338: 26,\n",
              " 342: 62,\n",
              " 345: 112,\n",
              " 346: 114,\n",
              " 351: 57,\n",
              " 355: 111,\n",
              " 363: 73,\n",
              " 364: 23,\n",
              " 366: 26,\n",
              " 368: 44,\n",
              " 372: 36,\n",
              " 375: 34,\n",
              " 376: 27,\n",
              " 377: 23,\n",
              " 380: 49,\n",
              " 384: 24,\n",
              " 385: 39,\n",
              " 387: 56,\n",
              " 394: 33}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "metadata": {
        "id": "6DLYUM3s8DDo",
        "colab_type": "code",
        "outputId": "c00938c6-b9a9-4cc5-e213-b4d551e4b74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Final results for presentation\n",
        "\n",
        "#itoicd = dict((v,k) for k,v in icd_dict.items())\n",
        "test_pred = np.argmax(model.predict(x_test, batch_size = 16, verbose = 1), axis=1)\n",
        "test_act = np.argmax(y_test, axis=1)\n",
        "trn_pred = np.argmax(model.predict(x_train, batch_size = 16, verbose = 1), axis=1)\n",
        "trn_act = np.argmax(y_train, axis=1)\n",
        "\n",
        "print(\"Accuracy on val dataset is {}\".format(sum(test_act==test_pred)/test_pred.shape[0]))\n",
        "print(\"Accuracy on trn dataset is {}\".format(sum(trn_act==trn_pred)/trn_pred.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "871/871 [==============================] - 0s 137us/step\n",
            "7834/7834 [==============================] - 1s 117us/step\n",
            "Accuracy on val dataset is 0.7669345579793341\n",
            "Accuracy on trn dataset is 0.857161092672964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vvc7MWcyLwue",
        "colab_type": "code",
        "outputId": "8c029b8c-8ea5-48b3-cf6b-d991290f63ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Saving Model\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_v1.0.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_v1.0.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n",
        "# later..."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cj0mhWJ0Qg2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model_v1.0.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_v1.0.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "score = np.argmax(loaded_model.predict(DATASET, batch_size = 16, verbose = 1), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}