{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/CCP_ICD10_Supmodel_v2/M_maxlen6_396_icd/CNNmodelv2_v1.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QYpecTXf_H6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Builf train and evaluate\n",
        "# Save model for offline scoring on test\n",
        "# Model name: CCP_ICD10_Searchengine/CNNmodel_v1.0.ipynb\n",
        "# References\n",
        "#https://github.com/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments/Model-2-keras_lstmConv.ipynb\n",
        "#https://github.com/njainds/NLP/blob/master/kaggle/QIQC/22nd%20Place%20Solution%20-%206%20models%20%2B%20POS%20tagging.ipynb\n",
        "#https://github.com/Cheneng/DPCNN/blob/master/model/DPCNN.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AL5rrZqLghp",
        "colab_type": "code",
        "outputId": "5ed317f3-e300-4df5-d210-cad44822c678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0zRdXN9yo6k3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa5b26fd-be9d-4d29-d9a3-27f11672a3b0"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import callbacks\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NhSwmpxVpCSx",
        "colab_type": "code",
        "outputId": "ce9b0f71-079b-4e29-b628-016647b40034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#!ls \"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2\"\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/d_maxlen6_396_icd\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OiHWhcY9SszU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"train_X.npy\")\n",
        "x_test = np.load(\"test_X.npy\")\n",
        "y_train = np.load(\"train_y.npy\")\n",
        "y_test = np.load(\"test_y.npy\")\n",
        "features = np.load(\"test_y.npy\")\n",
        "icd_dict = np.load(\"icd_dict.npy\").item()\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "embeddings = np.load(\"embedding_matrix.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nTOOQtvDHeZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=4590., mode='triangular',gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "    \n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size,\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwjoGzOR3m9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f49e9a32-970d-4ca1-9171-ab59be53e60a"
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "#del check_point, ra_val, early_stop\n",
        "!rm ./best_model.hdf5\n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(x_test, y_test), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove './best_model.hdf5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D5xLwVe9Bw91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ba6155a-45cd-4573-d213-0521fcd57fd1"
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen6_396_icd\")\n",
        "max_features = embeddings.shape[0]\n",
        "maxlen = x_train.shape[1]\n",
        "embed_size = embeddings.shape[1]\n",
        "n_class = y_train.shape[1]\n",
        "print(max_features,maxlen, embed_size, n_class)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13735 6 200 396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lXiTe8F678Kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    keras.backend.clear_session()\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x   = Embedding(max_features, embed_size, weights=[embeddings], trainable=True)(inp)\n",
        "    x   = SpatialDropout1D(rate=0.2)(x)\n",
        "    x1  = Conv1D(128, kernel_size=1, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x2  = Conv1D(128, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x3  = Conv1D(128, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x4  = Conv1D(128, kernel_size=4, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x5  = Conv1D(128, kernel_size=5, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    \n",
        "    x1  = GlobalMaxPooling1D()(x1)\n",
        "    x2  = GlobalMaxPooling1D()(x2)\n",
        "    x3  = GlobalMaxPooling1D()(x3)\n",
        "    x4  = GlobalMaxPooling1D()(x4)\n",
        "    x5  = GlobalMaxPooling1D()(x5)\n",
        "    c   = concatenate([x1,x2,x3,x4,x5])\n",
        "    y   = Dense(512, activation='relu')(c)\n",
        "    y   = Dropout(0.2)(y)\n",
        "    out = Dense(n_class, activation='softmax')(y)\n",
        "    model=Model(inputs=inp,outputs=out)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=[\"accuracy\"])\n",
        "    return model\n",
        "#print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Rej4RS8O1JF",
        "colab_type": "code",
        "outputId": "dea323d1-37ff-45b0-b52d-975d7cc17a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8484
        }
      },
      "cell_type": "code",
      "source": [
        "# Kfold training of model\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=8, random_state=2019, shuffle=True)\n",
        "pred_test = np.zeros((x_test.shape[0], n_class))\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kfold.split(x_train, np.argmax(y_train, axis=1))):\n",
        "    X_train, X_val, Y_train, Y_val = x_train[train_index], x_train[valid_index], y_train[train_index], y_train[valid_index]\n",
        "    \n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "    ra_val = RocAucEvaluation(validation_data=(X_val, Y_val), interval = 1)\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
        "    \n",
        "    model = get_model()\n",
        "    \n",
        "    print(\"### Model with seed: {}  for fold no. {} ####\".format( 2019, i))\n",
        "    \n",
        "    clr = CyclicLR(base_lr=1e-6, max_lr=5e-4,step_size=10840., mode='exp_range',gamma=0.99994)\n",
        "    model.fit(X_train, Y_train, batch_size = 24, epochs = 10, validation_data = (X_val, Y_val), verbose = 1, callbacks = [clr, ra_val, check_point, early_stop])\n",
        "    \n",
        "    pred_train = model.predict([X_val], batch_size=24, verbose=2)\n",
        "    pred_test += model.predict([x_test], batch_size=16, verbose=1)/8\n",
        "    os.remove(file_path)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### Model with seed: 2019  for fold no. 0 ####\n",
            "Train on 47216 samples, validate on 6935 samples\n",
            "Epoch 1/10\n",
            "47216/47216 [==============================] - 31s 651us/step - loss: 5.0076 - acc: 0.1333 - val_loss: 3.8020 - val_acc: 0.3008\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.890050\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.80197, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47216/47216 [==============================] - 30s 636us/step - loss: 3.0299 - acc: 0.3977 - val_loss: 2.2727 - val_acc: 0.5204\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.967450\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.80197 to 2.27271, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47216/47216 [==============================] - 30s 632us/step - loss: 2.0805 - acc: 0.5453 - val_loss: 1.7787 - val_acc: 0.6115\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.977842\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.27271 to 1.77868, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47216/47216 [==============================] - 30s 630us/step - loss: 1.6800 - acc: 0.6195 - val_loss: 1.5831 - val_acc: 0.6490\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.981504\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.77868 to 1.58314, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47216/47216 [==============================] - 30s 629us/step - loss: 1.4413 - acc: 0.6694 - val_loss: 1.4681 - val_acc: 0.6668\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.983775\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.58314 to 1.46813, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47216/47216 [==============================] - 30s 629us/step - loss: 1.2752 - acc: 0.7003 - val_loss: 1.4093 - val_acc: 0.6903\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.984504\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.46813 to 1.40931, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47216/47216 [==============================] - 30s 626us/step - loss: 1.1178 - acc: 0.7329 - val_loss: 1.3801 - val_acc: 0.6956\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.985355\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.40931 to 1.38007, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47216/47216 [==============================] - 30s 625us/step - loss: 0.9978 - acc: 0.7535 - val_loss: 1.3643 - val_acc: 0.6975\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.985332\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.38007 to 1.36432, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47216/47216 [==============================] - 30s 626us/step - loss: 0.9164 - acc: 0.7729 - val_loss: 1.3630 - val_acc: 0.7006\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.985717\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.36432 to 1.36301, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47216/47216 [==============================] - 30s 626us/step - loss: 0.8614 - acc: 0.7855 - val_loss: 1.3598 - val_acc: 0.7071\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.985858\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.36301 to 1.35980, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 139us/step\n",
            "### Model with seed: 2019  for fold no. 1 ####\n",
            "Train on 47271 samples, validate on 6880 samples\n",
            "Epoch 1/10\n",
            "47271/47271 [==============================] - 30s 633us/step - loss: 5.0113 - acc: 0.1350 - val_loss: 3.7497 - val_acc: 0.3106\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.903211\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.74967, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47271/47271 [==============================] - 29s 622us/step - loss: 2.9904 - acc: 0.3985 - val_loss: 2.2541 - val_acc: 0.5227\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.971764\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.74967 to 2.25411, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47271/47271 [==============================] - 29s 621us/step - loss: 2.0751 - acc: 0.5428 - val_loss: 1.7693 - val_acc: 0.6173\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.979906\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.25411 to 1.76925, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47271/47271 [==============================] - 29s 619us/step - loss: 1.6752 - acc: 0.6202 - val_loss: 1.5884 - val_acc: 0.6496\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.982465\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.76925 to 1.58841, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47271/47271 [==============================] - 29s 620us/step - loss: 1.4447 - acc: 0.6652 - val_loss: 1.4886 - val_acc: 0.6734\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.984002\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.58841 to 1.48863, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47271/47271 [==============================] - 29s 621us/step - loss: 1.2661 - acc: 0.6997 - val_loss: 1.4321 - val_acc: 0.6895\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.985320\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.48863 to 1.43214, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47271/47271 [==============================] - 29s 621us/step - loss: 1.1132 - acc: 0.7306 - val_loss: 1.3951 - val_acc: 0.6951\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.985855\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.43214 to 1.39513, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47271/47271 [==============================] - 29s 622us/step - loss: 0.9988 - acc: 0.7531 - val_loss: 1.3796 - val_acc: 0.6977\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.986040\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.39513 to 1.37963, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47271/47271 [==============================] - 29s 620us/step - loss: 0.9093 - acc: 0.7717 - val_loss: 1.3755 - val_acc: 0.7015\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.986095\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.37963 to 1.37550, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47271/47271 [==============================] - 29s 620us/step - loss: 0.8554 - acc: 0.7863 - val_loss: 1.3763 - val_acc: 0.7035\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.986100\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.37550\n",
            "6017/6017 [==============================] - 1s 137us/step\n",
            "### Model with seed: 2019  for fold no. 2 ####\n",
            "Train on 47314 samples, validate on 6837 samples\n",
            "Epoch 1/10\n",
            "47314/47314 [==============================] - 30s 643us/step - loss: 5.0334 - acc: 0.1277 - val_loss: 3.7779 - val_acc: 0.3060\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.901009\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.77785, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47314/47314 [==============================] - 30s 631us/step - loss: 3.0176 - acc: 0.3988 - val_loss: 2.2589 - val_acc: 0.5211\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.970827\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.77785 to 2.25893, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47314/47314 [==============================] - 30s 626us/step - loss: 2.0795 - acc: 0.5425 - val_loss: 1.7704 - val_acc: 0.6124\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.979812\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.25893 to 1.77044, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47314/47314 [==============================] - 30s 624us/step - loss: 1.6834 - acc: 0.6176 - val_loss: 1.5756 - val_acc: 0.6516\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.982758\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.77044 to 1.57562, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47314/47314 [==============================] - 30s 624us/step - loss: 1.4455 - acc: 0.6668 - val_loss: 1.4780 - val_acc: 0.6692\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.984548\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.57562 to 1.47800, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47314/47314 [==============================] - 30s 625us/step - loss: 1.2701 - acc: 0.7013 - val_loss: 1.4077 - val_acc: 0.6879\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.985587\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.47800 to 1.40768, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47314/47314 [==============================] - 29s 621us/step - loss: 1.1108 - acc: 0.7320 - val_loss: 1.3784 - val_acc: 0.6958\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.986078\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.40768 to 1.37836, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47314/47314 [==============================] - 29s 621us/step - loss: 0.9985 - acc: 0.7551 - val_loss: 1.3603 - val_acc: 0.6999\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.986390\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.37836 to 1.36026, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47314/47314 [==============================] - 29s 620us/step - loss: 0.9167 - acc: 0.7722 - val_loss: 1.3568 - val_acc: 0.7025\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.986344\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.36026 to 1.35677, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47314/47314 [==============================] - 29s 620us/step - loss: 0.8571 - acc: 0.7846 - val_loss: 1.3498 - val_acc: 0.7053\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.986382\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.35677 to 1.34984, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 137us/step\n",
            "### Model with seed: 2019  for fold no. 3 ####\n",
            "Train on 47361 samples, validate on 6790 samples\n",
            "Epoch 1/10\n",
            "47361/47361 [==============================] - 30s 637us/step - loss: 5.0346 - acc: 0.1272 - val_loss: 3.7262 - val_acc: 0.3199\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.901263\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.72618, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47361/47361 [==============================] - 30s 624us/step - loss: 3.0067 - acc: 0.3969 - val_loss: 2.2223 - val_acc: 0.5323\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.970849\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.72618 to 2.22230, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47361/47361 [==============================] - 30s 625us/step - loss: 2.0818 - acc: 0.5420 - val_loss: 1.7269 - val_acc: 0.6214\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.981029\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.22230 to 1.72686, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47361/47361 [==============================] - 30s 626us/step - loss: 1.6869 - acc: 0.6182 - val_loss: 1.5160 - val_acc: 0.6661\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.984261\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.72686 to 1.51597, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47361/47361 [==============================] - 30s 624us/step - loss: 1.4493 - acc: 0.6661 - val_loss: 1.4195 - val_acc: 0.6867\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.985555\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.51597 to 1.41951, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47361/47361 [==============================] - 30s 624us/step - loss: 1.2818 - acc: 0.6972 - val_loss: 1.3525 - val_acc: 0.6943\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.986807\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.41951 to 1.35247, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47361/47361 [==============================] - 29s 622us/step - loss: 1.1213 - acc: 0.7297 - val_loss: 1.3231 - val_acc: 0.7037\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.987069\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.35247 to 1.32315, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47361/47361 [==============================] - 30s 626us/step - loss: 1.0046 - acc: 0.7532 - val_loss: 1.3038 - val_acc: 0.7099\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.987309\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.32315 to 1.30377, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47361/47361 [==============================] - 29s 618us/step - loss: 0.9242 - acc: 0.7712 - val_loss: 1.3000 - val_acc: 0.7128\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.987359\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.30377 to 1.30003, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47361/47361 [==============================] - 29s 617us/step - loss: 0.8704 - acc: 0.7822 - val_loss: 1.2987 - val_acc: 0.7147\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.987372\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.30003 to 1.29869, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 135us/step\n",
            "### Model with seed: 2019  for fold no. 4 ####\n",
            "Train on 47398 samples, validate on 6753 samples\n",
            "Epoch 1/10\n",
            "47398/47398 [==============================] - 30s 636us/step - loss: 5.0075 - acc: 0.1349 - val_loss: 3.7272 - val_acc: 0.3064\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.897354\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.72718, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47398/47398 [==============================] - 30s 627us/step - loss: 2.9971 - acc: 0.3988 - val_loss: 2.2537 - val_acc: 0.5288\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.968032\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.72718 to 2.25372, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47398/47398 [==============================] - 30s 625us/step - loss: 2.0720 - acc: 0.5456 - val_loss: 1.7804 - val_acc: 0.6172\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.976745\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.25372 to 1.78041, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47398/47398 [==============================] - 30s 624us/step - loss: 1.6742 - acc: 0.6215 - val_loss: 1.5904 - val_acc: 0.6542\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.979896\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.78041 to 1.59039, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47398/47398 [==============================] - 29s 620us/step - loss: 1.4356 - acc: 0.6677 - val_loss: 1.4948 - val_acc: 0.6738\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.981154\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.59039 to 1.49482, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47398/47398 [==============================] - 30s 628us/step - loss: 1.2599 - acc: 0.7026 - val_loss: 1.4397 - val_acc: 0.6884\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.982390\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.49482 to 1.43975, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47398/47398 [==============================] - 29s 620us/step - loss: 1.1063 - acc: 0.7336 - val_loss: 1.4018 - val_acc: 0.6938\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.983157\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.43975 to 1.40175, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47398/47398 [==============================] - 30s 624us/step - loss: 0.9907 - acc: 0.7557 - val_loss: 1.3924 - val_acc: 0.6994\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.983142\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.40175 to 1.39244, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47398/47398 [==============================] - 29s 622us/step - loss: 0.9114 - acc: 0.7726 - val_loss: 1.3908 - val_acc: 0.7004\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.983509\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.39244 to 1.39084, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47398/47398 [==============================] - 30s 624us/step - loss: 0.8553 - acc: 0.7857 - val_loss: 1.3921 - val_acc: 0.7032\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.983407\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.39084\n",
            "6017/6017 [==============================] - 1s 138us/step\n",
            "### Model with seed: 2019  for fold no. 5 ####\n",
            "Train on 47451 samples, validate on 6700 samples\n",
            "Epoch 1/10\n",
            "47451/47451 [==============================] - 31s 643us/step - loss: 5.0043 - acc: 0.1357 - val_loss: 3.6949 - val_acc: 0.3190\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.901578\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.69495, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47451/47451 [==============================] - 30s 634us/step - loss: 2.9905 - acc: 0.4014 - val_loss: 2.2284 - val_acc: 0.5296\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.968152\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.69495 to 2.22836, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47451/47451 [==============================] - 30s 633us/step - loss: 2.0721 - acc: 0.5429 - val_loss: 1.7430 - val_acc: 0.6127\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.977920\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.22836 to 1.74298, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47451/47451 [==============================] - 30s 631us/step - loss: 1.6695 - acc: 0.6217 - val_loss: 1.5503 - val_acc: 0.6512\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.981532\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.74298 to 1.55032, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47451/47451 [==============================] - 30s 630us/step - loss: 1.4385 - acc: 0.6684 - val_loss: 1.4640 - val_acc: 0.6696\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.983206\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.55032 to 1.46403, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47451/47451 [==============================] - 30s 626us/step - loss: 1.2730 - acc: 0.7017 - val_loss: 1.4038 - val_acc: 0.6849\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.984418\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.46403 to 1.40376, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47451/47451 [==============================] - 30s 624us/step - loss: 1.1131 - acc: 0.7322 - val_loss: 1.3590 - val_acc: 0.6925\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.984590\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.40376 to 1.35896, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47451/47451 [==============================] - 30s 626us/step - loss: 0.9952 - acc: 0.7563 - val_loss: 1.3472 - val_acc: 0.6993\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.985016\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.35896 to 1.34716, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47451/47451 [==============================] - 30s 627us/step - loss: 0.9174 - acc: 0.7712 - val_loss: 1.3404 - val_acc: 0.7028\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.984808\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.34716 to 1.34045, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47451/47451 [==============================] - 30s 629us/step - loss: 0.8587 - acc: 0.7846 - val_loss: 1.3358 - val_acc: 0.7045\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.984877\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.34045 to 1.33581, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 135us/step\n",
            "### Model with seed: 2019  for fold no. 6 ####\n",
            "Train on 47497 samples, validate on 6654 samples\n",
            "Epoch 1/10\n",
            "47497/47497 [==============================] - 31s 646us/step - loss: 5.0300 - acc: 0.1305 - val_loss: 3.6941 - val_acc: 0.3094\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.905616\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.69406, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47497/47497 [==============================] - 30s 630us/step - loss: 3.0082 - acc: 0.3982 - val_loss: 2.2272 - val_acc: 0.5305\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.968763\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.69406 to 2.22719, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47497/47497 [==============================] - 30s 629us/step - loss: 2.0791 - acc: 0.5430 - val_loss: 1.7447 - val_acc: 0.6253\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.977596\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.22719 to 1.74470, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47497/47497 [==============================] - 30s 631us/step - loss: 1.6789 - acc: 0.6190 - val_loss: 1.5584 - val_acc: 0.6587\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.980893\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.74470 to 1.55842, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47497/47497 [==============================] - 30s 628us/step - loss: 1.4449 - acc: 0.6650 - val_loss: 1.4657 - val_acc: 0.6788\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.982215\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.55842 to 1.46567, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47497/47497 [==============================] - 30s 626us/step - loss: 1.2726 - acc: 0.6995 - val_loss: 1.4008 - val_acc: 0.6922\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.983621\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.46567 to 1.40076, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47497/47497 [==============================] - 30s 627us/step - loss: 1.1132 - acc: 0.7296 - val_loss: 1.3769 - val_acc: 0.6985\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.983454\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.40076 to 1.37687, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47497/47497 [==============================] - 30s 637us/step - loss: 0.9989 - acc: 0.7547 - val_loss: 1.3563 - val_acc: 0.7078\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.983852\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.37687 to 1.35634, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47497/47497 [==============================] - 30s 633us/step - loss: 0.9192 - acc: 0.7700 - val_loss: 1.3542 - val_acc: 0.7060\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.983904\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.35634 to 1.35418, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47497/47497 [==============================] - 30s 629us/step - loss: 0.8641 - acc: 0.7834 - val_loss: 1.3478 - val_acc: 0.7102\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.983969\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.35418 to 1.34781, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 135us/step\n",
            "### Model with seed: 2019  for fold no. 7 ####\n",
            "Train on 47549 samples, validate on 6602 samples\n",
            "Epoch 1/10\n",
            "47549/47549 [==============================] - 31s 651us/step - loss: 5.0167 - acc: 0.1327 - val_loss: 3.7031 - val_acc: 0.3188\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.904920\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.70310, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47549/47549 [==============================] - 30s 633us/step - loss: 3.0114 - acc: 0.3976 - val_loss: 2.2055 - val_acc: 0.5279\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.967323\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.70310 to 2.20546, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47549/47549 [==============================] - 30s 632us/step - loss: 2.0815 - acc: 0.5439 - val_loss: 1.7401 - val_acc: 0.6169\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.977476\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.20546 to 1.74012, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47549/47549 [==============================] - 30s 630us/step - loss: 1.6804 - acc: 0.6185 - val_loss: 1.5585 - val_acc: 0.6503\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.980542\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.74012 to 1.55847, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47549/47549 [==============================] - 30s 630us/step - loss: 1.4460 - acc: 0.6664 - val_loss: 1.4598 - val_acc: 0.6740\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.982641\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.55847 to 1.45977, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47549/47549 [==============================] - 30s 633us/step - loss: 1.2759 - acc: 0.6989 - val_loss: 1.3967 - val_acc: 0.6878\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.983926\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.45977 to 1.39667, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47549/47549 [==============================] - 30s 629us/step - loss: 1.1160 - acc: 0.7318 - val_loss: 1.3673 - val_acc: 0.6966\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.984147\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.39667 to 1.36727, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47549/47549 [==============================] - 30s 632us/step - loss: 1.0024 - acc: 0.7545 - val_loss: 1.3485 - val_acc: 0.7008\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.984741\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.36727 to 1.34853, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47549/47549 [==============================] - 30s 628us/step - loss: 0.9175 - acc: 0.7731 - val_loss: 1.3390 - val_acc: 0.7060\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.985074\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.34853 to 1.33900, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47549/47549 [==============================] - 30s 631us/step - loss: 0.8639 - acc: 0.7823 - val_loss: 1.3376 - val_acc: 0.7072\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.985001\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.33900 to 1.33756, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 142us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YTzDAHadI8I6",
        "colab_type": "code",
        "outputId": "61fbb011-a8dc-424c-9e48-534918ed3daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# ROC scores on Test set for different codes\n",
        "scores=[]\n",
        "for i in range(396):\n",
        "  score = roc_auc_score(y_test[:,i], pred_test[:,i])\n",
        "  scores.append(score)\n",
        "  #print(\"score for index %s is %d\" (i,score))\n",
        "\n",
        "low = list(np.argsort(scores)[:5])\n",
        "high = list(np.argsort(scores)[::-1][:250])\n",
        "print('high scores is {}'.format(np.mean([scores[i] for i in high])))\n",
        "print('low scores is {}'.format(np.mean([scores[i] for i in low])))\n",
        "# ROC is not a problem in multi-class prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "high scores is 0.9976635485766142\n",
            "low scores is 0.8496196545022776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cbDZj9NXtenR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving predictions for error analysis\n",
        "os.mkdir('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen6_396_icd/run1_kfold_71.3/')\n",
        "os.chdir('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen6_396_icd/run1_kfold_71.3')\n",
        "\n",
        "itoicd = dict((v,k) for k,v in icd_dict.items())\n",
        "test_pred = np.argmax(pred_test, axis=1)\n",
        "test_act = np.argmax(y_test, axis=1) \n",
        "mdf = pd.DataFrame({'test_act':[itoicd[i] for i in list(test_act)],'test_pred':[itoicd[i] for i in list(test_pred)]})\n",
        "mdf.to_csv('pred_test.csv',index=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_weiorJZVhZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Top Codes with low accuracy on test set\n",
        "#pred_test\n",
        "acc = [len(mdf[(mdf['test_pred']==i) & (mdf['test_act']==i)])/len(mdf[mdf['test_act']==i]) for i in mdf['test_act'].values]\n",
        "mdf2 = pd.DataFrame({'class_index': mdf['test_act'].values,'accuracy':acc})\n",
        "#print(len(mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()))\n",
        "codes= mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()\n",
        "mdf2.to_csv('error_codes.csv', index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsS4MwoqOvLK",
        "colab_type": "code",
        "outputId": "349d1848-fc2b-46c5-b8db-6dd06f62d928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy on various condifence levels and sample coverage on Test set\n",
        "test_pred = np.argmax(pred_test, axis=1)\n",
        "test_pred_proba = np.max(pred_test,axis=1)\n",
        "mdf3 = pd.DataFrame({'test_act':list(test_act),'test_pred':list(test_pred), 'prob': list(test_pred_proba)})\n",
        "#del CUTOFF\n",
        "for CUTOFF in range(0,100,5):\n",
        "    acc = len(mdf3[(mdf3['prob']>CUTOFF/100) & (mdf3['test_act']==mdf3['test_pred'])])/len(mdf3[(mdf3['prob']>CUTOFF/100)])\n",
        "    cov = len(mdf3[(mdf3['prob']>CUTOFF/100)])/len(mdf3)\n",
        "    print(\"Confidence: %f ## Accuracy: %f ## Coverage on Test dataset: %f\" % (CUTOFF/100,acc,cov))\n",
        "    #print(\"coverage with this accuracy level on Test dataset is {}\".format(cov))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence: 0.000000 ## Accuracy: 0.713478 ## Coverage on Test dataset: 1.000000\n",
            "Confidence: 0.050000 ## Accuracy: 0.727890 ## Coverage on Test dataset: 0.979059\n",
            "Confidence: 0.100000 ## Accuracy: 0.736118 ## Coverage on Test dataset: 0.966761\n",
            "Confidence: 0.150000 ## Accuracy: 0.742092 ## Coverage on Test dataset: 0.956291\n",
            "Confidence: 0.200000 ## Accuracy: 0.751280 ## Coverage on Test dataset: 0.941499\n",
            "Confidence: 0.250000 ## Accuracy: 0.762455 ## Coverage on Test dataset: 0.920725\n",
            "Confidence: 0.300000 ## Accuracy: 0.775014 ## Coverage on Test dataset: 0.895297\n",
            "Confidence: 0.350000 ## Accuracy: 0.785374 ## Coverage on Test dataset: 0.872694\n",
            "Confidence: 0.400000 ## Accuracy: 0.799330 ## Coverage on Test dataset: 0.843942\n",
            "Confidence: 0.450000 ## Accuracy: 0.814186 ## Coverage on Test dataset: 0.813030\n",
            "Confidence: 0.500000 ## Accuracy: 0.829592 ## Coverage on Test dataset: 0.777298\n",
            "Confidence: 0.550000 ## Accuracy: 0.846308 ## Coverage on Test dataset: 0.745056\n",
            "Confidence: 0.600000 ## Accuracy: 0.860694 ## Coverage on Test dataset: 0.708659\n",
            "Confidence: 0.650000 ## Accuracy: 0.877003 ## Coverage on Test dataset: 0.674256\n",
            "Confidence: 0.700000 ## Accuracy: 0.893201 ## Coverage on Test dataset: 0.638026\n",
            "Confidence: 0.750000 ## Accuracy: 0.905431 ## Coverage on Test dataset: 0.602792\n",
            "Confidence: 0.800000 ## Accuracy: 0.919384 ## Coverage on Test dataset: 0.560745\n",
            "Confidence: 0.850000 ## Accuracy: 0.929129 ## Coverage on Test dataset: 0.511218\n",
            "Confidence: 0.900000 ## Accuracy: 0.943883 ## Coverage on Test dataset: 0.444241\n",
            "Confidence: 0.950000 ## Accuracy: 0.957740 ## Coverage on Test dataset: 0.350008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dVM2EqgpX0Lr",
        "colab_type": "code",
        "outputId": "dc794495-7acc-4fd9-a7df-fa66809374a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "# Steps- for re generating the Data for modeling\n",
        "\n",
        "#datasize for icd codes\n",
        "\n",
        "strain = np.argmax(np.vstack([y_train,y_test]), axis=1)\n",
        "codesize = [sum(strain==icd_dict[i]) for i in codes]\n",
        "#print(len([i for i in codesize if i < 30]))\n",
        "codesize2 = [sum(strain==icd_dict[i]) for i in (set([itoicd[i] for i in set(strain)])-set(codes))]\n",
        "#print(len([i for i in codesize2 if i < 30]))\n",
        "\n",
        "print(\"mean dataset size of error codes is %d\" % (np.mean(codesize)))\n",
        "print(\"mean  dataset size of non-error codes is %d\" % (np.mean(codesize2)))\n",
        "print(\"median dataset size of error codes is %d\" % (np.median(codesize)))\n",
        "print(\"median  dataset size of non-error codes is %d\" % (np.median(codesize2)))\n",
        "\n",
        "# word entropy for icd codes\n",
        "\n",
        "idx = [[j for j in range(len(strain)) if strain[j]==icd_dict[i]] for i in codes]\n",
        "idx2 = [[j for j in range(len(strain)) if strain[j]==icd_dict[i]] for i in (set([itoicd[i] for i in set(strain)])-set(codes))]\n",
        "x = np.vstack([x_train, x_test])\n",
        "word_ent = [len(set([j for i in [[list(x[i]) for i in p] for p in idx][p] for j in i])) for p in range(len([[list(x[i]) for i in p] for p in idx]))]\n",
        "word_ent2 = [len(set([j for i in [[list(x[i]) for i in p] for p in idx2][p] for j in i])) for p in range(len([[list(x[i]) for i in p] for p in idx2]))]\n",
        "\n",
        "print(\"#################################################\")\n",
        "print(\"mean # of unqiue words in error codes is %d\" % (np.mean(word_ent)))\n",
        "print(\"mean # of unqiue words in non-error codes is %d\" % (np.mean(word_ent2)))\n",
        "print(\"median # of unqiue words in error codes is %d\" % (np.median(word_ent)))\n",
        "print(\"median # of unqiue words in non-error codes is %d\" % (np.median(word_ent2)))\n",
        "\n",
        "\n",
        "#codesize\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean dataset size of error codes is 63\n",
            "mean  dataset size of non-error codes is 187\n",
            "median dataset size of error codes is 44\n",
            "median  dataset size of non-error codes is 103\n",
            "#################################################\n",
            "mean # of unqiue words in error codes is 73\n",
            "mean # of unqiue words in non-error codes is 107\n",
            "median # of unqiue words in error codes is 59\n",
            "median # of unqiue words in non-error codes is 79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vvc7MWcyLwue",
        "colab_type": "code",
        "outputId": "f15c6daa-634c-447e-e918-65269fb30491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Saving Model\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_v1.0.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_v1.0.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n",
        "# later..."
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cj0mhWJ0Qg2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model_v1.0.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_v1.0.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "score = np.argmax(loaded_model.predict(DATASET, batch_size = 16, verbose = 1), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}