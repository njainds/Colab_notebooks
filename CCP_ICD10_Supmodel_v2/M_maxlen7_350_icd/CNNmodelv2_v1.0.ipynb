{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/CCP_ICD10_Supmodel_v2/M_maxlen7_350_icd/CNNmodelv2_v1.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QYpecTXf_H6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Builf train and evaluate\n",
        "# Save model for offline scoring on test\n",
        "# Model name: CCP_ICD10_Searchengine/CNNmodel_v1.0.ipynb\n",
        "# References\n",
        "#https://github.com/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments/Model-2-keras_lstmConv.ipynb\n",
        "#https://github.com/njainds/NLP/blob/master/kaggle/QIQC/22nd%20Place%20Solution%20-%206%20models%20%2B%20POS%20tagging.ipynb\n",
        "#https://github.com/Cheneng/DPCNN/blob/master/model/DPCNN.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AL5rrZqLghp",
        "colab_type": "code",
        "outputId": "5ed317f3-e300-4df5-d210-cad44822c678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0zRdXN9yo6k3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa5b26fd-be9d-4d29-d9a3-27f11672a3b0"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import callbacks\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NhSwmpxVpCSx",
        "colab_type": "code",
        "outputId": "aabf2968-e23f-4e59-a8f9-5fa2f92add25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#!ls \"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2\"\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/d_maxlen7_350_icd\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OiHWhcY9SszU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"train_X.npy\")\n",
        "x_test = np.load(\"test_X.npy\")\n",
        "y_train = np.load(\"train_y.npy\")\n",
        "y_test = np.load(\"test_y.npy\")\n",
        "features = np.load(\"test_y.npy\")\n",
        "icd_dict = np.load(\"icd_dict.npy\").item()\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "embeddings = np.load(\"embedding_matrix.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nTOOQtvDHeZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=4590., mode='triangular',gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "    \n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size,\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwjoGzOR3m9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2a52079-5a77-4c94-a480-3ac6ab6502a3"
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "#del check_point, ra_val, early_stop\n",
        "!rm ./best_model.hdf5\n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(x_test, y_test), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove './best_model.hdf5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D5xLwVe9Bw91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b15574a-a36b-4079-8703-ce9e6db5d6b5"
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen7_350_icd\")\n",
        "max_features = embeddings.shape[0]\n",
        "maxlen = x_train.shape[1]\n",
        "embed_size = embeddings.shape[1]\n",
        "n_class = y_train.shape[1]\n",
        "print(max_features,maxlen, embed_size, n_class)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13735 7 200 350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lXiTe8F678Kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    keras.backend.clear_session()\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x   = Embedding(max_features, embed_size, weights=[embeddings], trainable=True)(inp)\n",
        "    x   = SpatialDropout1D(rate=0.2)(x)\n",
        "    x1  = Conv1D(128, kernel_size=1, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x2  = Conv1D(128, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x3  = Conv1D(128, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x4  = Conv1D(128, kernel_size=4, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x5  = Conv1D(128, kernel_size=5, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    \n",
        "    x1  = GlobalMaxPooling1D()(x1)\n",
        "    x2  = GlobalMaxPooling1D()(x2)\n",
        "    x3  = GlobalMaxPooling1D()(x3)\n",
        "    x4  = GlobalMaxPooling1D()(x4)\n",
        "    x5  = GlobalMaxPooling1D()(x5)\n",
        "    c   = concatenate([x1,x2,x3,x4,x5])\n",
        "    y   = Dense(512, activation='relu')(c)\n",
        "    y   = Dropout(0.2)(y)\n",
        "    out = Dense(n_class, activation='softmax')(y)\n",
        "    model=Model(inputs=inp,outputs=out)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=[\"accuracy\"])\n",
        "    return model\n",
        "#print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DjIl2g-N-GUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef94869f-a55f-46e2-c17a-e798e6d7e3f7"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52033, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "8Rej4RS8O1JF",
        "colab_type": "code",
        "outputId": "912f739c-692a-43c6-a6a0-a813a6912ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8706
        }
      },
      "cell_type": "code",
      "source": [
        "# Kfold training of model\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=8, random_state=2019, shuffle=True)\n",
        "pred_test = np.zeros((x_test.shape[0], n_class))\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kfold.split(x_train, np.argmax(y_train, axis=1))):\n",
        "    X_train, X_val, Y_train, Y_val = x_train[train_index], x_train[valid_index], y_train[train_index], y_train[valid_index]\n",
        "    \n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "    ra_val = RocAucEvaluation(validation_data=(X_val, Y_val), interval = 1)\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
        "    \n",
        "    model = get_model()\n",
        "    \n",
        "    print(\"### Model with seed: {}  for fold no. {} ####\".format( 2019, i))\n",
        "    \n",
        "    clr = CyclicLR(base_lr=1e-6, max_lr=5e-4,step_size=10840., mode='exp_range',gamma=0.99994)\n",
        "    model.fit(X_train, Y_train, batch_size = 24, epochs = 10, validation_data = (X_val, Y_val), verbose = 1, callbacks = [clr, ra_val, check_point, early_stop])\n",
        "    \n",
        "    pred_train = model.predict([X_val], batch_size=24, verbose=2)\n",
        "    pred_test += model.predict([x_test], batch_size=16, verbose=1)/8\n",
        "    os.remove(file_path)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "### Model with seed: 2019  for fold no. 0 ####\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 45382 samples, validate on 6651 samples\n",
            "Epoch 1/10\n",
            "45382/45382 [==============================] - 32s 710us/step - loss: 4.9219 - acc: 0.1326 - val_loss: 3.6684 - val_acc: 0.3087\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.901586\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.66841, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45382/45382 [==============================] - 29s 631us/step - loss: 2.8979 - acc: 0.4103 - val_loss: 2.1510 - val_acc: 0.5384\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.971983\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.66841 to 2.15102, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45382/45382 [==============================] - 29s 631us/step - loss: 1.9586 - acc: 0.5625 - val_loss: 1.6533 - val_acc: 0.6306\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.981240\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.15102 to 1.65330, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45382/45382 [==============================] - 29s 636us/step - loss: 1.5571 - acc: 0.6419 - val_loss: 1.4488 - val_acc: 0.6715\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.984467\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.65330 to 1.44881, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45382/45382 [==============================] - 29s 642us/step - loss: 1.3312 - acc: 0.6876 - val_loss: 1.3472 - val_acc: 0.6979\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.985978\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.44881 to 1.34720, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45382/45382 [==============================] - 29s 634us/step - loss: 1.1701 - acc: 0.7207 - val_loss: 1.2946 - val_acc: 0.7127\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.986532\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.34720 to 1.29460, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45382/45382 [==============================] - 29s 636us/step - loss: 1.0224 - acc: 0.7504 - val_loss: 1.2593 - val_acc: 0.7211\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.986922\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.29460 to 1.25932, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45382/45382 [==============================] - 29s 630us/step - loss: 0.9080 - acc: 0.7755 - val_loss: 1.2536 - val_acc: 0.7252\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.986939\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.25932 to 1.25363, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45382/45382 [==============================] - 29s 635us/step - loss: 0.8275 - acc: 0.7913 - val_loss: 1.2560 - val_acc: 0.7321\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.986972\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.25363\n",
            "Epoch 10/10\n",
            "45382/45382 [==============================] - 29s 632us/step - loss: 0.7726 - acc: 0.8051 - val_loss: 1.2418 - val_acc: 0.7327\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.987441\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.25363 to 1.24180, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 147us/step\n",
            "### Model with seed: 2019  for fold no. 1 ####\n",
            "Train on 45431 samples, validate on 6602 samples\n",
            "Epoch 1/10\n",
            "45431/45431 [==============================] - 29s 640us/step - loss: 4.9703 - acc: 0.1286 - val_loss: 3.7260 - val_acc: 0.2987\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.908176\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.72604, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45431/45431 [==============================] - 29s 630us/step - loss: 2.9326 - acc: 0.4079 - val_loss: 2.1395 - val_acc: 0.5377\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.974874\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.72604 to 2.13950, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45431/45431 [==============================] - 29s 630us/step - loss: 1.9699 - acc: 0.5590 - val_loss: 1.6408 - val_acc: 0.6348\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.983618\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.13950 to 1.64082, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45431/45431 [==============================] - 29s 629us/step - loss: 1.5652 - acc: 0.6407 - val_loss: 1.4077 - val_acc: 0.6813\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.986666\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.64082 to 1.40770, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45431/45431 [==============================] - 29s 630us/step - loss: 1.3298 - acc: 0.6903 - val_loss: 1.3082 - val_acc: 0.7046\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.988431\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.40770 to 1.30817, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45431/45431 [==============================] - 29s 630us/step - loss: 1.1694 - acc: 0.7222 - val_loss: 1.2524 - val_acc: 0.7133\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.988874\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.30817 to 1.25243, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45431/45431 [==============================] - 29s 631us/step - loss: 1.0235 - acc: 0.7537 - val_loss: 1.2083 - val_acc: 0.7266\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.989506\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.25243 to 1.20829, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45431/45431 [==============================] - 29s 631us/step - loss: 0.9106 - acc: 0.7759 - val_loss: 1.1906 - val_acc: 0.7328\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.989673\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.20829 to 1.19061, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45431/45431 [==============================] - 29s 631us/step - loss: 0.8319 - acc: 0.7924 - val_loss: 1.1866 - val_acc: 0.7355\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.989802\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.19061 to 1.18657, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45431/45431 [==============================] - 29s 629us/step - loss: 0.7750 - acc: 0.8037 - val_loss: 1.1788 - val_acc: 0.7401\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.989878\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.18657 to 1.17880, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 143us/step\n",
            "### Model with seed: 2019  for fold no. 2 ####\n",
            "Train on 45467 samples, validate on 6566 samples\n",
            "Epoch 1/10\n",
            "45467/45467 [==============================] - 29s 642us/step - loss: 4.9606 - acc: 0.1293 - val_loss: 3.7359 - val_acc: 0.3041\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.902309\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.73594, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45467/45467 [==============================] - 29s 632us/step - loss: 2.9447 - acc: 0.4061 - val_loss: 2.1252 - val_acc: 0.5474\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.973167\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.73594 to 2.12521, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45467/45467 [==============================] - 29s 633us/step - loss: 1.9670 - acc: 0.5603 - val_loss: 1.6182 - val_acc: 0.6418\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.982457\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.12521 to 1.61819, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45467/45467 [==============================] - 29s 630us/step - loss: 1.5639 - acc: 0.6402 - val_loss: 1.4320 - val_acc: 0.6831\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.985363\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.61819 to 1.43204, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45467/45467 [==============================] - 29s 630us/step - loss: 1.3308 - acc: 0.6896 - val_loss: 1.3269 - val_acc: 0.7004\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.986807\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.43204 to 1.32689, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45467/45467 [==============================] - 29s 629us/step - loss: 1.1736 - acc: 0.7216 - val_loss: 1.2616 - val_acc: 0.7176\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.987018\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.32689 to 1.26158, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45467/45467 [==============================] - 29s 628us/step - loss: 1.0213 - acc: 0.7529 - val_loss: 1.2372 - val_acc: 0.7225\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.987499\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.26158 to 1.23716, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45467/45467 [==============================] - 29s 628us/step - loss: 0.9100 - acc: 0.7766 - val_loss: 1.2061 - val_acc: 0.7274\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.988064\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.23716 to 1.20611, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45467/45467 [==============================] - 29s 628us/step - loss: 0.8293 - acc: 0.7934 - val_loss: 1.2019 - val_acc: 0.7341\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.988017\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.20611 to 1.20190, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45467/45467 [==============================] - 29s 627us/step - loss: 0.7725 - acc: 0.8039 - val_loss: 1.2003 - val_acc: 0.7344\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.988002\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.20190 to 1.20031, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 143us/step\n",
            "### Model with seed: 2019  for fold no. 3 ####\n",
            "Train on 45510 samples, validate on 6523 samples\n",
            "Epoch 1/10\n",
            "45510/45510 [==============================] - 29s 636us/step - loss: 4.9171 - acc: 0.1349 - val_loss: 3.6722 - val_acc: 0.3158\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.905190\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.67225, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45510/45510 [==============================] - 29s 631us/step - loss: 2.9081 - acc: 0.4117 - val_loss: 2.1497 - val_acc: 0.5461\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.971304\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.67225 to 2.14973, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45510/45510 [==============================] - 29s 631us/step - loss: 1.9543 - acc: 0.5634 - val_loss: 1.6480 - val_acc: 0.6362\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.980789\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.14973 to 1.64796, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45510/45510 [==============================] - 29s 629us/step - loss: 1.5633 - acc: 0.6418 - val_loss: 1.4528 - val_acc: 0.6790\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.984264\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.64796 to 1.45285, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45510/45510 [==============================] - 29s 627us/step - loss: 1.3307 - acc: 0.6892 - val_loss: 1.3596 - val_acc: 0.7009\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.985453\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.45285 to 1.35957, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45510/45510 [==============================] - 29s 629us/step - loss: 1.1674 - acc: 0.7224 - val_loss: 1.3111 - val_acc: 0.7101\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.986334\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.35957 to 1.31112, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45510/45510 [==============================] - 29s 628us/step - loss: 1.0177 - acc: 0.7541 - val_loss: 1.2706 - val_acc: 0.7225\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.986768\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.31112 to 1.27064, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45510/45510 [==============================] - 29s 629us/step - loss: 0.9095 - acc: 0.7756 - val_loss: 1.2612 - val_acc: 0.7259\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.987062\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.27064 to 1.26121, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45510/45510 [==============================] - 29s 630us/step - loss: 0.8264 - acc: 0.7934 - val_loss: 1.2531 - val_acc: 0.7279\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.987006\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.26121 to 1.25310, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45510/45510 [==============================] - 29s 628us/step - loss: 0.7688 - acc: 0.8055 - val_loss: 1.2511 - val_acc: 0.7300\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.987131\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.25310 to 1.25106, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 145us/step\n",
            "### Model with seed: 2019  for fold no. 4 ####\n",
            "Train on 45541 samples, validate on 6492 samples\n",
            "Epoch 1/10\n",
            "45541/45541 [==============================] - 29s 639us/step - loss: 4.9511 - acc: 0.1303 - val_loss: 3.6449 - val_acc: 0.3253\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.908605\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.64490, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45541/45541 [==============================] - 29s 628us/step - loss: 2.8860 - acc: 0.4137 - val_loss: 2.1029 - val_acc: 0.5437\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.975844\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.64490 to 2.10292, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45541/45541 [==============================] - 29s 631us/step - loss: 1.9562 - acc: 0.5614 - val_loss: 1.6370 - val_acc: 0.6308\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.982969\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.10292 to 1.63701, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45541/45541 [==============================] - 29s 629us/step - loss: 1.5613 - acc: 0.6423 - val_loss: 1.4239 - val_acc: 0.6802\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.986273\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.63701 to 1.42386, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45541/45541 [==============================] - 29s 630us/step - loss: 1.3300 - acc: 0.6907 - val_loss: 1.3533 - val_acc: 0.6929\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.987174\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.42386 to 1.35325, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45541/45541 [==============================] - 29s 630us/step - loss: 1.1705 - acc: 0.7231 - val_loss: 1.2958 - val_acc: 0.7135\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.988121\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.35325 to 1.29578, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45541/45541 [==============================] - 29s 630us/step - loss: 1.0283 - acc: 0.7506 - val_loss: 1.2556 - val_acc: 0.7210\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.988307\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.29578 to 1.25556, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45541/45541 [==============================] - 29s 629us/step - loss: 0.9083 - acc: 0.7757 - val_loss: 1.2442 - val_acc: 0.7260\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.988861\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.25556 to 1.24416, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45541/45541 [==============================] - 29s 629us/step - loss: 0.8289 - acc: 0.7943 - val_loss: 1.2390 - val_acc: 0.7300\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.988710\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.24416 to 1.23896, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45541/45541 [==============================] - 29s 626us/step - loss: 0.7754 - acc: 0.8069 - val_loss: 1.2423 - val_acc: 0.7314\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.988673\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.23896\n",
            "5782/5782 [==============================] - 1s 144us/step\n",
            "### Model with seed: 2019  for fold no. 5 ####\n",
            "Train on 45590 samples, validate on 6443 samples\n",
            "Epoch 1/10\n",
            "45590/45590 [==============================] - 29s 635us/step - loss: 4.9412 - acc: 0.1324 - val_loss: 3.6363 - val_acc: 0.3228\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.910192\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.63627, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45590/45590 [==============================] - 29s 631us/step - loss: 2.9122 - acc: 0.4095 - val_loss: 2.0974 - val_acc: 0.5449\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.973870\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.63627 to 2.09737, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45590/45590 [==============================] - 29s 628us/step - loss: 1.9605 - acc: 0.5626 - val_loss: 1.5795 - val_acc: 0.6429\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.982953\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.09737 to 1.57948, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45590/45590 [==============================] - 29s 628us/step - loss: 1.5623 - acc: 0.6429 - val_loss: 1.3987 - val_acc: 0.6821\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.985573\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.57948 to 1.39870, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45590/45590 [==============================] - 29s 628us/step - loss: 1.3307 - acc: 0.6922 - val_loss: 1.2855 - val_acc: 0.7115\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.987127\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.39870 to 1.28550, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45590/45590 [==============================] - 29s 627us/step - loss: 1.1734 - acc: 0.7215 - val_loss: 1.2292 - val_acc: 0.7197\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.987914\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.28550 to 1.22922, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45590/45590 [==============================] - 29s 631us/step - loss: 1.0266 - acc: 0.7522 - val_loss: 1.2029 - val_acc: 0.7302\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.988434\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.22922 to 1.20294, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45590/45590 [==============================] - 29s 628us/step - loss: 0.9103 - acc: 0.7751 - val_loss: 1.1840 - val_acc: 0.7371\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.988753\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.20294 to 1.18402, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45590/45590 [==============================] - 29s 630us/step - loss: 0.8333 - acc: 0.7912 - val_loss: 1.1765 - val_acc: 0.7366\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.988706\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.18402 to 1.17654, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45590/45590 [==============================] - 29s 630us/step - loss: 0.7741 - acc: 0.8055 - val_loss: 1.1797 - val_acc: 0.7385\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.988755\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.17654\n",
            "5782/5782 [==============================] - 1s 142us/step\n",
            "### Model with seed: 2019  for fold no. 6 ####\n",
            "Train on 45632 samples, validate on 6401 samples\n",
            "Epoch 1/10\n",
            "45632/45632 [==============================] - 29s 638us/step - loss: 4.9327 - acc: 0.1353 - val_loss: 3.6363 - val_acc: 0.3145\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.904581\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.63630, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45632/45632 [==============================] - 29s 629us/step - loss: 2.8976 - acc: 0.4112 - val_loss: 2.1573 - val_acc: 0.5377\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.970515\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.63630 to 2.15728, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45632/45632 [==============================] - 29s 628us/step - loss: 1.9466 - acc: 0.5648 - val_loss: 1.6926 - val_acc: 0.6216\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.979884\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.15728 to 1.69261, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45632/45632 [==============================] - 29s 628us/step - loss: 1.5491 - acc: 0.6446 - val_loss: 1.4933 - val_acc: 0.6635\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.983744\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.69261 to 1.49333, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45632/45632 [==============================] - 29s 629us/step - loss: 1.3202 - acc: 0.6912 - val_loss: 1.4020 - val_acc: 0.6925\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.984987\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.49333 to 1.40205, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45632/45632 [==============================] - 29s 626us/step - loss: 1.1617 - acc: 0.7238 - val_loss: 1.3370 - val_acc: 0.7049\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.986099\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.40205 to 1.33701, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45632/45632 [==============================] - 29s 626us/step - loss: 1.0191 - acc: 0.7554 - val_loss: 1.2964 - val_acc: 0.7119\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.986646\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.33701 to 1.29636, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45632/45632 [==============================] - 29s 625us/step - loss: 0.8994 - acc: 0.7772 - val_loss: 1.2837 - val_acc: 0.7213\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.987070\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.29636 to 1.28370, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45632/45632 [==============================] - 29s 631us/step - loss: 0.8242 - acc: 0.7924 - val_loss: 1.2726 - val_acc: 0.7230\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.987144\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.28370 to 1.27257, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45632/45632 [==============================] - 29s 629us/step - loss: 0.7690 - acc: 0.8055 - val_loss: 1.2723 - val_acc: 0.7249\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.987151\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.27257 to 1.27227, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 144us/step\n",
            "### Model with seed: 2019  for fold no. 7 ####\n",
            "Train on 45678 samples, validate on 6355 samples\n",
            "Epoch 1/10\n",
            "45678/45678 [==============================] - 29s 638us/step - loss: 4.9435 - acc: 0.1311 - val_loss: 3.6235 - val_acc: 0.3180\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.906767\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.62350, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45678/45678 [==============================] - 29s 633us/step - loss: 2.8973 - acc: 0.4110 - val_loss: 2.0759 - val_acc: 0.5556\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.971843\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.62350 to 2.07594, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45678/45678 [==============================] - 29s 627us/step - loss: 1.9471 - acc: 0.5636 - val_loss: 1.5955 - val_acc: 0.6450\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.981135\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.07594 to 1.59554, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45678/45678 [==============================] - 29s 628us/step - loss: 1.5499 - acc: 0.6447 - val_loss: 1.3975 - val_acc: 0.6862\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.984540\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.59554 to 1.39752, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45678/45678 [==============================] - 29s 626us/step - loss: 1.3259 - acc: 0.6926 - val_loss: 1.3338 - val_acc: 0.7024\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.986190\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.39752 to 1.33378, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45678/45678 [==============================] - 29s 626us/step - loss: 1.1686 - acc: 0.7237 - val_loss: 1.2605 - val_acc: 0.7183\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.987226\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.33378 to 1.26047, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45678/45678 [==============================] - 29s 629us/step - loss: 1.0255 - acc: 0.7521 - val_loss: 1.2347 - val_acc: 0.7284\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.987697\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.26047 to 1.23467, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45678/45678 [==============================] - 29s 627us/step - loss: 0.9082 - acc: 0.7744 - val_loss: 1.2138 - val_acc: 0.7298\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.987980\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.23467 to 1.21383, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45678/45678 [==============================] - 29s 629us/step - loss: 0.8304 - acc: 0.7912 - val_loss: 1.2094 - val_acc: 0.7323\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.988040\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.21383 to 1.20936, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45678/45678 [==============================] - 29s 627us/step - loss: 0.7748 - acc: 0.8031 - val_loss: 1.2021 - val_acc: 0.7352\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.988182\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.20936 to 1.20210, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 145us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YTzDAHadI8I6",
        "colab_type": "code",
        "outputId": "61fbb011-a8dc-424c-9e48-534918ed3daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# ROC scores on Test set for different codes\n",
        "scores=[]\n",
        "for i in range(396):\n",
        "  score = roc_auc_score(y_test[:,i], pred_test[:,i])\n",
        "  scores.append(score)\n",
        "  #print(\"score for index %s is %d\" (i,score))\n",
        "\n",
        "low = list(np.argsort(scores)[:5])\n",
        "high = list(np.argsort(scores)[::-1][:250])\n",
        "print('high scores is {}'.format(np.mean([scores[i] for i in high])))\n",
        "print('low scores is {}'.format(np.mean([scores[i] for i in low])))\n",
        "# ROC is not a problem in multi-class prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "high scores is 0.9976635485766142\n",
            "low scores is 0.8496196545022776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cbDZj9NXtenR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving predictions for error analysis\n",
        "os.mkdir('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen7_350_icd/run1_kfold_73.4/')\n",
        "os.chdir('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen7_350_icd/run1_kfold_73.4')\n",
        "\n",
        "itoicd = dict((v,k) for k,v in icd_dict.items())\n",
        "test_pred = np.argmax(pred_test, axis=1)\n",
        "test_act = np.argmax(y_test, axis=1) \n",
        "mdf = pd.DataFrame({'test_act':[itoicd[i] for i in list(test_act)],'test_pred':[itoicd[i] for i in list(test_pred)]})\n",
        "mdf.to_csv('pred_test.csv',index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_weiorJZVhZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Top Codes with low accuracy on test set\n",
        "#pred_test\n",
        "acc = [len(mdf[(mdf['test_pred']==i) & (mdf['test_act']==i)])/len(mdf[mdf['test_act']==i]) for i in mdf['test_act'].values]\n",
        "mdf2 = pd.DataFrame({'class_index': mdf['test_act'].values,'accuracy':acc})\n",
        "#print(len(mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()))\n",
        "codes= mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()\n",
        "mdf2.to_csv('error_codes.csv', index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsS4MwoqOvLK",
        "colab_type": "code",
        "outputId": "522d33cf-8fa4-424d-f265-e08804554fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy on various condifence levels and sample coverage on Test set\n",
        "test_pred = np.argmax(pred_test, axis=1)\n",
        "test_pred_proba = np.max(pred_test,axis=1)\n",
        "mdf3 = pd.DataFrame({'test_act':list(test_act),'test_pred':list(test_pred), 'prob': list(test_pred_proba)})\n",
        "#del CUTOFF\n",
        "for CUTOFF in range(0,100,5):\n",
        "    acc = len(mdf3[(mdf3['prob']>CUTOFF/100) & (mdf3['test_act']==mdf3['test_pred'])])/len(mdf3[(mdf3['prob']>CUTOFF/100)])\n",
        "    cov = len(mdf3[(mdf3['prob']>CUTOFF/100)])/len(mdf3)\n",
        "    print(\"Confidence: %f ## Accuracy: %f ## Coverage on Test dataset: %f\" % (CUTOFF/100,acc,cov))\n",
        "    #print(\"coverage with this accuracy level on Test dataset is {}\".format(cov))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence: 0.000000 ## Accuracy: 0.734694 ## Coverage on Test dataset: 1.000000\n",
            "Confidence: 0.050000 ## Accuracy: 0.748106 ## Coverage on Test dataset: 0.981840\n",
            "Confidence: 0.100000 ## Accuracy: 0.754626 ## Coverage on Test dataset: 0.971982\n",
            "Confidence: 0.150000 ## Accuracy: 0.764270 ## Coverage on Test dataset: 0.957454\n",
            "Confidence: 0.200000 ## Accuracy: 0.773353 ## Coverage on Test dataset: 0.942407\n",
            "Confidence: 0.250000 ## Accuracy: 0.783007 ## Coverage on Test dataset: 0.926150\n",
            "Confidence: 0.300000 ## Accuracy: 0.793064 ## Coverage on Test dataset: 0.907644\n",
            "Confidence: 0.350000 ## Accuracy: 0.806856 ## Coverage on Test dataset: 0.882912\n",
            "Confidence: 0.400000 ## Accuracy: 0.820198 ## Coverage on Test dataset: 0.858008\n",
            "Confidence: 0.450000 ## Accuracy: 0.837059 ## Coverage on Test dataset: 0.827914\n",
            "Confidence: 0.500000 ## Accuracy: 0.849130 ## Coverage on Test dataset: 0.795572\n",
            "Confidence: 0.550000 ## Accuracy: 0.862754 ## Coverage on Test dataset: 0.766171\n",
            "Confidence: 0.600000 ## Accuracy: 0.873329 ## Coverage on Test dataset: 0.737288\n",
            "Confidence: 0.650000 ## Accuracy: 0.884871 ## Coverage on Test dataset: 0.703044\n",
            "Confidence: 0.700000 ## Accuracy: 0.897390 ## Coverage on Test dataset: 0.669146\n",
            "Confidence: 0.750000 ## Accuracy: 0.905460 ## Coverage on Test dataset: 0.636631\n",
            "Confidence: 0.800000 ## Accuracy: 0.916136 ## Coverage on Test dataset: 0.598063\n",
            "Confidence: 0.850000 ## Accuracy: 0.932385 ## Coverage on Test dataset: 0.547388\n",
            "Confidence: 0.900000 ## Accuracy: 0.948573 ## Coverage on Test dataset: 0.491007\n",
            "Confidence: 0.950000 ## Accuracy: 0.963701 ## Coverage on Test dataset: 0.390695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dVM2EqgpX0Lr",
        "colab_type": "code",
        "outputId": "a114457a-b618-4894-cd1d-3de58bc6d817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "# Steps- for re generating the Data for modeling\n",
        "\n",
        "#datasize for icd codes\n",
        "\n",
        "strain = np.argmax(np.vstack([y_train,y_test]), axis=1)\n",
        "codesize = [sum(strain==icd_dict[i]) for i in codes]\n",
        "#print(len([i for i in codesize if i < 30]))\n",
        "codesize2 = [sum(strain==icd_dict[i]) for i in (set([itoicd[i] for i in set(strain)])-set(codes))]\n",
        "#print(len([i for i in codesize2 if i < 30]))\n",
        "\n",
        "print(\"mean dataset size of error codes is %d\" % (np.mean(codesize)))\n",
        "print(\"mean  dataset size of non-error codes is %d\" % (np.mean(codesize2)))\n",
        "print(\"median dataset size of error codes is %d\" % (np.median(codesize)))\n",
        "print(\"median  dataset size of non-error codes is %d\" % (np.median(codesize2)))\n",
        "\n",
        "# word entropy for icd codes\n",
        "\n",
        "idx = [[j for j in range(len(strain)) if strain[j]==icd_dict[i]] for i in codes]\n",
        "idx2 = [[j for j in range(len(strain)) if strain[j]==icd_dict[i]] for i in (set([itoicd[i] for i in set(strain)])-set(codes))]\n",
        "x = np.vstack([x_train, x_test])\n",
        "word_ent = [len(set([j for i in [[list(x[i]) for i in p] for p in idx][p] for j in i])) for p in range(len([[list(x[i]) for i in p] for p in idx]))]\n",
        "word_ent2 = [len(set([j for i in [[list(x[i]) for i in p] for p in idx2][p] for j in i])) for p in range(len([[list(x[i]) for i in p] for p in idx2]))]\n",
        "\n",
        "print(\"#################################################\")\n",
        "print(\"mean # of unqiue words in error codes is %d\" % (np.mean(word_ent)))\n",
        "print(\"mean # of unqiue words in non-error codes is %d\" % (np.mean(word_ent2)))\n",
        "print(\"median # of unqiue words in error codes is %d\" % (np.median(word_ent)))\n",
        "print(\"median # of unqiue words in non-error codes is %d\" % (np.median(word_ent2)))\n",
        "\n",
        "\n",
        "#codesize\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean dataset size of error codes is 70\n",
            "mean  dataset size of non-error codes is 193\n",
            "median dataset size of error codes is 50\n",
            "median  dataset size of non-error codes is 104\n",
            "#################################################\n",
            "mean # of unqiue words in error codes is 76\n",
            "mean # of unqiue words in non-error codes is 109\n",
            "median # of unqiue words in error codes is 58\n",
            "median # of unqiue words in non-error codes is 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vvc7MWcyLwue",
        "colab_type": "code",
        "outputId": "b6a11cfa-1eb7-4c6e-f697-612db5396f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Saving Model\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_v1.0.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_v1.0.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n",
        "# later..."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cj0mhWJ0Qg2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model_v1.0.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_v1.0.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "score = np.argmax(loaded_model.predict(DATASET, batch_size = 16, verbose = 1), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}