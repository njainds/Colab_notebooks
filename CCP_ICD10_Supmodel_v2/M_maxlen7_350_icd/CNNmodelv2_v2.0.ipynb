{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/CCP_ICD10_Supmodel_v2/M_maxlen7_350_icd/CNNmodelv2_v2.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QYpecTXf_H6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Builf train and evaluate\n",
        "# Save model for offline scoring on test\n",
        "# Model name: CCP_ICD10_Searchengine/CNNmodel_v1.0.ipynb\n",
        "# References\n",
        "#https://github.com/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments/Model-2-keras_lstmConv.ipynb\n",
        "#https://github.com/njainds/NLP/blob/master/kaggle/QIQC/22nd%20Place%20Solution%20-%206%20models%20%2B%20POS%20tagging.ipynb\n",
        "#https://github.com/Cheneng/DPCNN/blob/master/model/DPCNN.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AL5rrZqLghp",
        "colab_type": "code",
        "outputId": "5ed317f3-e300-4df5-d210-cad44822c678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0zRdXN9yo6k3",
        "colab_type": "code",
        "outputId": "7b97f6ba-818f-46f7-8571-5a7932ccdb89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import callbacks\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NhSwmpxVpCSx",
        "colab_type": "code",
        "outputId": "0dfaeb30-304e-4454-a9f5-282ff769b6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#!ls \"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2\"\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/d_maxlen7_350_icd\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OiHWhcY9SszU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"train_X.npy\")\n",
        "x_test = np.load(\"test_X.npy\")\n",
        "y_train = np.load(\"train_y.npy\")\n",
        "y_test = np.load(\"test_y.npy\")\n",
        "features = np.load(\"test_y.npy\")\n",
        "icd_dict = np.load(\"icd_dict.npy\").item()\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "embeddings = np.load(\"embedding_matrix.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nTOOQtvDHeZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=4590., mode='triangular',gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "    \n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size,\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwjoGzOR3m9H",
        "colab_type": "code",
        "outputId": "d3d26af0-dad4-4f03-f4a3-ae2d3cddb7ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "#del check_point, ra_val, early_stop\n",
        "!rm ./best_model.hdf5\n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(x_test, y_test), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove './best_model.hdf5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D5xLwVe9Bw91",
        "colab_type": "code",
        "outputId": "c1eb8d38-24bd-4088-8947-2da25990b366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen7_350_icd\")\n",
        "max_features = embeddings.shape[0]\n",
        "maxlen = x_train.shape[1]\n",
        "embed_size = embeddings.shape[1]\n",
        "n_class = y_train.shape[1]\n",
        "print(max_features,maxlen, embed_size, n_class)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13735 7 200 350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lXiTe8F678Kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    keras.backend.clear_session()\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x   = Embedding(max_features, embed_size, weights=[embeddings], trainable=True)(inp)\n",
        "    x   = SpatialDropout1D(rate=0.2)(x)\n",
        "    x1  = Conv1D(128, kernel_size=1, padding='valid', kernel_initializer='he_uniform', activation = 'relu')(x)\n",
        "    x2  = Conv1D(128, kernel_size=2, padding='valid', kernel_initializer='he_uniform', activation = 'relu')(x)\n",
        "    x3  = Conv1D(128, kernel_size=3, padding='valid', kernel_initializer='he_uniform', activation = 'relu')(x)\n",
        "    x4  = Conv1D(128, kernel_size=4, padding='valid', kernel_initializer='he_uniform', activation = 'relu')(x)\n",
        "    x5  = Conv1D(128, kernel_size=5, padding='valid', kernel_initializer='he_uniform', activation = 'relu')(x)\n",
        "    \n",
        "    x1  = GlobalMaxPooling1D()(x1)\n",
        "    x2  = GlobalMaxPooling1D()(x2)\n",
        "    x3  = GlobalMaxPooling1D()(x3)\n",
        "    x4  = GlobalMaxPooling1D()(x4)\n",
        "    x5  = GlobalMaxPooling1D()(x5)\n",
        "    c   = concatenate([x1,x2,x3,x4,x5])\n",
        "    y   = Dense(512, activation='relu')(c)\n",
        "    y   = Dropout(0.2)(y)\n",
        "    out = Dense(n_class, activation='softmax')(y)\n",
        "    model=Model(inputs=inp,outputs=out)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=[\"accuracy\"])\n",
        "    return model\n",
        "#print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Rej4RS8O1JF",
        "colab_type": "code",
        "outputId": "f4cbbbc7-26c9-4177-8442-f23d60ee12ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9858
        }
      },
      "cell_type": "code",
      "source": [
        "# Kfold training of model\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=8, random_state=2019, shuffle=True)\n",
        "pred_test = np.zeros((x_test.shape[0], n_class))\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kfold.split(x_train, np.argmax(y_train, axis=1))):\n",
        "    X_train, X_val, Y_train, Y_val = x_train[train_index], x_train[valid_index], y_train[train_index], y_train[valid_index]\n",
        "    \n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "    ra_val = RocAucEvaluation(validation_data=(X_val, Y_val), interval = 1)\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
        "    \n",
        "    model = get_model()\n",
        "    \n",
        "    print(\"### Model with seed: {}  for fold no. {} ####\".format( 2019, i))\n",
        "    \n",
        "    clr = CyclicLR(base_lr=1e-6, max_lr=5e-4,step_size=10840., mode='exp_range',gamma=0.99994)\n",
        "    model.fit(X_train, Y_train, batch_size = 24, epochs = 10, validation_data = (X_val, Y_val), verbose = 1, callbacks = [clr, ra_val, check_point, early_stop])\n",
        "    \n",
        "    pred_train = model.predict([X_val], batch_size=24, verbose=2)\n",
        "    pred_test += model.predict([x_test], batch_size=16, verbose=1)/8\n",
        "    os.remove(file_path)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "### Model with seed: 2019  for fold no. 0 ####\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 45382 samples, validate on 6651 samples\n",
            "Epoch 1/10\n",
            "45382/45382 [==============================] - 34s 755us/step - loss: 4.9669 - acc: 0.1274 - val_loss: 3.7932 - val_acc: 0.2953\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.891598\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.79322, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45382/45382 [==============================] - 31s 677us/step - loss: 3.0036 - acc: 0.3980 - val_loss: 2.2275 - val_acc: 0.5223\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.970786\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.79322 to 2.22753, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45382/45382 [==============================] - 31s 678us/step - loss: 2.0341 - acc: 0.5487 - val_loss: 1.6996 - val_acc: 0.6160\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.980661\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.22753 to 1.69958, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45382/45382 [==============================] - 31s 674us/step - loss: 1.6238 - acc: 0.6271 - val_loss: 1.4679 - val_acc: 0.6697\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.984448\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.69958 to 1.46794, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45382/45382 [==============================] - 31s 673us/step - loss: 1.3823 - acc: 0.6824 - val_loss: 1.3640 - val_acc: 0.6951\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.985645\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.46794 to 1.36404, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45382/45382 [==============================] - 30s 670us/step - loss: 1.2181 - acc: 0.7125 - val_loss: 1.2945 - val_acc: 0.7131\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.986663\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.36404 to 1.29451, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45382/45382 [==============================] - 30s 668us/step - loss: 1.0758 - acc: 0.7412 - val_loss: 1.2558 - val_acc: 0.7221\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.987178\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.29451 to 1.25584, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45382/45382 [==============================] - 30s 671us/step - loss: 0.9679 - acc: 0.7640 - val_loss: 1.2354 - val_acc: 0.7297\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.987423\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.25584 to 1.23537, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45382/45382 [==============================] - 30s 666us/step - loss: 0.8832 - acc: 0.7820 - val_loss: 1.2286 - val_acc: 0.7333\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.987444\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.23537 to 1.22855, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45382/45382 [==============================] - 30s 665us/step - loss: 0.8243 - acc: 0.7950 - val_loss: 1.2210 - val_acc: 0.7342\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.987654\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.22855 to 1.22102, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 154us/step\n",
            "### Model with seed: 2019  for fold no. 1 ####\n",
            "Train on 45431 samples, validate on 6602 samples\n",
            "Epoch 1/10\n",
            "45431/45431 [==============================] - 31s 686us/step - loss: 4.9915 - acc: 0.1273 - val_loss: 3.8044 - val_acc: 0.3042\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.896664\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.80439, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45431/45431 [==============================] - 31s 673us/step - loss: 3.0060 - acc: 0.3981 - val_loss: 2.2268 - val_acc: 0.5127\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.973808\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.80439 to 2.22681, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45431/45431 [==============================] - 30s 667us/step - loss: 2.0423 - acc: 0.5489 - val_loss: 1.6784 - val_acc: 0.6307\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.982948\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.22681 to 1.67841, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45431/45431 [==============================] - 30s 669us/step - loss: 1.6275 - acc: 0.6279 - val_loss: 1.4721 - val_acc: 0.6666\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.986132\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.67841 to 1.47213, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45431/45431 [==============================] - 30s 668us/step - loss: 1.3943 - acc: 0.6776 - val_loss: 1.3406 - val_acc: 0.6981\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.987698\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.47213 to 1.34055, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45431/45431 [==============================] - 30s 666us/step - loss: 1.2299 - acc: 0.7102 - val_loss: 1.2697 - val_acc: 0.7168\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.988371\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.34055 to 1.26974, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45431/45431 [==============================] - 30s 666us/step - loss: 1.0836 - acc: 0.7421 - val_loss: 1.2129 - val_acc: 0.7280\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.989113\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.26974 to 1.21290, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45431/45431 [==============================] - 30s 667us/step - loss: 0.9708 - acc: 0.7631 - val_loss: 1.1927 - val_acc: 0.7317\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.989309\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.21290 to 1.19275, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45431/45431 [==============================] - 30s 666us/step - loss: 0.8871 - acc: 0.7809 - val_loss: 1.1850 - val_acc: 0.7361\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.989452\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.19275 to 1.18500, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45431/45431 [==============================] - 30s 664us/step - loss: 0.8312 - acc: 0.7928 - val_loss: 1.1781 - val_acc: 0.7384\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.989549\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.18500 to 1.17814, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 149us/step\n",
            "### Model with seed: 2019  for fold no. 2 ####\n",
            "Train on 45467 samples, validate on 6566 samples\n",
            "Epoch 1/10\n",
            "45467/45467 [==============================] - 31s 690us/step - loss: 4.9774 - acc: 0.1253 - val_loss: 3.7989 - val_acc: 0.2990\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.895209\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.79893, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45467/45467 [==============================] - 31s 676us/step - loss: 3.0364 - acc: 0.3946 - val_loss: 2.2224 - val_acc: 0.5236\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.970580\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.79893 to 2.22241, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45467/45467 [==============================] - 31s 673us/step - loss: 2.0457 - acc: 0.5460 - val_loss: 1.6815 - val_acc: 0.6261\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.981954\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.22241 to 1.68151, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45467/45467 [==============================] - 31s 672us/step - loss: 1.6245 - acc: 0.6294 - val_loss: 1.4816 - val_acc: 0.6683\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.984656\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.68151 to 1.48158, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45467/45467 [==============================] - 30s 671us/step - loss: 1.3902 - acc: 0.6792 - val_loss: 1.3517 - val_acc: 0.6890\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.986029\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.48158 to 1.35172, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45467/45467 [==============================] - 30s 665us/step - loss: 1.2224 - acc: 0.7137 - val_loss: 1.2763 - val_acc: 0.7134\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.987153\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.35172 to 1.27634, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45467/45467 [==============================] - 30s 665us/step - loss: 1.0797 - acc: 0.7416 - val_loss: 1.2484 - val_acc: 0.7237\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.987400\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.27634 to 1.24836, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45467/45467 [==============================] - 30s 666us/step - loss: 0.9672 - acc: 0.7648 - val_loss: 1.2110 - val_acc: 0.7323\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.987752\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.24836 to 1.21098, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45467/45467 [==============================] - 30s 663us/step - loss: 0.8892 - acc: 0.7793 - val_loss: 1.2046 - val_acc: 0.7323\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.987817\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.21098 to 1.20456, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45467/45467 [==============================] - 30s 666us/step - loss: 0.8321 - acc: 0.7917 - val_loss: 1.1991 - val_acc: 0.7373\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.987793\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.20456 to 1.19906, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 150us/step\n",
            "### Model with seed: 2019  for fold no. 3 ####\n",
            "Train on 45510 samples, validate on 6523 samples\n",
            "Epoch 1/10\n",
            "45510/45510 [==============================] - 31s 678us/step - loss: 4.9487 - acc: 0.1348 - val_loss: 3.7495 - val_acc: 0.3019\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.896053\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.74953, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45510/45510 [==============================] - 30s 670us/step - loss: 2.9827 - acc: 0.4020 - val_loss: 2.2137 - val_acc: 0.5208\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.972064\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.74953 to 2.21367, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45510/45510 [==============================] - 30s 667us/step - loss: 2.0233 - acc: 0.5492 - val_loss: 1.6940 - val_acc: 0.6241\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.980778\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.21367 to 1.69396, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45510/45510 [==============================] - 30s 667us/step - loss: 1.6075 - acc: 0.6321 - val_loss: 1.4794 - val_acc: 0.6721\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.983906\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.69396 to 1.47938, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45510/45510 [==============================] - 30s 666us/step - loss: 1.3794 - acc: 0.6806 - val_loss: 1.3773 - val_acc: 0.6909\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.985314\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.47938 to 1.37732, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45510/45510 [==============================] - 30s 665us/step - loss: 1.2149 - acc: 0.7146 - val_loss: 1.3046 - val_acc: 0.7124\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.986026\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.37732 to 1.30461, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45510/45510 [==============================] - 30s 666us/step - loss: 1.0746 - acc: 0.7415 - val_loss: 1.2648 - val_acc: 0.7241\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.986533\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.30461 to 1.26480, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45510/45510 [==============================] - 30s 664us/step - loss: 0.9543 - acc: 0.7672 - val_loss: 1.2573 - val_acc: 0.7290\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.986701\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.26480 to 1.25730, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45510/45510 [==============================] - 30s 670us/step - loss: 0.8789 - acc: 0.7822 - val_loss: 1.2426 - val_acc: 0.7316\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.986961\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.25730 to 1.24259, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45510/45510 [==============================] - 30s 666us/step - loss: 0.8199 - acc: 0.7946 - val_loss: 1.2407 - val_acc: 0.7348\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.987057\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.24259 to 1.24070, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 149us/step\n",
            "### Model with seed: 2019  for fold no. 4 ####\n",
            "Train on 45541 samples, validate on 6492 samples\n",
            "Epoch 1/10\n",
            "45541/45541 [==============================] - 31s 689us/step - loss: 5.0010 - acc: 0.1283 - val_loss: 3.8023 - val_acc: 0.2994\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.893145\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.80233, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45541/45541 [==============================] - 31s 670us/step - loss: 3.0477 - acc: 0.3934 - val_loss: 2.2372 - val_acc: 0.5294\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.973007\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.80233 to 2.23724, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45541/45541 [==============================] - 30s 664us/step - loss: 2.0588 - acc: 0.5414 - val_loss: 1.7048 - val_acc: 0.6269\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.982418\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.23724 to 1.70480, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45541/45541 [==============================] - 30s 665us/step - loss: 1.6297 - acc: 0.6303 - val_loss: 1.4639 - val_acc: 0.6722\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.985405\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.70480 to 1.46391, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45541/45541 [==============================] - 30s 665us/step - loss: 1.3864 - acc: 0.6814 - val_loss: 1.3855 - val_acc: 0.6896\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.986912\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.46391 to 1.38546, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45541/45541 [==============================] - 30s 663us/step - loss: 1.2230 - acc: 0.7127 - val_loss: 1.3097 - val_acc: 0.7050\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.987503\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.38546 to 1.30970, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45541/45541 [==============================] - 30s 660us/step - loss: 1.0721 - acc: 0.7428 - val_loss: 1.2696 - val_acc: 0.7160\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.988077\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.30970 to 1.26964, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45541/45541 [==============================] - 30s 667us/step - loss: 0.9637 - acc: 0.7639 - val_loss: 1.2499 - val_acc: 0.7187\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.988510\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.26964 to 1.24989, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45541/45541 [==============================] - 30s 663us/step - loss: 0.8815 - acc: 0.7821 - val_loss: 1.2354 - val_acc: 0.7227\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.988721\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.24989 to 1.23540, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45541/45541 [==============================] - 30s 661us/step - loss: 0.8258 - acc: 0.7953 - val_loss: 1.2339 - val_acc: 0.7235\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.988676\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.23540 to 1.23392, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 153us/step\n",
            "### Model with seed: 2019  for fold no. 5 ####\n",
            "Train on 45590 samples, validate on 6443 samples\n",
            "Epoch 1/10\n",
            "45590/45590 [==============================] - 31s 670us/step - loss: 4.9491 - acc: 0.1321 - val_loss: 3.7026 - val_acc: 0.3112\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.907606\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.70256, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45590/45590 [==============================] - 30s 658us/step - loss: 2.9790 - acc: 0.4021 - val_loss: 2.1547 - val_acc: 0.5387\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.973256\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.70256 to 2.15472, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45590/45590 [==============================] - 30s 657us/step - loss: 2.0358 - acc: 0.5497 - val_loss: 1.6259 - val_acc: 0.6415\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.981413\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.15472 to 1.62590, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45590/45590 [==============================] - 30s 656us/step - loss: 1.6233 - acc: 0.6287 - val_loss: 1.4308 - val_acc: 0.6759\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.984409\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.62590 to 1.43080, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45590/45590 [==============================] - 30s 654us/step - loss: 1.3882 - acc: 0.6796 - val_loss: 1.3087 - val_acc: 0.7028\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.986332\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.43080 to 1.30868, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45590/45590 [==============================] - 30s 653us/step - loss: 1.2243 - acc: 0.7150 - val_loss: 1.2442 - val_acc: 0.7153\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.987063\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.30868 to 1.24417, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45590/45590 [==============================] - 30s 654us/step - loss: 1.0773 - acc: 0.7413 - val_loss: 1.1999 - val_acc: 0.7287\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.987974\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.24417 to 1.19988, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45590/45590 [==============================] - 30s 656us/step - loss: 0.9671 - acc: 0.7641 - val_loss: 1.1794 - val_acc: 0.7344\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.988275\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.19988 to 1.17942, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45590/45590 [==============================] - 30s 652us/step - loss: 0.8868 - acc: 0.7805 - val_loss: 1.1762 - val_acc: 0.7368\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.988305\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.17942 to 1.17624, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45590/45590 [==============================] - 30s 649us/step - loss: 0.8307 - acc: 0.7941 - val_loss: 1.1682 - val_acc: 0.7361\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.988307\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.17624 to 1.16816, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 147us/step\n",
            "### Model with seed: 2019  for fold no. 6 ####\n",
            "Train on 45632 samples, validate on 6401 samples\n",
            "Epoch 1/10\n",
            "45632/45632 [==============================] - 31s 669us/step - loss: 4.9905 - acc: 0.1266 - val_loss: 3.7692 - val_acc: 0.3015\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.891166\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.76923, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45632/45632 [==============================] - 30s 655us/step - loss: 3.0072 - acc: 0.3985 - val_loss: 2.2471 - val_acc: 0.5243\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.969062\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.76923 to 2.24706, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45632/45632 [==============================] - 30s 653us/step - loss: 2.0142 - acc: 0.5552 - val_loss: 1.7432 - val_acc: 0.6191\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.980332\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.24706 to 1.74317, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45632/45632 [==============================] - 30s 651us/step - loss: 1.6046 - acc: 0.6318 - val_loss: 1.5324 - val_acc: 0.6629\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.983143\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.74317 to 1.53237, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45632/45632 [==============================] - 30s 651us/step - loss: 1.3719 - acc: 0.6829 - val_loss: 1.4376 - val_acc: 0.6738\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.985158\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.53237 to 1.43764, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45632/45632 [==============================] - 30s 653us/step - loss: 1.2075 - acc: 0.7162 - val_loss: 1.3539 - val_acc: 0.6977\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.986129\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.43764 to 1.35390, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45632/45632 [==============================] - 30s 655us/step - loss: 1.0633 - acc: 0.7460 - val_loss: 1.3099 - val_acc: 0.7122\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.986559\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.35390 to 1.30994, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45632/45632 [==============================] - 30s 651us/step - loss: 0.9495 - acc: 0.7696 - val_loss: 1.2904 - val_acc: 0.7116\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.986858\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.30994 to 1.29038, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45632/45632 [==============================] - 30s 654us/step - loss: 0.8755 - acc: 0.7829 - val_loss: 1.2770 - val_acc: 0.7199\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.986997\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.29038 to 1.27696, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45632/45632 [==============================] - 30s 652us/step - loss: 0.8171 - acc: 0.7966 - val_loss: 1.2754 - val_acc: 0.7224\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.987010\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.27696 to 1.27545, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 1s 146us/step\n",
            "### Model with seed: 2019  for fold no. 7 ####\n",
            "Train on 45678 samples, validate on 6355 samples\n",
            "Epoch 1/10\n",
            "45678/45678 [==============================] - 30s 658us/step - loss: 4.9622 - acc: 0.1333 - val_loss: 3.6763 - val_acc: 0.3235\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.901945\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.67630, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45678/45678 [==============================] - 30s 648us/step - loss: 2.9798 - acc: 0.4024 - val_loss: 2.1448 - val_acc: 0.5457\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.971652\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.67630 to 2.14482, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45678/45678 [==============================] - 30s 646us/step - loss: 2.0290 - acc: 0.5491 - val_loss: 1.6394 - val_acc: 0.6348\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.980457\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.14482 to 1.63942, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45678/45678 [==============================] - 29s 646us/step - loss: 1.6087 - acc: 0.6321 - val_loss: 1.4528 - val_acc: 0.6788\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.983596\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.63942 to 1.45275, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45678/45678 [==============================] - 30s 647us/step - loss: 1.3782 - acc: 0.6814 - val_loss: 1.3501 - val_acc: 0.6991\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.985262\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.45275 to 1.35005, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45678/45678 [==============================] - 29s 643us/step - loss: 1.2181 - acc: 0.7128 - val_loss: 1.2803 - val_acc: 0.7172\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.986419\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.35005 to 1.28031, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45678/45678 [==============================] - 30s 646us/step - loss: 1.0743 - acc: 0.7444 - val_loss: 1.2423 - val_acc: 0.7213\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.986759\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.28031 to 1.24228, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45678/45678 [==============================] - 29s 645us/step - loss: 0.9573 - acc: 0.7667 - val_loss: 1.2224 - val_acc: 0.7257\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.987047\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.24228 to 1.22243, saving model to best_model.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3dce55b987ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mclr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCyclicLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10840.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'exp_range'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99994\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mra_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'best_model.hdf5', errno = 5, error message = 'Input/output error', flags = 13, o_flags = 242)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "iVCbgUPfKL5b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_test=pred_test*8/7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YTzDAHadI8I6",
        "colab_type": "code",
        "outputId": "61fbb011-a8dc-424c-9e48-534918ed3daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# ROC scores on Test set for different codes\n",
        "scores=[]\n",
        "for i in range(396):\n",
        "  score = roc_auc_score(y_test[:,i], pred_test[:,i])\n",
        "  scores.append(score)\n",
        "  #print(\"score for index %s is %d\" (i,score))\n",
        "\n",
        "low = list(np.argsort(scores)[:5])\n",
        "high = list(np.argsort(scores)[::-1][:250])\n",
        "print('high scores is {}'.format(np.mean([scores[i] for i in high])))\n",
        "print('low scores is {}'.format(np.mean([scores[i] for i in low])))\n",
        "# ROC is not a problem in multi-class prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "high scores is 0.9976635485766142\n",
            "low scores is 0.8496196545022776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cbDZj9NXtenR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving predictions for error analysis\n",
        "#os.mkdir('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen7_350_icd/run1_kfold_73.5/')\n",
        "#os.chdir('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen7_350_icd/run1_kfold_73.5')\n",
        "\n",
        "itoicd = dict((v,k) for k,v in icd_dict.items())\n",
        "test_pred = np.argmax(pred_test, axis=1)\n",
        "test_act = np.argmax(y_test, axis=1) \n",
        "mdf = pd.DataFrame({'test_act':[itoicd[i] for i in list(test_act)],'test_pred':[itoicd[i] for i in list(test_pred)]})\n",
        "mdf.to_csv('pred_test.csv',index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_weiorJZVhZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Top Codes with low accuracy on test set\n",
        "#pred_test\n",
        "acc = [len(mdf[(mdf['test_pred']==i) & (mdf['test_act']==i)])/len(mdf[mdf['test_act']==i]) for i in mdf['test_act'].values]\n",
        "mdf2 = pd.DataFrame({'class_index': mdf['test_act'].values,'accuracy':acc})\n",
        "#print(len(mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()))\n",
        "codes= mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()\n",
        "mdf2.to_csv('error_codes.csv', index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsS4MwoqOvLK",
        "colab_type": "code",
        "outputId": "9b2747ef-e6df-491a-c142-f1af0e384d38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy on various condifence levels and sample coverage on Test set\n",
        "test_pred = np.argmax(pred_test, axis=1)\n",
        "test_pred_proba = np.max(pred_test,axis=1)\n",
        "mdf3 = pd.DataFrame({'test_act':list(test_act),'test_pred':list(test_pred), 'prob': list(test_pred_proba)})\n",
        "#del CUTOFF\n",
        "for CUTOFF in range(0,100,5):\n",
        "    acc = len(mdf3[(mdf3['prob']>CUTOFF/100) & (mdf3['test_act']==mdf3['test_pred'])])/len(mdf3[(mdf3['prob']>CUTOFF/100)])\n",
        "    cov = len(mdf3[(mdf3['prob']>CUTOFF/100)])/len(mdf3)\n",
        "    print(\"Confidence: %f ## Accuracy: %f ## Coverage on Test dataset: %f\" % (CUTOFF/100,acc,cov))\n",
        "    #print(\"coverage with this accuracy level on Test dataset is {}\".format(cov))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence: 0.000000 ## Accuracy: 0.735732 ## Coverage on Test dataset: 1.000000\n",
            "Confidence: 0.050000 ## Accuracy: 0.749647 ## Coverage on Test dataset: 0.980975\n",
            "Confidence: 0.100000 ## Accuracy: 0.757944 ## Coverage on Test dataset: 0.968869\n",
            "Confidence: 0.150000 ## Accuracy: 0.767935 ## Coverage on Test dataset: 0.954687\n",
            "Confidence: 0.200000 ## Accuracy: 0.777962 ## Coverage on Test dataset: 0.938603\n",
            "Confidence: 0.250000 ## Accuracy: 0.786544 ## Coverage on Test dataset: 0.922864\n",
            "Confidence: 0.300000 ## Accuracy: 0.800807 ## Coverage on Test dataset: 0.900380\n",
            "Confidence: 0.350000 ## Accuracy: 0.814018 ## Coverage on Test dataset: 0.875994\n",
            "Confidence: 0.400000 ## Accuracy: 0.825751 ## Coverage on Test dataset: 0.851608\n",
            "Confidence: 0.450000 ## Accuracy: 0.838466 ## Coverage on Test dataset: 0.825493\n",
            "Confidence: 0.500000 ## Accuracy: 0.851143 ## Coverage on Test dataset: 0.794708\n",
            "Confidence: 0.550000 ## Accuracy: 0.865276 ## Coverage on Test dataset: 0.762539\n",
            "Confidence: 0.600000 ## Accuracy: 0.874585 ## Coverage on Test dataset: 0.729505\n",
            "Confidence: 0.650000 ## Accuracy: 0.888307 ## Coverage on Test dataset: 0.693705\n",
            "Confidence: 0.700000 ## Accuracy: 0.897938 ## Coverage on Test dataset: 0.662574\n",
            "Confidence: 0.750000 ## Accuracy: 0.909465 ## Coverage on Test dataset: 0.630405\n",
            "Confidence: 0.800000 ## Accuracy: 0.920328 ## Coverage on Test dataset: 0.590453\n",
            "Confidence: 0.850000 ## Accuracy: 0.930344 ## Coverage on Test dataset: 0.543756\n",
            "Confidence: 0.900000 ## Accuracy: 0.949013 ## Coverage on Test dataset: 0.481667\n",
            "Confidence: 0.950000 ## Accuracy: 0.964936 ## Coverage on Test dataset: 0.379799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dVM2EqgpX0Lr",
        "colab_type": "code",
        "outputId": "a114457a-b618-4894-cd1d-3de58bc6d817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "# Steps- for re generating the Data for modeling\n",
        "\n",
        "#datasize for icd codes\n",
        "\n",
        "strain = np.argmax(np.vstack([y_train,y_test]), axis=1)\n",
        "codesize = [sum(strain==icd_dict[i]) for i in codes]\n",
        "#print(len([i for i in codesize if i < 30]))\n",
        "codesize2 = [sum(strain==icd_dict[i]) for i in (set([itoicd[i] for i in set(strain)])-set(codes))]\n",
        "#print(len([i for i in codesize2 if i < 30]))\n",
        "\n",
        "print(\"mean dataset size of error codes is %d\" % (np.mean(codesize)))\n",
        "print(\"mean  dataset size of non-error codes is %d\" % (np.mean(codesize2)))\n",
        "print(\"median dataset size of error codes is %d\" % (np.median(codesize)))\n",
        "print(\"median  dataset size of non-error codes is %d\" % (np.median(codesize2)))\n",
        "\n",
        "# word entropy for icd codes\n",
        "\n",
        "idx = [[j for j in range(len(strain)) if strain[j]==icd_dict[i]] for i in codes]\n",
        "idx2 = [[j for j in range(len(strain)) if strain[j]==icd_dict[i]] for i in (set([itoicd[i] for i in set(strain)])-set(codes))]\n",
        "x = np.vstack([x_train, x_test])\n",
        "word_ent = [len(set([j for i in [[list(x[i]) for i in p] for p in idx][p] for j in i])) for p in range(len([[list(x[i]) for i in p] for p in idx]))]\n",
        "word_ent2 = [len(set([j for i in [[list(x[i]) for i in p] for p in idx2][p] for j in i])) for p in range(len([[list(x[i]) for i in p] for p in idx2]))]\n",
        "\n",
        "print(\"#################################################\")\n",
        "print(\"mean # of unqiue words in error codes is %d\" % (np.mean(word_ent)))\n",
        "print(\"mean # of unqiue words in non-error codes is %d\" % (np.mean(word_ent2)))\n",
        "print(\"median # of unqiue words in error codes is %d\" % (np.median(word_ent)))\n",
        "print(\"median # of unqiue words in non-error codes is %d\" % (np.median(word_ent2)))\n",
        "\n",
        "\n",
        "#codesize\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean dataset size of error codes is 70\n",
            "mean  dataset size of non-error codes is 193\n",
            "median dataset size of error codes is 50\n",
            "median  dataset size of non-error codes is 104\n",
            "#################################################\n",
            "mean # of unqiue words in error codes is 76\n",
            "mean # of unqiue words in non-error codes is 109\n",
            "median # of unqiue words in error codes is 58\n",
            "median # of unqiue words in non-error codes is 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vvc7MWcyLwue",
        "colab_type": "code",
        "outputId": "b6a11cfa-1eb7-4c6e-f697-612db5396f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Saving Model\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_v1.0.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_v1.0.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n",
        "# later..."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cj0mhWJ0Qg2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model_v1.0.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_v1.0.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "score = np.argmax(loaded_model.predict(DATASET, batch_size = 16, verbose = 1), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}