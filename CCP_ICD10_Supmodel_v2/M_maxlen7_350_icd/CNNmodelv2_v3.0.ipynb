{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/CCP_ICD10_Supmodel_v2/M_maxlen7_350_icd/CNNmodelv2_v3.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QYpecTXf_H6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Builf train and evaluate\n",
        "# Save model for offline scoring on test\n",
        "# Model name: CCP_ICD10_Searchengine/CNNmodel_v1.0.ipynb\n",
        "# References\n",
        "#https://github.com/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments/Model-2-keras_lstmConv.ipynb\n",
        "#https://github.com/njainds/NLP/blob/master/kaggle/QIQC/22nd%20Place%20Solution%20-%206%20models%20%2B%20POS%20tagging.ipynb\n",
        "#https://github.com/Cheneng/DPCNN/blob/master/model/DPCNN.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AL5rrZqLghp",
        "colab_type": "code",
        "outputId": "5ed317f3-e300-4df5-d210-cad44822c678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0zRdXN9yo6k3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import Input, Dense, Embedding, concatenate, CuDNNGRU, CuDNNLSTM, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, SpatialDropout1D, Flatten, Lambda, Permute, Reshape, merge, Dropout, Conv2D, MaxPool2D, Concatenate, Conv1D, MaxPool1D, add, MaxPooling1D\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D, Add\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import callbacks\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NhSwmpxVpCSx",
        "colab_type": "code",
        "outputId": "0dfaeb30-304e-4454-a9f5-282ff769b6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#!ls \"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2\"\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/d_maxlen7_350_icd\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OiHWhcY9SszU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"train_X.npy\")\n",
        "x_test = np.load(\"test_X.npy\")\n",
        "y_train = np.load(\"train_y.npy\")\n",
        "y_test = np.load(\"test_y.npy\")\n",
        "features = np.load(\"test_y.npy\")\n",
        "icd_dict = np.load(\"icd_dict.npy\").item()\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "embeddings = np.load(\"embedding_matrix.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nTOOQtvDHeZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=4590., mode='triangular',gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "    \n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size,\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwjoGzOR3m9H",
        "colab_type": "code",
        "outputId": "d3d26af0-dad4-4f03-f4a3-ae2d3cddb7ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "#del check_point, ra_val, early_stop\n",
        "!rm ./best_model.hdf5\n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(x_test, y_test), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove './best_model.hdf5': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D5xLwVe9Bw91",
        "colab_type": "code",
        "outputId": "c1eb8d38-24bd-4088-8947-2da25990b366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen7_350_icd\")\n",
        "max_features = embeddings.shape[0]\n",
        "maxlen = x_train.shape[1]\n",
        "embed_size = embeddings.shape[1]\n",
        "n_class = y_train.shape[1]\n",
        "print(max_features,maxlen, embed_size, n_class)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13735 7 200 350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i-tXdS0MM5aN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_dpcnn_model(num_block = 5, k = 3, units = 64):\n",
        "    pad = 'same'\n",
        "    keras.backend.clear_session()\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    embedding_layer1   = Embedding(max_features, embed_size, weights=[embeddings], trainable=True)(inp)\n",
        "    embedding_layer1 = SpatialDropout1D(0.3)(embedding_layer1)\n",
        "    emb_short_cut = Conv1D(units, kernel_size = 1, padding = pad, activation = 'relu')(embedding_layer1)\n",
        "    emb_short_cut = Conv1D(units, kernel_size = 1, padding = pad, activation = 'relu')(emb_short_cut)\n",
        "    # Main block\n",
        "    for b in range(1, num_block + 1):\n",
        "        if b == 1:\n",
        "            block = embedding_layer1\n",
        "            short_cut = emb_short_cut\n",
        "        else:\n",
        "            block = block\n",
        "            short_cut = block\n",
        "        block = Conv1D(units, kernel_size = k, padding = pad, activation = 'relu')(block)\n",
        "        block = Conv1D(units, kernel_size = k, padding = pad, activation = 'relu')(block)\n",
        "        block = add([short_cut, block])\n",
        "        block = MaxPooling1D(pool_size = 3, strides = 2, padding = pad)(block)\n",
        "    # Final block\n",
        "    short_cut = block\n",
        "    block = Conv1D(units, kernel_size = k, padding = pad, activation = 'relu')(block)\n",
        "    block = Conv1D(units, kernel_size = k, padding = pad, activation = 'relu')(block)\n",
        "    block = add([short_cut, block])\n",
        "    max_pool = GlobalMaxPooling1D()(block)\n",
        "    avg_pool = GlobalAveragePooling1D()(block)\n",
        "    last = (Lambda(lambda x: x[:,-1,:]) (block))\n",
        "    block = concatenate([max_pool, avg_pool, last])\n",
        "    #reverse\n",
        "    rev_embedding_layer = Lambda(lambda x: K.reverse(x,axes=-1))(embedding_layer1)\n",
        "    rev_emb_short_cut = Conv1D(units, kernel_size = 1, padding = pad, activation = 'relu')(rev_embedding_layer)\n",
        "    rev_emb_short_cut = Conv1D(units, kernel_size = 1, padding = pad, activation = 'relu')(rev_emb_short_cut)\n",
        "    # Main block\n",
        "    for b in range(1, num_block + 1):\n",
        "        if b == 1:\n",
        "            rev_block = rev_embedding_layer\n",
        "            rev_short_cut = rev_emb_short_cut\n",
        "        else:\n",
        "            rev_block = rev_block\n",
        "            rev_short_cut = rev_block\n",
        "        rev_block = Conv1D(units, kernel_size = k, padding = pad, activation = 'relu')(rev_block)\n",
        "        rev_block = Conv1D(units, kernel_size = k, padding = pad, activation = 'relu')(rev_block)\n",
        "        rev_block = add([rev_short_cut, rev_block])\n",
        "        rev_block = MaxPooling1D(pool_size = 3, strides = 2, padding = pad)(rev_block)\n",
        "    # Final block\n",
        "    rev_short_cut = rev_block\n",
        "    rev_block = Conv1D(units, kernel_size = k, padding = pad, activation = 'relu')(rev_block)\n",
        "    rev_block = Conv1D(units, kernel_size = k, padding = pad, activation = 'relu')(rev_block)\n",
        "    rev_block = add([rev_short_cut, rev_block])\n",
        "    rev_max_pool = GlobalMaxPooling1D()(rev_block)\n",
        "    rev_avg_pool = GlobalAveragePooling1D()(rev_block)\n",
        "    rev_last = (Lambda(lambda x: x[:,-1,:]) (rev_block))\n",
        "    rev_block = concatenate([rev_max_pool, rev_avg_pool, rev_last])\n",
        "    block = concatenate([rev_block, block])\n",
        "    # output block\n",
        "    out_put = Dense(64, activation = 'relu')(block)\n",
        "    outp = Dense(n_class, activation='softmax')(out_put)\n",
        "    model=Model(inputs=inp,outputs=outp)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Rej4RS8O1JF",
        "colab_type": "code",
        "outputId": "52c364b1-179d-4b0a-e261-6ed70f6072c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8484
        }
      },
      "cell_type": "code",
      "source": [
        "# Kfold training of model\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=8, random_state=2019, shuffle=True)\n",
        "pred_test = np.zeros((x_test.shape[0], n_class))\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kfold.split(x_train, np.argmax(y_train, axis=1))):\n",
        "    X_train, X_val, Y_train, Y_val = x_train[train_index], x_train[valid_index], y_train[train_index], y_train[valid_index]\n",
        "    \n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "    ra_val = RocAucEvaluation(validation_data=(X_val, Y_val), interval = 1)\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
        "    \n",
        "    model = build_dpcnn_model(num_block = 5, k = 3, units = 64)\n",
        "    \n",
        "    print(\"### Model with seed: {}  for fold no. {} ####\".format( 2019, i))\n",
        "    \n",
        "    clr = CyclicLR(base_lr=1e-6, max_lr=5e-4,step_size=10840., mode='exp_range',gamma=0.99994)\n",
        "    model.fit(X_train, Y_train, batch_size = 24, epochs = 10, validation_data = (X_val, Y_val), verbose = 1, callbacks = [clr, ra_val, check_point, early_stop])\n",
        "    \n",
        "    pred_train = model.predict([X_val], batch_size=24, verbose=2)\n",
        "    pred_test += model.predict([x_test], batch_size=16, verbose=1)/8\n",
        "    os.remove(file_path)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### Model with seed: 2019  for fold no. 0 ####\n",
            "Train on 45382 samples, validate on 6651 samples\n",
            "Epoch 1/10\n",
            "45382/45382 [==============================] - 59s 1ms/step - loss: 5.3935 - acc: 0.0741 - val_loss: 4.5238 - val_acc: 0.1890\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.741518\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.52376, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45382/45382 [==============================] - 58s 1ms/step - loss: 3.7147 - acc: 0.2923 - val_loss: 2.8981 - val_acc: 0.4120\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.925337\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.52376 to 2.89814, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45382/45382 [==============================] - 57s 1ms/step - loss: 2.6527 - acc: 0.4405 - val_loss: 2.2561 - val_acc: 0.5153\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.962174\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.89814 to 2.25612, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45382/45382 [==============================] - 56s 1ms/step - loss: 2.1514 - acc: 0.5276 - val_loss: 1.9227 - val_acc: 0.5810\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.973435\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.25612 to 1.92265, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45382/45382 [==============================] - 56s 1ms/step - loss: 1.8499 - acc: 0.5858 - val_loss: 1.6980 - val_acc: 0.6315\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.978727\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.92265 to 1.69804, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45382/45382 [==============================] - 56s 1ms/step - loss: 1.6355 - acc: 0.6303 - val_loss: 1.6050 - val_acc: 0.6498\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.980514\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.69804 to 1.60498, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45382/45382 [==============================] - 57s 1ms/step - loss: 1.4648 - acc: 0.6648 - val_loss: 1.5069 - val_acc: 0.6746\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.982072\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.60498 to 1.50687, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45382/45382 [==============================] - 56s 1ms/step - loss: 1.3347 - acc: 0.6910 - val_loss: 1.4435 - val_acc: 0.6901\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.982840\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.50687 to 1.44347, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45382/45382 [==============================] - 57s 1ms/step - loss: 1.2456 - acc: 0.7101 - val_loss: 1.4258 - val_acc: 0.6967\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.983577\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.44347 to 1.42578, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45382/45382 [==============================] - 56s 1ms/step - loss: 1.1760 - acc: 0.7277 - val_loss: 1.4004 - val_acc: 0.7008\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.983757\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.42578 to 1.40036, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 2s 270us/step\n",
            "### Model with seed: 2019  for fold no. 1 ####\n",
            "Train on 45431 samples, validate on 6602 samples\n",
            "Epoch 1/10\n",
            "45431/45431 [==============================] - 59s 1ms/step - loss: 5.3802 - acc: 0.0734 - val_loss: 4.5384 - val_acc: 0.1651\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.744161\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.53835, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45431/45431 [==============================] - 57s 1ms/step - loss: 3.6818 - acc: 0.2950 - val_loss: 2.8894 - val_acc: 0.4121\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.927852\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.53835 to 2.88942, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45431/45431 [==============================] - 56s 1ms/step - loss: 2.6108 - acc: 0.4512 - val_loss: 2.2007 - val_acc: 0.5235\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.961889\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.88942 to 2.20068, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45431/45431 [==============================] - 56s 1ms/step - loss: 2.1096 - acc: 0.5410 - val_loss: 1.8483 - val_acc: 0.6057\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.974336\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.20068 to 1.84829, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45431/45431 [==============================] - 55s 1ms/step - loss: 1.8284 - acc: 0.5937 - val_loss: 1.6758 - val_acc: 0.6327\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.979766\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.84829 to 1.67582, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45431/45431 [==============================] - 56s 1ms/step - loss: 1.6306 - acc: 0.6307 - val_loss: 1.5568 - val_acc: 0.6677\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.982496\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.67582 to 1.55679, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45431/45431 [==============================] - 56s 1ms/step - loss: 1.4624 - acc: 0.6672 - val_loss: 1.4573 - val_acc: 0.6852\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.983972\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.55679 to 1.45735, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45431/45431 [==============================] - 55s 1ms/step - loss: 1.3306 - acc: 0.6959 - val_loss: 1.4066 - val_acc: 0.6971\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.984517\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.45735 to 1.40655, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45431/45431 [==============================] - 56s 1ms/step - loss: 1.2401 - acc: 0.7148 - val_loss: 1.3826 - val_acc: 0.7007\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.984762\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.40655 to 1.38265, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45431/45431 [==============================] - 56s 1ms/step - loss: 1.1760 - acc: 0.7274 - val_loss: 1.3548 - val_acc: 0.7110\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.985376\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.38265 to 1.35475, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 2s 272us/step\n",
            "### Model with seed: 2019  for fold no. 2 ####\n",
            "Train on 45467 samples, validate on 6566 samples\n",
            "Epoch 1/10\n",
            "45467/45467 [==============================] - 59s 1ms/step - loss: 5.3707 - acc: 0.0699 - val_loss: 4.5236 - val_acc: 0.1698\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.750712\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.52358, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45467/45467 [==============================] - 58s 1ms/step - loss: 3.7013 - acc: 0.2938 - val_loss: 2.9122 - val_acc: 0.4022\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.925250\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.52358 to 2.91216, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45467/45467 [==============================] - 56s 1ms/step - loss: 2.6547 - acc: 0.4412 - val_loss: 2.2298 - val_acc: 0.5250\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.962052\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.91216 to 2.22979, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45467/45467 [==============================] - 56s 1ms/step - loss: 2.1414 - acc: 0.5265 - val_loss: 1.8888 - val_acc: 0.5871\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.973640\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.22979 to 1.88883, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45467/45467 [==============================] - 56s 1ms/step - loss: 1.8395 - acc: 0.5875 - val_loss: 1.6761 - val_acc: 0.6375\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.978681\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.88883 to 1.67611, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45467/45467 [==============================] - 56s 1ms/step - loss: 1.6336 - acc: 0.6329 - val_loss: 1.5387 - val_acc: 0.6625\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.982044\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.67611 to 1.53874, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45467/45467 [==============================] - 55s 1ms/step - loss: 1.4566 - acc: 0.6691 - val_loss: 1.4592 - val_acc: 0.6850\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.982456\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.53874 to 1.45922, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45467/45467 [==============================] - 55s 1ms/step - loss: 1.3304 - acc: 0.6965 - val_loss: 1.4095 - val_acc: 0.6977\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.983198\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.45922 to 1.40945, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45467/45467 [==============================] - 56s 1ms/step - loss: 1.2379 - acc: 0.7138 - val_loss: 1.3776 - val_acc: 0.7035\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.983952\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.40945 to 1.37765, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45467/45467 [==============================] - 57s 1ms/step - loss: 1.1796 - acc: 0.7257 - val_loss: 1.3590 - val_acc: 0.7106\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.983995\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.37765 to 1.35900, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 2s 277us/step\n",
            "### Model with seed: 2019  for fold no. 3 ####\n",
            "Train on 45510 samples, validate on 6523 samples\n",
            "Epoch 1/10\n",
            "45510/45510 [==============================] - 59s 1ms/step - loss: 5.4116 - acc: 0.0669 - val_loss: 4.5483 - val_acc: 0.1797\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.737036\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.54832, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45510/45510 [==============================] - 58s 1ms/step - loss: 3.7161 - acc: 0.2875 - val_loss: 2.9273 - val_acc: 0.3987\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.922770\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.54832 to 2.92731, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45510/45510 [==============================] - 57s 1ms/step - loss: 2.6727 - acc: 0.4368 - val_loss: 2.3055 - val_acc: 0.5007\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.959402\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.92731 to 2.30549, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45510/45510 [==============================] - 56s 1ms/step - loss: 2.1743 - acc: 0.5228 - val_loss: 1.9607 - val_acc: 0.5764\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.972205\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.30549 to 1.96069, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45510/45510 [==============================] - 56s 1ms/step - loss: 1.8659 - acc: 0.5831 - val_loss: 1.7512 - val_acc: 0.6209\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.977150\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.96069 to 1.75123, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45510/45510 [==============================] - 55s 1ms/step - loss: 1.6540 - acc: 0.6270 - val_loss: 1.6443 - val_acc: 0.6469\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.979463\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.75123 to 1.64434, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45510/45510 [==============================] - 57s 1ms/step - loss: 1.4746 - acc: 0.6646 - val_loss: 1.5399 - val_acc: 0.6709\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.980691\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.64434 to 1.53985, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45510/45510 [==============================] - 57s 1ms/step - loss: 1.3401 - acc: 0.6919 - val_loss: 1.4736 - val_acc: 0.6851\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.981790\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.53985 to 1.47363, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45510/45510 [==============================] - 56s 1ms/step - loss: 1.2537 - acc: 0.7091 - val_loss: 1.4551 - val_acc: 0.6952\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.982419\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.47363 to 1.45513, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45510/45510 [==============================] - 56s 1ms/step - loss: 1.1818 - acc: 0.7263 - val_loss: 1.4327 - val_acc: 0.7055\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.982947\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.45513 to 1.43268, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 2s 272us/step\n",
            "### Model with seed: 2019  for fold no. 4 ####\n",
            "Train on 45541 samples, validate on 6492 samples\n",
            "Epoch 1/10\n",
            "45541/45541 [==============================] - 60s 1ms/step - loss: 5.3101 - acc: 0.0833 - val_loss: 4.3691 - val_acc: 0.2076\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.764341\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.36910, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45541/45541 [==============================] - 58s 1ms/step - loss: 3.6804 - acc: 0.2954 - val_loss: 2.9357 - val_acc: 0.4039\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.925236\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.36910 to 2.93571, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45541/45541 [==============================] - 58s 1ms/step - loss: 2.6590 - acc: 0.4392 - val_loss: 2.2727 - val_acc: 0.5156\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.962101\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.93571 to 2.27275, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45541/45541 [==============================] - 57s 1ms/step - loss: 2.1572 - acc: 0.5279 - val_loss: 1.9107 - val_acc: 0.5823\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.973902\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.27275 to 1.91073, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45541/45541 [==============================] - 57s 1ms/step - loss: 1.8561 - acc: 0.5841 - val_loss: 1.7155 - val_acc: 0.6275\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.979092\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.91073 to 1.71554, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45541/45541 [==============================] - 57s 1ms/step - loss: 1.6526 - acc: 0.6262 - val_loss: 1.5916 - val_acc: 0.6520\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.980566\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.71554 to 1.59158, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45541/45541 [==============================] - 56s 1ms/step - loss: 1.4762 - acc: 0.6667 - val_loss: 1.5057 - val_acc: 0.6745\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.982401\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.59158 to 1.50569, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45541/45541 [==============================] - 57s 1ms/step - loss: 1.3451 - acc: 0.6931 - val_loss: 1.4548 - val_acc: 0.6909\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.983343\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.50569 to 1.45478, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45541/45541 [==============================] - 58s 1ms/step - loss: 1.2513 - acc: 0.7133 - val_loss: 1.4196 - val_acc: 0.6959\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.983896\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.45478 to 1.41961, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45541/45541 [==============================] - 57s 1ms/step - loss: 1.1859 - acc: 0.7270 - val_loss: 1.4015 - val_acc: 0.7021\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.984457\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.41961 to 1.40149, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 2s 272us/step\n",
            "### Model with seed: 2019  for fold no. 5 ####\n",
            "Train on 45590 samples, validate on 6443 samples\n",
            "Epoch 1/10\n",
            "45590/45590 [==============================] - 60s 1ms/step - loss: 5.3609 - acc: 0.0787 - val_loss: 4.4114 - val_acc: 0.1886\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.758711\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.41139, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45590/45590 [==============================] - 58s 1ms/step - loss: 3.6805 - acc: 0.2927 - val_loss: 2.8881 - val_acc: 0.3993\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.930599\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.41139 to 2.88807, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45590/45590 [==============================] - 57s 1ms/step - loss: 2.6680 - acc: 0.4383 - val_loss: 2.2514 - val_acc: 0.5094\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.964127\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.88807 to 2.25135, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45590/45590 [==============================] - 57s 1ms/step - loss: 2.1590 - acc: 0.5268 - val_loss: 1.8398 - val_acc: 0.5997\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.975803\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.25135 to 1.83985, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45590/45590 [==============================] - 55s 1ms/step - loss: 1.8515 - acc: 0.5869 - val_loss: 1.6621 - val_acc: 0.6390\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.979947\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.83985 to 1.66213, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45590/45590 [==============================] - 56s 1ms/step - loss: 1.6407 - acc: 0.6292 - val_loss: 1.5516 - val_acc: 0.6618\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.982105\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.66213 to 1.55159, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45590/45590 [==============================] - 56s 1ms/step - loss: 1.4664 - acc: 0.6673 - val_loss: 1.4656 - val_acc: 0.6798\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.983529\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.55159 to 1.46558, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45590/45590 [==============================] - 56s 1ms/step - loss: 1.3312 - acc: 0.6959 - val_loss: 1.3940 - val_acc: 0.6981\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.984426\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.46558 to 1.39400, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45590/45590 [==============================] - 56s 1ms/step - loss: 1.2425 - acc: 0.7120 - val_loss: 1.3618 - val_acc: 0.7029\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.984682\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.39400 to 1.36175, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45590/45590 [==============================] - 57s 1ms/step - loss: 1.1748 - acc: 0.7275 - val_loss: 1.3405 - val_acc: 0.7088\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.984897\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.36175 to 1.34051, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 2s 272us/step\n",
            "### Model with seed: 2019  for fold no. 6 ####\n",
            "Train on 45632 samples, validate on 6401 samples\n",
            "Epoch 1/10\n",
            "45632/45632 [==============================] - 60s 1ms/step - loss: 5.3586 - acc: 0.0782 - val_loss: 4.3647 - val_acc: 0.1872\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.765514\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.36467, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45632/45632 [==============================] - 58s 1ms/step - loss: 3.6818 - acc: 0.2901 - val_loss: 2.9287 - val_acc: 0.4074\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.919693\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.36467 to 2.92874, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45632/45632 [==============================] - 56s 1ms/step - loss: 2.6964 - acc: 0.4383 - val_loss: 2.2886 - val_acc: 0.5138\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.958593\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.92874 to 2.28864, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45632/45632 [==============================] - 57s 1ms/step - loss: 2.1817 - acc: 0.5252 - val_loss: 1.9772 - val_acc: 0.5779\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.970781\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.28864 to 1.97724, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45632/45632 [==============================] - 57s 1ms/step - loss: 1.8746 - acc: 0.5817 - val_loss: 1.7922 - val_acc: 0.6185\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.975335\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.97724 to 1.79216, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45632/45632 [==============================] - 57s 1ms/step - loss: 1.6593 - acc: 0.6280 - val_loss: 1.6527 - val_acc: 0.6494\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.977795\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.79216 to 1.65274, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45632/45632 [==============================] - 57s 1ms/step - loss: 1.4812 - acc: 0.6658 - val_loss: 1.5778 - val_acc: 0.6696\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.979420\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.65274 to 1.57780, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45632/45632 [==============================] - 57s 1ms/step - loss: 1.3465 - acc: 0.6940 - val_loss: 1.5322 - val_acc: 0.6780\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.980406\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.57780 to 1.53221, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45632/45632 [==============================] - 57s 1ms/step - loss: 1.2559 - acc: 0.7122 - val_loss: 1.4976 - val_acc: 0.6836\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.980753\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.53221 to 1.49758, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45632/45632 [==============================] - 57s 1ms/step - loss: 1.1856 - acc: 0.7267 - val_loss: 1.4739 - val_acc: 0.6915\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.981413\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.49758 to 1.47386, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 2s 277us/step\n",
            "### Model with seed: 2019  for fold no. 7 ####\n",
            "Train on 45678 samples, validate on 6355 samples\n",
            "Epoch 1/10\n",
            "45678/45678 [==============================] - 60s 1ms/step - loss: 5.3380 - acc: 0.0725 - val_loss: 4.4114 - val_acc: 0.2112\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.752150\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.41143, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "45678/45678 [==============================] - 59s 1ms/step - loss: 3.6666 - acc: 0.3003 - val_loss: 2.7817 - val_acc: 0.4264\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.928512\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.41143 to 2.78169, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "45678/45678 [==============================] - 58s 1ms/step - loss: 2.6168 - acc: 0.4479 - val_loss: 2.1556 - val_acc: 0.5287\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.964436\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.78169 to 2.15565, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "45678/45678 [==============================] - 58s 1ms/step - loss: 2.1208 - acc: 0.5330 - val_loss: 1.8698 - val_acc: 0.5940\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.974110\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.15565 to 1.86983, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "45678/45678 [==============================] - 57s 1ms/step - loss: 1.8324 - acc: 0.5928 - val_loss: 1.6460 - val_acc: 0.6447\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.978692\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.86983 to 1.64602, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "45678/45678 [==============================] - 56s 1ms/step - loss: 1.6348 - acc: 0.6324 - val_loss: 1.5500 - val_acc: 0.6662\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.980555\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.64602 to 1.55004, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "45678/45678 [==============================] - 57s 1ms/step - loss: 1.4640 - acc: 0.6688 - val_loss: 1.4572 - val_acc: 0.6859\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.982257\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.55004 to 1.45723, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "45678/45678 [==============================] - 57s 1ms/step - loss: 1.3337 - acc: 0.6944 - val_loss: 1.4140 - val_acc: 0.7007\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.983066\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.45723 to 1.41402, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "45678/45678 [==============================] - 58s 1ms/step - loss: 1.2419 - acc: 0.7145 - val_loss: 1.3937 - val_acc: 0.7054\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.983391\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.41402 to 1.39372, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "45678/45678 [==============================] - 58s 1ms/step - loss: 1.1799 - acc: 0.7276 - val_loss: 1.3731 - val_acc: 0.7106\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.983671\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.39372 to 1.37307, saving model to best_model.hdf5\n",
            "5782/5782 [==============================] - 2s 279us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iVCbgUPfKL5b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_test=pred_test*8/7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YTzDAHadI8I6",
        "colab_type": "code",
        "outputId": "61fbb011-a8dc-424c-9e48-534918ed3daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# ROC scores on Test set for different codes\n",
        "scores=[]\n",
        "for i in range(396):\n",
        "  score = roc_auc_score(y_test[:,i], pred_test[:,i])\n",
        "  scores.append(score)\n",
        "  #print(\"score for index %s is %d\" (i,score))\n",
        "\n",
        "low = list(np.argsort(scores)[:5])\n",
        "high = list(np.argsort(scores)[::-1][:250])\n",
        "print('high scores is {}'.format(np.mean([scores[i] for i in high])))\n",
        "print('low scores is {}'.format(np.mean([scores[i] for i in low])))\n",
        "# ROC is not a problem in multi-class prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "high scores is 0.9976635485766142\n",
            "low scores is 0.8496196545022776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cbDZj9NXtenR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving predictions for error analysis\n",
        "os.mkdir('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen7_350_icd/run1_noembed_dpcnn_72.2/')\n",
        "os.chdir('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/M_maxlen7_350_icd/run1_noembed_dpcnn_72.2')\n",
        "\n",
        "itoicd = dict((v,k) for k,v in icd_dict.items())\n",
        "test_pred = np.argmax(pred_test, axis=1)\n",
        "test_act = np.argmax(y_test, axis=1) \n",
        "mdf = pd.DataFrame({'test_act':[itoicd[i] for i in list(test_act)],'test_pred':[itoicd[i] for i in list(test_pred)]})\n",
        "mdf.to_csv('pred_test.csv',index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_weiorJZVhZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Top Codes with low accuracy on test set\n",
        "#pred_test\n",
        "acc = [len(mdf[(mdf['test_pred']==i) & (mdf['test_act']==i)])/len(mdf[mdf['test_act']==i]) for i in mdf['test_act'].values]\n",
        "mdf2 = pd.DataFrame({'class_index': mdf['test_act'].values,'accuracy':acc})\n",
        "#print(len(mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()))\n",
        "codes= mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()\n",
        "mdf2.to_csv('error_codes.csv', index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsS4MwoqOvLK",
        "colab_type": "code",
        "outputId": "57d703ec-c3fe-4300-b623-2ac9b5a4306c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy on various condifence levels and sample coverage on Test set\n",
        "test_pred = np.argmax(pred_test, axis=1)\n",
        "test_pred_proba = np.max(pred_test,axis=1)\n",
        "mdf3 = pd.DataFrame({'test_act':list(test_act),'test_pred':list(test_pred), 'prob': list(test_pred_proba)})\n",
        "#del CUTOFF\n",
        "for CUTOFF in range(0,100,5):\n",
        "    acc = len(mdf3[(mdf3['prob']>CUTOFF/100) & (mdf3['test_act']==mdf3['test_pred'])])/len(mdf3[(mdf3['prob']>CUTOFF/100)])\n",
        "    cov = len(mdf3[(mdf3['prob']>CUTOFF/100)])/len(mdf3)\n",
        "    print(\"Confidence: %f ## Accuracy: %f ## Coverage on Test dataset: %f\" % (CUTOFF/100,acc,cov))\n",
        "    #print(\"coverage with this accuracy level on Test dataset is {}\".format(cov))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence: 0.000000 ## Accuracy: 0.722587 ## Coverage on Test dataset: 1.000000\n",
            "Confidence: 0.050000 ## Accuracy: 0.742481 ## Coverage on Test dataset: 0.971809\n",
            "Confidence: 0.100000 ## Accuracy: 0.755172 ## Coverage on Test dataset: 0.952957\n",
            "Confidence: 0.150000 ## Accuracy: 0.768589 ## Coverage on Test dataset: 0.932722\n",
            "Confidence: 0.200000 ## Accuracy: 0.780936 ## Coverage on Test dataset: 0.912660\n",
            "Confidence: 0.250000 ## Accuracy: 0.794721 ## Coverage on Test dataset: 0.884642\n",
            "Confidence: 0.300000 ## Accuracy: 0.809899 ## Coverage on Test dataset: 0.856105\n",
            "Confidence: 0.350000 ## Accuracy: 0.821555 ## Coverage on Test dataset: 0.829644\n",
            "Confidence: 0.400000 ## Accuracy: 0.834125 ## Coverage on Test dataset: 0.800761\n",
            "Confidence: 0.450000 ## Accuracy: 0.851566 ## Coverage on Test dataset: 0.762020\n",
            "Confidence: 0.500000 ## Accuracy: 0.866127 ## Coverage on Test dataset: 0.726046\n",
            "Confidence: 0.550000 ## Accuracy: 0.879590 ## Coverage on Test dataset: 0.692321\n",
            "Confidence: 0.600000 ## Accuracy: 0.892340 ## Coverage on Test dataset: 0.657039\n",
            "Confidence: 0.650000 ## Accuracy: 0.902419 ## Coverage on Test dataset: 0.622103\n",
            "Confidence: 0.700000 ## Accuracy: 0.913940 ## Coverage on Test dataset: 0.586821\n",
            "Confidence: 0.750000 ## Accuracy: 0.921772 ## Coverage on Test dataset: 0.550502\n",
            "Confidence: 0.800000 ## Accuracy: 0.935517 ## Coverage on Test dataset: 0.506918\n",
            "Confidence: 0.850000 ## Accuracy: 0.950988 ## Coverage on Test dataset: 0.455206\n",
            "Confidence: 0.900000 ## Accuracy: 0.962003 ## Coverage on Test dataset: 0.386890\n",
            "Confidence: 0.950000 ## Accuracy: 0.967995 ## Coverage on Test dataset: 0.286406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dVM2EqgpX0Lr",
        "colab_type": "code",
        "outputId": "a114457a-b618-4894-cd1d-3de58bc6d817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "# Steps- for re generating the Data for modeling\n",
        "\n",
        "#datasize for icd codes\n",
        "\n",
        "strain = np.argmax(np.vstack([y_train,y_test]), axis=1)\n",
        "codesize = [sum(strain==icd_dict[i]) for i in codes]\n",
        "#print(len([i for i in codesize if i < 30]))\n",
        "codesize2 = [sum(strain==icd_dict[i]) for i in (set([itoicd[i] for i in set(strain)])-set(codes))]\n",
        "#print(len([i for i in codesize2 if i < 30]))\n",
        "\n",
        "print(\"mean dataset size of error codes is %d\" % (np.mean(codesize)))\n",
        "print(\"mean  dataset size of non-error codes is %d\" % (np.mean(codesize2)))\n",
        "print(\"median dataset size of error codes is %d\" % (np.median(codesize)))\n",
        "print(\"median  dataset size of non-error codes is %d\" % (np.median(codesize2)))\n",
        "\n",
        "# word entropy for icd codes\n",
        "\n",
        "idx = [[j for j in range(len(strain)) if strain[j]==icd_dict[i]] for i in codes]\n",
        "idx2 = [[j for j in range(len(strain)) if strain[j]==icd_dict[i]] for i in (set([itoicd[i] for i in set(strain)])-set(codes))]\n",
        "x = np.vstack([x_train, x_test])\n",
        "word_ent = [len(set([j for i in [[list(x[i]) for i in p] for p in idx][p] for j in i])) for p in range(len([[list(x[i]) for i in p] for p in idx]))]\n",
        "word_ent2 = [len(set([j for i in [[list(x[i]) for i in p] for p in idx2][p] for j in i])) for p in range(len([[list(x[i]) for i in p] for p in idx2]))]\n",
        "\n",
        "print(\"#################################################\")\n",
        "print(\"mean # of unqiue words in error codes is %d\" % (np.mean(word_ent)))\n",
        "print(\"mean # of unqiue words in non-error codes is %d\" % (np.mean(word_ent2)))\n",
        "print(\"median # of unqiue words in error codes is %d\" % (np.median(word_ent)))\n",
        "print(\"median # of unqiue words in non-error codes is %d\" % (np.median(word_ent2)))\n",
        "\n",
        "\n",
        "#codesize\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean dataset size of error codes is 70\n",
            "mean  dataset size of non-error codes is 193\n",
            "median dataset size of error codes is 50\n",
            "median  dataset size of non-error codes is 104\n",
            "#################################################\n",
            "mean # of unqiue words in error codes is 76\n",
            "mean # of unqiue words in non-error codes is 109\n",
            "median # of unqiue words in error codes is 58\n",
            "median # of unqiue words in non-error codes is 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vvc7MWcyLwue",
        "colab_type": "code",
        "outputId": "b6a11cfa-1eb7-4c6e-f697-612db5396f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Saving Model\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_v1.0.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_v1.0.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n",
        "# later..."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cj0mhWJ0Qg2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model_v1.0.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_v1.0.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "score = np.argmax(loaded_model.predict(DATASET, batch_size = 16, verbose = 1), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}