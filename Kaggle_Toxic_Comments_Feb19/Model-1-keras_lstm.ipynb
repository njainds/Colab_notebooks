{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments_Feb19/Model-1-keras_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oYZkU7ZN3CL0",
        "outputId": "6592d71a-4865-4c2d-b500-9f7a83f80b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BAFlm8xPHpyc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "import torch\n",
        "from torchtext import data\n",
        "import spacy\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "import zipfile\n",
        "import gzip\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "from nltk import word_tokenize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D, Conv2D, Input, SpatialDropout1D, Embedding, Dense, Activation, Bidirectional, LSTM,CuDNNLSTM, CuDNNGRU, GlobalMaxPooling1D, concatenate, Dropout\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.models import Model\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.engine import Layer\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from unidecode import unidecode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D-lZ41oqDYTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/kaggle_toxic_comments\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ETSksPDYFps2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector) ##sum([word[1] for word in vocab[:120000]])=92%##\n",
        "maxlen = 250 # max number of words in a question to use ## train.num_words.quantile(q=0.96, interpolation='nearest')=258 ##\n",
        "batch_size = 512 # how many samples to process at once\n",
        "n_epochs = 5 # how many times to iterate over all samples\n",
        "n_splits = 5 # Number of K-fold Splits\n",
        "\n",
        "SEED = 2019\n",
        "def seed_everything(seed=2019):\n",
        "    random.seed(seed)\n",
        "    \n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2hyLLFNIHoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/My Drive/kaggle_toxic_comments/\")\n",
        "x_train = np.load(\"x_train.npy\")\n",
        "x_test = np.load(\"x_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "features = np.load(\"features.npy\")\n",
        "test_features = np.load(\"test_features.npy\")\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "ext_lexvec_embeddings = np.load(\"ext_lexvec_embeddings.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jwc1rMTeyDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train simple LSTM using different embeddings\n",
        "# Top compeitions- QIQC and Toxic comments\n",
        "# ensembles (stacking and blending)\n",
        "# Pretrained models- ULMFit and BERT\n",
        "# Gensim and fasttext text classification\n",
        "# Other SOTAs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wdi_9dQMkT2G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Model-1: Keras embedding-spatialdropout-BiLSTM-BiGRU-maxpool-linear+relu-linear-softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIUW0jz1Wh0F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxiqwQ77Tivr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "            \n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YEPJ623BlR17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "358bd3c6-e71c-44ca-b01f-10def633d52d"
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(maxlen,))\n",
        "x   = Embedding(max_features, embed_size, weights=[ext_lexvec_embeddings], trainable=False)(inp)\n",
        "x   = SpatialDropout1D(rate=0.2)(x)\n",
        "x   = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
        "x1  = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
        "x   = GlobalMaxPooling1D()(x)\n",
        "x1  = GlobalMaxPooling1D()(x1)\n",
        "c   = concatenate([x,x1])\n",
        "y   = Dense(64, activation='relu')(c)\n",
        "y   = Dropout(0.2)(y)\n",
        "out = Dense(6, activation='sigmoid')(y)\n",
        "model=Model(inputs=inp,outputs=out)\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 250)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 250, 300)     36000000    input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_8 (SpatialDro (None, 250, 300)     0           embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_13 (Bidirectional (None, 250, 256)     440320      spatial_dropout1d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_14 (Bidirectional (None, 250, 128)     123648      bidirectional_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_10 (Global (None, 256)          0           bidirectional_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_11 (Global (None, 128)          0           bidirectional_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 384)          0           global_max_pooling1d_10[0][0]    \n",
            "                                                                 global_max_pooling1d_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 64)           24640       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 6)            390         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 36,588,998\n",
            "Trainable params: 588,998\n",
            "Non-trainable params: 36,000,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vAegUwOJ1Juw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "d8681062-cac1-4e53-c306-82089e305105"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size = 128, epochs = 3, validation_data = (X_valid, Y_valid), verbose = 1, callbacks = [ra_val, check_point, early_stop])\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/3\n",
            "143613/143613 [==============================] - 263s 2ms/step - loss: 0.0692 - acc: 0.9767 - val_loss: 0.0473 - val_acc: 0.9821\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.975698\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.04730, saving model to best_model.hdf5\n",
            "Epoch 2/3\n",
            "143613/143613 [==============================] - 258s 2ms/step - loss: 0.0488 - acc: 0.9819 - val_loss: 0.0451 - val_acc: 0.9828\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.981123\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.04730 to 0.04507, saving model to best_model.hdf5\n",
            "Epoch 3/3\n",
            "143613/143613 [==============================] - 264s 2ms/step - loss: 0.0452 - acc: 0.9826 - val_loss: 0.0422 - val_acc: 0.9833\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.985062\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.04507 to 0.04215, saving model to best_model.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f189578c940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "ngNuKxFWn7Xp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e68cd8dc-9774-42da-aa53-b804a0ac4ea3"
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test, batch_size = 1024, verbose = 1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 44s 286us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vep6bR7etg4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"./sample_submission.csv\")\n",
        "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = (pred)\n",
        "submission.to_csv(\"submission_model1_Feb21_auc_985062.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0eB1ufDwzxLr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Next tries:\n",
        "#https://www.kaggle.com/tunguz/bi-gru-cnn-poolings-gpu-kernel-version\n",
        "#https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80568 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uD84nJZWKAUC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xxyH2FUE0ZXy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8aIfgmw0uwZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7lPbxkVy07A4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cogJ7mAj26-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w7096K_ZnsNC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAbN93Z7nSxg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vcvd_PdAoY--",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOiL1lHD6Ffu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lIS3AizP9vdR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7c_QyY9ytW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}