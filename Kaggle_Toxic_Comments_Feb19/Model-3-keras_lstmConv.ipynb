{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments_Feb19/Model-3-keras_lstmConv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oYZkU7ZN3CL0",
        "outputId": "245993c0-d384-4fc2-d769-f93ae3572d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BAFlm8xPHpyc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "import torch\n",
        "from torchtext import data\n",
        "import spacy\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "import zipfile\n",
        "import gzip\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "from nltk import word_tokenize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D, Conv2D, Input, SpatialDropout1D, Embedding, Dense, Activation, Bidirectional, LSTM,CuDNNLSTM, CuDNNGRU, GlobalMaxPooling1D,GlobalAveragePooling1D, concatenate, Dropout\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.models import Model\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.engine import Layer\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from unidecode import unidecode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D-lZ41oqDYTC",
        "colab_type": "code",
        "outputId": "e7db26ca-073c-4f67-c38f-0bbdbd955a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/kaggle_toxic_comments\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "best_model.hdf5\t\t\t\ttest.csv\n",
            "ext_fasttextwiki_embeddings.npy\t\ttest_features.npy\n",
            "ext_glove_embeddings.npy\t\ttest_labels.csv\n",
            "ext_lexvec_embeddings.npy\t\ttoxic_lookup_en_wiki_fasttext_300d.npy\n",
            "features.npy\t\t\t\ttrain.csv\n",
            "inputed_lexvec_embeddings.npy\t\tword_index.npy\n",
            "local_fasttextwiki_embeddings.npy\tx_test.npy\n",
            "sample_submission.csv\t\t\tx_train.npy\n",
            "submission_baseline_lr.csv\t\ty_train.npy\n",
            "submission_model1_Feb21_auc_985062.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ETSksPDYFps2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector) ##sum([word[1] for word in vocab[:120000]])=92%##\n",
        "maxlen = 250 # max number of words in a question to use ## train.num_words.quantile(q=0.96, interpolation='nearest')=258 ##\n",
        "batch_size = 512 # how many samples to process at once\n",
        "n_epochs = 5 # how many times to iterate over all samples\n",
        "n_splits = 5 # Number of K-fold Splits\n",
        "\n",
        "SEED = 2019\n",
        "def seed_everything(seed=2019):\n",
        "    random.seed(seed)\n",
        "    \n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2hyLLFNIHoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/My Drive/kaggle_toxic_comments/\")\n",
        "x_train = np.load(\"x_train.npy\")\n",
        "x_test = np.load(\"x_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "features = np.load(\"features.npy\")\n",
        "test_features = np.load(\"test_features.npy\")\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "ext_lexvec_embeddings = np.load(\"ext_lexvec_embeddings.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jwc1rMTeyDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train simple LSTM using different embeddings\n",
        "# Top compeitions- QIQC and Toxic comments\n",
        "# ensembles (stacking and blending)\n",
        "# Pretrained models- ULMFit and BERT\n",
        "# Gensim and fasttext text classification\n",
        "# Other SOTAs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wdi_9dQMkT2G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Model-3: https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80568"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIUW0jz1Wh0F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxiqwQ77Tivr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "            \n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YEPJ623BlR17",
        "colab_type": "code",
        "outputId": "f230e1f0-bb3a-4b08-a447-50affa9e72c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(maxlen,))\n",
        "x   = Embedding(max_features, embed_size, weights=[ext_lexvec_embeddings], trainable=False)(inp)\n",
        "x   = SpatialDropout1D(rate=0.2)(x)\n",
        "x   = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n",
        "x   = Conv1D(64, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "x1  = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
        "x1   = Conv1D(64, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x1)\n",
        "x_max   = GlobalMaxPooling1D()(x)\n",
        "x_avg   = GlobalAveragePooling1D()(x)\n",
        "x1_max  = GlobalMaxPooling1D()(x1)\n",
        "x1_avg  = GlobalAveragePooling1D()(x1)\n",
        "c   = concatenate([x_max,x_avg,x1_max,x1_avg])\n",
        "y   = Dense(64, activation='relu')(c)\n",
        "y   = Dropout(0.2)(y)\n",
        "out = Dense(6, activation='sigmoid')(y)\n",
        "model=Model(inputs=inp,outputs=out)\n",
        "model.compile(loss='binary_crossentropy', optimizer=(lr=1e-3), metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 250)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 250, 300)     36000000    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_4 (SpatialDro (None, 250, 300)     0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 250, 256)     330240      spatial_dropout1d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 249, 64)      32832       bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_7 (Bidirectional) (None, 249, 256)     198656      conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 248, 64)      32832       bidirectional_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 64)           0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_5 (Glo (None, 64)           0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_6 (GlobalM (None, 64)           0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_6 (Glo (None, 64)           0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 256)          0           global_max_pooling1d_5[0][0]     \n",
            "                                                                 global_average_pooling1d_5[0][0] \n",
            "                                                                 global_max_pooling1d_6[0][0]     \n",
            "                                                                 global_average_pooling1d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 64)           16448       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 6)            390         dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 36,611,398\n",
            "Trainable params: 611,398\n",
            "Non-trainable params: 36,000,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vAegUwOJ1Juw",
        "colab_type": "code",
        "outputId": "75e7f4e6-a204-4b7e-8bc1-610dee2f3a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, batch_size = 128, epochs = 6, validation_data = (X_valid, Y_valid), verbose = 1, callbacks = [ra_val, check_point, early_stop])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/3\n",
            "143613/143613 [==============================] - 289s 2ms/step - loss: 0.0444 - acc: 0.9828 - val_loss: 0.0422 - val_acc: 0.9833\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.985711\n",
            "\n",
            "Epoch 00001: val_loss improved from 0.04301 to 0.04221, saving model to best_model.hdf5\n",
            "Epoch 2/3\n",
            "143613/143613 [==============================] - 285s 2ms/step - loss: 0.0426 - acc: 0.9833 - val_loss: 0.0413 - val_acc: 0.9839\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.986680\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.04221 to 0.04130, saving model to best_model.hdf5\n",
            "Epoch 3/3\n",
            "143613/143613 [==============================] - 284s 2ms/step - loss: 0.0409 - acc: 0.9841 - val_loss: 0.0416 - val_acc: 0.9831\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.988075\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.04130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feab69da048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "ngNuKxFWn7Xp",
        "colab_type": "code",
        "outputId": "98e75173-2a9e-4192-8614-b06d3424d000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test, batch_size = 1024, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 52s 341us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vep6bR7etg4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"./sample_submission.csv\")\n",
        "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = (pred)\n",
        "submission.to_csv(\"submission_model2_Feb22_auc_988075.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0eB1ufDwzxLr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Next tries:\n",
        "#https://www.kaggle.com/tunguz/bi-gru-cnn-poolings-gpu-kernel-version\n",
        "#https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80568 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uD84nJZWKAUC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xxyH2FUE0ZXy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8aIfgmw0uwZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7lPbxkVy07A4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cogJ7mAj26-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w7096K_ZnsNC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAbN93Z7nSxg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vcvd_PdAoY--",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOiL1lHD6Ffu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lIS3AizP9vdR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7c_QyY9ytW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}