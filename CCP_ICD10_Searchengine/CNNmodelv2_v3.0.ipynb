{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/CCP_ICD10_Searchengine/CNNmodelv2_v3.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QYpecTXf_H6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Builf train and evaluate\n",
        "# Save model for offline scoring on test\n",
        "# Model name: CCP_ICD10_Searchengine/CNNmodel_v1.0.ipynb\n",
        "# References\n",
        "#https://github.com/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments/Model-2-keras_lstmConv.ipynb\n",
        "#https://github.com/njainds/NLP/blob/master/kaggle/QIQC/22nd%20Place%20Solution%20-%206%20models%20%2B%20POS%20tagging.ipynb\n",
        "#https://github.com/Cheneng/DPCNN/blob/master/model/DPCNN.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AL5rrZqLghp",
        "colab_type": "code",
        "outputId": "5ed317f3-e300-4df5-d210-cad44822c678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0zRdXN9yo6k3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import callbacks\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NhSwmpxVpCSx",
        "colab_type": "code",
        "outputId": "808a57b0-1831-4685-d434-382c6c013007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2\"\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "best_model.hdf5       mispell_dict.npy\ttest_X.npy\t  train_X.npy\n",
            "embedding_matrix.npy  model_data.csv\ttest_y.npy\t  train_y.npy\n",
            "icd_dict.npy\t      run1_kfold_71.2\ttokenizer.pickle  word_index.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OiHWhcY9SszU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"train_X.npy\")\n",
        "x_test = np.load(\"test_X.npy\")\n",
        "y_train = np.load(\"train_y.npy\")\n",
        "y_test = np.load(\"test_y.npy\")\n",
        "features = np.load(\"test_y.npy\")\n",
        "icd_dict = np.load(\"icd_dict.npy\").item()\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "embeddings = np.load(\"embedding_matrix.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nTOOQtvDHeZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=4590., mode='triangular',gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "    \n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size,\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwjoGzOR3m9H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "#del check_point, ra_val, early_stop\n",
        "!rm ./best_model.hdf5\n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(x_test, y_test), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D5xLwVe9Bw91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "max_features = embeddings.shape[0]\n",
        "maxlen = x_train.shape[1]\n",
        "embed_size = embeddings.shape[1]\n",
        "n_class = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXiTe8F678Kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    keras.backend.clear_session()\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x   = Embedding(max_features, embed_size, weights=[embeddings], trainable=True)(inp)\n",
        "    x   = SpatialDropout1D(rate=0.2)(x)\n",
        "    x1  = Conv1D(128, kernel_size=1, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x2  = Conv1D(128, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x3  = Conv1D(128, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x4  = Conv1D(128, kernel_size=4, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x5  = Conv1D(128, kernel_size=5, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    \n",
        "    x1  = GlobalMaxPooling1D()(x1)\n",
        "    x2  = GlobalMaxPooling1D()(x2)\n",
        "    x3  = GlobalMaxPooling1D()(x3)\n",
        "    x4  = GlobalMaxPooling1D()(x4)\n",
        "    x5  = GlobalMaxPooling1D()(x5)\n",
        "    c   = concatenate([x1,x2,x3,x4,x5])\n",
        "    y   = Dense(512, activation='relu')(c)\n",
        "    y   = Dropout(0.2)(y)\n",
        "    out = Dense(n_class, activation='softmax')(y)\n",
        "    model=Model(inputs=inp,outputs=out)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=[\"accuracy\"])\n",
        "    return model\n",
        "#print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Rej4RS8O1JF",
        "colab_type": "code",
        "outputId": "5d4c8f32-9e80-49b2-80da-07d89ce62909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8809
        }
      },
      "cell_type": "code",
      "source": [
        "# Kfold training of model\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=8, random_state=2019, shuffle=True)\n",
        "pred_test = np.zeros((x_test.shape[0], n_class))\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kfold.split(x_train, np.argmax(y_train, axis=1))):\n",
        "    X_train, X_val, Y_train, Y_val = x_train[train_index], x_train[valid_index], y_train[train_index], y_train[valid_index]\n",
        "    \n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "    ra_val = RocAucEvaluation(validation_data=(X_val, Y_val), interval = 1)\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
        "    \n",
        "    model = get_model()\n",
        "    \n",
        "    print(\"### Model with seed: {}  for fold no. {} ####\".format( 2019, i))\n",
        "    \n",
        "    clr = CyclicLR(base_lr=1e-6, max_lr=5e-4,step_size=11281., mode='exp_range',gamma=0.99994)\n",
        "    model.fit(X_train, Y_train, batch_size = 24, epochs = 10, validation_data = (X_val, Y_val), verbose = 1, callbacks = [clr, ra_val, check_point, early_stop])\n",
        "    \n",
        "    pred_train = model.predict([X_val], batch_size=24, verbose=2)\n",
        "    pred_test += model.predict([x_test], batch_size=16, verbose=1)/8\n",
        "    os.remove(file_path)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "### Model with seed: 2019  for fold no. 0 ####\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 47216 samples, validate on 6935 samples\n",
            "Epoch 1/10\n",
            "47216/47216 [==============================] - 37s 779us/step - loss: 5.0722 - acc: 0.1278 - val_loss: 3.8979 - val_acc: 0.2968\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.888904\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.89786, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47216/47216 [==============================] - 33s 690us/step - loss: 3.0779 - acc: 0.3901 - val_loss: 2.3167 - val_acc: 0.5223\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.967468\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.89786 to 2.31670, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47216/47216 [==============================] - 33s 689us/step - loss: 2.0989 - acc: 0.5420 - val_loss: 1.7888 - val_acc: 0.6149\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.977315\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.31670 to 1.78879, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47216/47216 [==============================] - 32s 683us/step - loss: 1.6837 - acc: 0.6178 - val_loss: 1.5958 - val_acc: 0.6564\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.980745\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.78879 to 1.59575, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47216/47216 [==============================] - 32s 680us/step - loss: 1.4469 - acc: 0.6657 - val_loss: 1.4757 - val_acc: 0.6797\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.982602\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.59575 to 1.47574, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47216/47216 [==============================] - 32s 676us/step - loss: 1.2838 - acc: 0.6983 - val_loss: 1.4227 - val_acc: 0.6919\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.983523\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.47574 to 1.42268, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47216/47216 [==============================] - 32s 671us/step - loss: 1.1300 - acc: 0.7272 - val_loss: 1.3799 - val_acc: 0.6988\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.983835\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.42268 to 1.37986, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47216/47216 [==============================] - 32s 672us/step - loss: 1.0086 - acc: 0.7526 - val_loss: 1.3634 - val_acc: 0.7048\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.984475\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.37986 to 1.36338, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47216/47216 [==============================] - 32s 672us/step - loss: 0.9200 - acc: 0.7735 - val_loss: 1.3587 - val_acc: 0.7058\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.984819\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.36338 to 1.35874, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47216/47216 [==============================] - 32s 669us/step - loss: 0.8644 - acc: 0.7805 - val_loss: 1.3525 - val_acc: 0.7063\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.984835\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.35874 to 1.35255, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 156us/step\n",
            "### Model with seed: 2019  for fold no. 1 ####\n",
            "Train on 47271 samples, validate on 6880 samples\n",
            "Epoch 1/10\n",
            "47271/47271 [==============================] - 33s 700us/step - loss: 5.0689 - acc: 0.1250 - val_loss: 3.8286 - val_acc: 0.2956\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.893664\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.82856, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47271/47271 [==============================] - 32s 687us/step - loss: 3.0502 - acc: 0.3937 - val_loss: 2.3103 - val_acc: 0.5100\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.967167\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.82856 to 2.31026, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47271/47271 [==============================] - 32s 676us/step - loss: 2.0972 - acc: 0.5394 - val_loss: 1.8000 - val_acc: 0.6076\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.978078\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.31026 to 1.80004, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47271/47271 [==============================] - 32s 678us/step - loss: 1.6832 - acc: 0.6189 - val_loss: 1.5815 - val_acc: 0.6500\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.982012\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.80004 to 1.58146, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47271/47271 [==============================] - 32s 680us/step - loss: 1.4439 - acc: 0.6680 - val_loss: 1.4689 - val_acc: 0.6733\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.983615\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.58146 to 1.46889, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47271/47271 [==============================] - 32s 680us/step - loss: 1.2764 - acc: 0.6974 - val_loss: 1.4290 - val_acc: 0.6837\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.984670\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.46889 to 1.42895, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47271/47271 [==============================] - 32s 676us/step - loss: 1.1275 - acc: 0.7282 - val_loss: 1.3847 - val_acc: 0.6949\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.985238\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.42895 to 1.38467, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47271/47271 [==============================] - 32s 678us/step - loss: 1.0062 - acc: 0.7525 - val_loss: 1.3656 - val_acc: 0.7057\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.985326\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.38467 to 1.36564, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47271/47271 [==============================] - 32s 678us/step - loss: 0.9171 - acc: 0.7717 - val_loss: 1.3663 - val_acc: 0.7028\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.985671\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.36564\n",
            "Epoch 10/10\n",
            "47271/47271 [==============================] - 32s 676us/step - loss: 0.8599 - acc: 0.7838 - val_loss: 1.3621 - val_acc: 0.7060\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.985807\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.36564 to 1.36208, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 153us/step\n",
            "### Model with seed: 2019  for fold no. 2 ####\n",
            "Train on 47314 samples, validate on 6837 samples\n",
            "Epoch 1/10\n",
            "47314/47314 [==============================] - 33s 687us/step - loss: 5.0395 - acc: 0.1291 - val_loss: 3.8073 - val_acc: 0.2968\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.890073\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.80729, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47314/47314 [==============================] - 32s 677us/step - loss: 3.0593 - acc: 0.3917 - val_loss: 2.2643 - val_acc: 0.5235\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.968129\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.80729 to 2.26433, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47314/47314 [==============================] - 33s 695us/step - loss: 2.1019 - acc: 0.5380 - val_loss: 1.7514 - val_acc: 0.6216\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.978894\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.26433 to 1.75140, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47314/47314 [==============================] - 32s 685us/step - loss: 1.6908 - acc: 0.6167 - val_loss: 1.5346 - val_acc: 0.6564\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.982393\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.75140 to 1.53455, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47314/47314 [==============================] - 32s 681us/step - loss: 1.4518 - acc: 0.6646 - val_loss: 1.4358 - val_acc: 0.6768\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.984043\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.53455 to 1.43577, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47314/47314 [==============================] - 32s 682us/step - loss: 1.2806 - acc: 0.6984 - val_loss: 1.3722 - val_acc: 0.6877\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.985390\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.43577 to 1.37222, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47314/47314 [==============================] - 32s 675us/step - loss: 1.1322 - acc: 0.7282 - val_loss: 1.3350 - val_acc: 0.7013\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.985782\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.37222 to 1.33502, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47314/47314 [==============================] - 32s 677us/step - loss: 1.0097 - acc: 0.7517 - val_loss: 1.3255 - val_acc: 0.7029\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.986404\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.33502 to 1.32552, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47314/47314 [==============================] - 32s 680us/step - loss: 0.9268 - acc: 0.7690 - val_loss: 1.3137 - val_acc: 0.7101\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.986396\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.32552 to 1.31369, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47314/47314 [==============================] - 32s 674us/step - loss: 0.8639 - acc: 0.7802 - val_loss: 1.3128 - val_acc: 0.7111\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.986620\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.31369 to 1.31280, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 152us/step\n",
            "### Model with seed: 2019  for fold no. 3 ####\n",
            "Train on 47361 samples, validate on 6790 samples\n",
            "Epoch 1/10\n",
            "47361/47361 [==============================] - 32s 685us/step - loss: 5.0540 - acc: 0.1271 - val_loss: 3.7881 - val_acc: 0.3032\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.897228\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.78814, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47361/47361 [==============================] - 31s 663us/step - loss: 3.0442 - acc: 0.3976 - val_loss: 2.2698 - val_acc: 0.5199\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.968656\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.78814 to 2.26982, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47361/47361 [==============================] - 32s 677us/step - loss: 2.0892 - acc: 0.5412 - val_loss: 1.7538 - val_acc: 0.6206\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.978801\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.26982 to 1.75379, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47361/47361 [==============================] - 32s 676us/step - loss: 1.6804 - acc: 0.6184 - val_loss: 1.5587 - val_acc: 0.6635\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.982304\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.75379 to 1.55868, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47361/47361 [==============================] - 32s 675us/step - loss: 1.4464 - acc: 0.6657 - val_loss: 1.4520 - val_acc: 0.6823\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.983730\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.55868 to 1.45199, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47361/47361 [==============================] - 32s 677us/step - loss: 1.2799 - acc: 0.6977 - val_loss: 1.3981 - val_acc: 0.6943\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.985208\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.45199 to 1.39814, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47361/47361 [==============================] - 32s 671us/step - loss: 1.1280 - acc: 0.7281 - val_loss: 1.3595 - val_acc: 0.7077\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.985863\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.39814 to 1.35951, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47361/47361 [==============================] - 32s 669us/step - loss: 1.0039 - acc: 0.7534 - val_loss: 1.3476 - val_acc: 0.7052\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.986192\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.35951 to 1.34765, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47361/47361 [==============================] - 31s 658us/step - loss: 0.9215 - acc: 0.7692 - val_loss: 1.3413 - val_acc: 0.7121\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.986285\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.34765 to 1.34132, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47361/47361 [==============================] - 31s 656us/step - loss: 0.8598 - acc: 0.7833 - val_loss: 1.3397 - val_acc: 0.7130\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.986506\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.34132 to 1.33969, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 149us/step\n",
            "### Model with seed: 2019  for fold no. 4 ####\n",
            "Train on 47398 samples, validate on 6753 samples\n",
            "Epoch 1/10\n",
            "47398/47398 [==============================] - 31s 664us/step - loss: 5.0589 - acc: 0.1279 - val_loss: 3.8335 - val_acc: 0.2905\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.886639\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.83349, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47398/47398 [==============================] - 31s 657us/step - loss: 3.0792 - acc: 0.3898 - val_loss: 2.3033 - val_acc: 0.5106\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.969418\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.83349 to 2.30328, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47398/47398 [==============================] - 31s 654us/step - loss: 2.1090 - acc: 0.5386 - val_loss: 1.7722 - val_acc: 0.6119\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.980901\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.30328 to 1.77219, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47398/47398 [==============================] - 31s 654us/step - loss: 1.6882 - acc: 0.6187 - val_loss: 1.5470 - val_acc: 0.6527\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.984480\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.77219 to 1.54697, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47398/47398 [==============================] - 31s 646us/step - loss: 1.4530 - acc: 0.6654 - val_loss: 1.4442 - val_acc: 0.6738\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.985830\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.54697 to 1.44424, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47398/47398 [==============================] - 31s 646us/step - loss: 1.2809 - acc: 0.6997 - val_loss: 1.3851 - val_acc: 0.6886\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.986417\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.44424 to 1.38515, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47398/47398 [==============================] - 31s 652us/step - loss: 1.1227 - acc: 0.7315 - val_loss: 1.3459 - val_acc: 0.6985\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.986954\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.38515 to 1.34590, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47398/47398 [==============================] - 31s 650us/step - loss: 1.0078 - acc: 0.7527 - val_loss: 1.3172 - val_acc: 0.7021\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.987255\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.34590 to 1.31724, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47398/47398 [==============================] - 31s 651us/step - loss: 0.9266 - acc: 0.7702 - val_loss: 1.3096 - val_acc: 0.7083\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.987313\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.31724 to 1.30962, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47398/47398 [==============================] - 31s 651us/step - loss: 0.8633 - acc: 0.7843 - val_loss: 1.3120 - val_acc: 0.7099\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.987406\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.30962\n",
            "6017/6017 [==============================] - 1s 145us/step\n",
            "### Model with seed: 2019  for fold no. 5 ####\n",
            "Train on 47451 samples, validate on 6700 samples\n",
            "Epoch 1/10\n",
            "47451/47451 [==============================] - 31s 659us/step - loss: 5.0334 - acc: 0.1288 - val_loss: 3.7483 - val_acc: 0.3085\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.898283\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.74825, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47451/47451 [==============================] - 31s 652us/step - loss: 3.0370 - acc: 0.3983 - val_loss: 2.2200 - val_acc: 0.5245\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.969584\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.74825 to 2.21998, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47451/47451 [==============================] - 31s 649us/step - loss: 2.0918 - acc: 0.5399 - val_loss: 1.7383 - val_acc: 0.6191\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.979664\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.21998 to 1.73830, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47451/47451 [==============================] - 31s 652us/step - loss: 1.6888 - acc: 0.6180 - val_loss: 1.5313 - val_acc: 0.6594\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.982900\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.73830 to 1.53134, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47451/47451 [==============================] - 31s 650us/step - loss: 1.4479 - acc: 0.6644 - val_loss: 1.4345 - val_acc: 0.6824\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.984691\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.53134 to 1.43452, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47451/47451 [==============================] - 31s 653us/step - loss: 1.2766 - acc: 0.7001 - val_loss: 1.3821 - val_acc: 0.6975\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.985651\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.43452 to 1.38207, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47451/47451 [==============================] - 31s 652us/step - loss: 1.1279 - acc: 0.7261 - val_loss: 1.3509 - val_acc: 0.7010\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.985628\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.38207 to 1.35086, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47451/47451 [==============================] - 31s 651us/step - loss: 1.0084 - acc: 0.7524 - val_loss: 1.3223 - val_acc: 0.7100\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.986303\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.35086 to 1.32235, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47451/47451 [==============================] - 31s 652us/step - loss: 0.9297 - acc: 0.7671 - val_loss: 1.3188 - val_acc: 0.7143\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.986308\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.32235 to 1.31879, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47451/47451 [==============================] - 31s 653us/step - loss: 0.8646 - acc: 0.7810 - val_loss: 1.3136 - val_acc: 0.7139\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.986412\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.31879 to 1.31361, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 146us/step\n",
            "### Model with seed: 2019  for fold no. 6 ####\n",
            "Train on 47497 samples, validate on 6654 samples\n",
            "Epoch 1/10\n",
            "47497/47497 [==============================] - 31s 662us/step - loss: 5.0608 - acc: 0.1240 - val_loss: 3.7738 - val_acc: 0.3031\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.893172\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.77378, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47497/47497 [==============================] - 31s 649us/step - loss: 3.0590 - acc: 0.3924 - val_loss: 2.2398 - val_acc: 0.5237\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.967459\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.77378 to 2.23981, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47497/47497 [==============================] - 31s 648us/step - loss: 2.0927 - acc: 0.5402 - val_loss: 1.7359 - val_acc: 0.6244\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.978445\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.23981 to 1.73586, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47497/47497 [==============================] - 31s 652us/step - loss: 1.6839 - acc: 0.6190 - val_loss: 1.5352 - val_acc: 0.6560\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.982127\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.73586 to 1.53525, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47497/47497 [==============================] - 31s 651us/step - loss: 1.4449 - acc: 0.6684 - val_loss: 1.4364 - val_acc: 0.6773\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.984250\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.53525 to 1.43636, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47497/47497 [==============================] - 31s 650us/step - loss: 1.2762 - acc: 0.6997 - val_loss: 1.3822 - val_acc: 0.6930\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.984898\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.43636 to 1.38222, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47497/47497 [==============================] - 31s 651us/step - loss: 1.1272 - acc: 0.7287 - val_loss: 1.3549 - val_acc: 0.6976\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.985358\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.38222 to 1.35491, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47497/47497 [==============================] - 31s 649us/step - loss: 1.0036 - acc: 0.7545 - val_loss: 1.3340 - val_acc: 0.7051\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.985582\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.35491 to 1.33404, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47497/47497 [==============================] - 31s 649us/step - loss: 0.9257 - acc: 0.7714 - val_loss: 1.3228 - val_acc: 0.7101\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.985660\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.33404 to 1.32276, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47497/47497 [==============================] - 31s 648us/step - loss: 0.8646 - acc: 0.7836 - val_loss: 1.3209 - val_acc: 0.7119\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.985978\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.32276 to 1.32095, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 144us/step\n",
            "### Model with seed: 2019  for fold no. 7 ####\n",
            "Train on 47549 samples, validate on 6602 samples\n",
            "Epoch 1/10\n",
            "47549/47549 [==============================] - 32s 672us/step - loss: 5.0548 - acc: 0.1255 - val_loss: 3.7964 - val_acc: 0.3007\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.900746\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.79641, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "47549/47549 [==============================] - 31s 655us/step - loss: 3.0473 - acc: 0.3941 - val_loss: 2.2572 - val_acc: 0.5235\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.968994\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.79641 to 2.25723, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "47549/47549 [==============================] - 31s 653us/step - loss: 2.0765 - acc: 0.5446 - val_loss: 1.7596 - val_acc: 0.6157\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.978714\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.25723 to 1.75957, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "47549/47549 [==============================] - 31s 656us/step - loss: 1.6709 - acc: 0.6206 - val_loss: 1.5867 - val_acc: 0.6486\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.981104\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.75957 to 1.58666, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "47549/47549 [==============================] - 31s 654us/step - loss: 1.4336 - acc: 0.6670 - val_loss: 1.4804 - val_acc: 0.6766\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.982945\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.58666 to 1.48037, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "47549/47549 [==============================] - 31s 656us/step - loss: 1.2741 - acc: 0.6991 - val_loss: 1.4170 - val_acc: 0.6889\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.983508\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.48037 to 1.41698, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "47549/47549 [==============================] - 31s 652us/step - loss: 1.1171 - acc: 0.7298 - val_loss: 1.3775 - val_acc: 0.6971\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.984302\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.41698 to 1.37753, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "47549/47549 [==============================] - 31s 657us/step - loss: 0.9985 - acc: 0.7544 - val_loss: 1.3658 - val_acc: 0.6996\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.984508\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.37753 to 1.36585, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "47549/47549 [==============================] - 31s 657us/step - loss: 0.9111 - acc: 0.7726 - val_loss: 1.3596 - val_acc: 0.7045\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.984712\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.36585 to 1.35963, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "47549/47549 [==============================] - 31s 655us/step - loss: 0.8588 - acc: 0.7836 - val_loss: 1.3561 - val_acc: 0.7068\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.984751\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.35963 to 1.35609, saving model to best_model.hdf5\n",
            "6017/6017 [==============================] - 1s 144us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YTzDAHadI8I6",
        "colab_type": "code",
        "outputId": "61fbb011-a8dc-424c-9e48-534918ed3daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# ROC scores on Test set for different codes\n",
        "scores=[]\n",
        "for i in range(396):\n",
        "  score = roc_auc_score(y_test[:,i], pred_test[:,i])\n",
        "  scores.append(score)\n",
        "  #print(\"score for index %s is %d\" (i,score))\n",
        "\n",
        "low = list(np.argsort(scores)[:5])\n",
        "high = list(np.argsort(scores)[::-1][:250])\n",
        "print('high scores is {}'.format(np.mean([scores[i] for i in high])))\n",
        "print('low scores is {}'.format(np.mean([scores[i] for i in low])))\n",
        "# ROC is not a problem in multi-class prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "high scores is 0.9976635485766142\n",
            "low scores is 0.8496196545022776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cbDZj9NXtenR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving predictions for error analysis\n",
        "#os.mkdir('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/run1_kfold_71.2/')\n",
        "os.chdir('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2/run1_kfold_71.2')\n",
        "\n",
        "itoicd = dict((v,k) for k,v in icd_dict.items())\n",
        "test_pred = np.argmax(pred_test, axis=1)\n",
        "test_act = np.argmax(y_test, axis=1) \n",
        "mdf = pd.DataFrame({'test_act':[itoicd[i] for i in list(test_act)],'test_pred':[itoicd[i] for i in list(test_pred)]})\n",
        "#mdf.to_csv('pred_test.csv',index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_weiorJZVhZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Top Codes with low accuracy on test set\n",
        "#pred_test\n",
        "#acc = [len(mdf[(mdf['test_pred']==i) & (mdf['test_act']==i)])/len(mdf[mdf['test_act']==i]) for i in mdf['test_act'].values]\n",
        "#mdf2 = pd.DataFrame({'class_index': mdf['test_act'].values,'accuracy':acc})\n",
        "#print(len(mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()))\n",
        "#codes= mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()\n",
        "mdf2.to_csv('error_codes.csv', index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsS4MwoqOvLK",
        "colab_type": "code",
        "outputId": "02539f84-42fc-4252-8bb7-9b15b0ca7f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy on various condifence levels and sample coverage on Test set\n",
        "#test_pred = np.argmax(pred_test, axis=1)\n",
        "#test_pred_proba = np.max(pred_test,axis=1)\n",
        "#mdf3 = pd.DataFrame({'test_act':list(test_act),'test_pred':list(test_pred), 'prob': list(test_pred_proba)})\n",
        "#del CUTOFF\n",
        "for CUTOFF in range(30,100,5):\n",
        "    acc = len(mdf3[(mdf3['prob']>CUTOFF/100) & (mdf3['test_act']==mdf3['test_pred'])])/len(mdf3[(mdf3['prob']>CUTOFF/100)])\n",
        "    cov = len(mdf3[(mdf3['prob']>CUTOFF/100)])/len(mdf3)\n",
        "    print(\"Confidence: %f ## Accuracy: %f ## Coverage on Test dataset: %f\" % (CUTOFF/100,acc,cov))\n",
        "    #print(\"coverage with this accuracy level on Test dataset is {}\".format(cov))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confidence: 0.300000 ## Accuracy: 0.772086 ## Coverage on Test dataset: 0.895463\n",
            "Confidence: 0.350000 ## Accuracy: 0.783944 ## Coverage on Test dataset: 0.871531\n",
            "Confidence: 0.400000 ## Accuracy: 0.797096 ## Coverage on Test dataset: 0.846934\n",
            "Confidence: 0.450000 ## Accuracy: 0.810531 ## Coverage on Test dataset: 0.817517\n",
            "Confidence: 0.500000 ## Accuracy: 0.827498 ## Coverage on Test dataset: 0.783281\n",
            "Confidence: 0.550000 ## Accuracy: 0.840798 ## Coverage on Test dataset: 0.749543\n",
            "Confidence: 0.600000 ## Accuracy: 0.854133 ## Coverage on Test dataset: 0.717800\n",
            "Confidence: 0.650000 ## Accuracy: 0.871945 ## Coverage on Test dataset: 0.680073\n",
            "Confidence: 0.700000 ## Accuracy: 0.883553 ## Coverage on Test dataset: 0.643676\n",
            "Confidence: 0.750000 ## Accuracy: 0.897148 ## Coverage on Test dataset: 0.605950\n",
            "Confidence: 0.800000 ## Accuracy: 0.908049 ## Coverage on Test dataset: 0.565730\n",
            "Confidence: 0.850000 ## Accuracy: 0.923652 ## Coverage on Test dataset: 0.511551\n",
            "Confidence: 0.900000 ## Accuracy: 0.938258 ## Coverage on Test dataset: 0.452219\n",
            "Confidence: 0.950000 ## Accuracy: 0.956075 ## Coverage on Test dataset: 0.355659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dVM2EqgpX0Lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "50e740ee-b2e8-435d-c4ba-2f95335a3839"
      },
      "cell_type": "code",
      "source": [
        "# Steps- for re generating the Data for modeling\n",
        "\n",
        "#datasize for icd codes\n",
        "\n",
        "#strain = np.argmax(np.vstack([y_train,y_test]), axis=1)\n",
        "#codesize = [sum(strain==icd_dict[i]) for i in codes]\n",
        "#print(len([i for i in codesize if i < 30]))\n",
        "#codesize2 = [sum(strain==icd_dict[i]) for i in (set([itoicd[i] for i in set(strain)])-set(codes))]\n",
        "#print(len([i for i in codesize2 if i < 30]))\n",
        "\n",
        "print(\"mean dataset size of error codes is %d\" % (np.mean(codesize)))\n",
        "print(\"mean  dataset size of non-error codes is %d\" % (np.mean(codesize2)))\n",
        "print(\"median dataset size of error codes is %d\" % (np.median(codesize)))\n",
        "print(\"median  dataset size of non-error codes is %d\" % (np.median(codesize2)))\n",
        "\n",
        "# word entropy for icd codes\n",
        "\n",
        "#idx = [[j for j in range(len(strain)) if strain[j]==icd_dict[i]] for i in codes]\n",
        "#idx2 = [[j for j in range(len(strain)) if strain[j]==icd_dict[i]] for i in (set([itoicd[i] for i in set(strain)])-set(codes))]\n",
        "#x = np.vstack([x_train, x_test])\n",
        "#word_ent = [len(set([j for i in [[list(x[i]) for i in p] for p in idx][p] for j in i])) for p in range(len([[list(x[i]) for i in p] for p in idx]))]\n",
        "#word_ent2 = [len(set([j for i in [[list(x[i]) for i in p] for p in idx2][p] for j in i])) for p in range(len([[list(x[i]) for i in p] for p in idx2]))]\n",
        "\n",
        "print(\"#################################################\")\n",
        "print(\"mean # of unqiue words in error codes is %d\" % (np.mean(word_ent)))\n",
        "print(\"mean # of unqiue words in non-error codes is %d\" % (np.mean(word_ent2)))\n",
        "print(\"median # of unqiue words in error codes is %d\" % (np.median(word_ent)))\n",
        "print(\"median # of unqiue words in non-error codes is %d\" % (np.median(word_ent2)))\n",
        "\n",
        "\n",
        "#codesize\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean dataset size of error codes is 61\n",
            "mean  dataset size of non-error codes is 190\n",
            "median dataset size of error codes is 44\n",
            "median  dataset size of non-error codes is 103\n",
            "#################################################\n",
            "mean # of unqiue words in error codes is 69\n",
            "mean # of unqiue words in non-error codes is 110\n",
            "median # of unqiue words in error codes is 57\n",
            "median # of unqiue words in non-error codes is 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vvc7MWcyLwue",
        "colab_type": "code",
        "outputId": "b6a11cfa-1eb7-4c6e-f697-612db5396f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Saving Model\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_v1.0.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_v1.0.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n",
        "# later..."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cj0mhWJ0Qg2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model_v1.0.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_v1.0.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "score = np.argmax(loaded_model.predict(DATASET, batch_size = 16, verbose = 1), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}