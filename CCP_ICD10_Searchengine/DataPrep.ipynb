{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/CCP_ICD10_Searchengine/DataPrep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QYpecTXf_H6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data Preparation\n",
        "#Cleaning: Spellchecks, lemma\n",
        "#Create embedding matrix, missing embedding imputation\n",
        "\n",
        "# Build tokenizer and vocab\n",
        "# create test and train with sequence\n",
        "\n",
        "# Builf train and evaluate\n",
        "\n",
        "# Save model for offline scoring on test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xlhWWPwGggVX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data preparation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AL5rrZqLghp",
        "colab_type": "code",
        "outputId": "18831d1c-8e3c-4e18-a142-de9bc7c64e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0zRdXN9yo6k3",
        "colab_type": "code",
        "outputId": "8cb5a329-0d07-4e52-9375-b47bf67df0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from fastai.text import *\n",
        "import html\n",
        "import sklearn\n",
        "import torch.tensor as T\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#from fastai.learner import *\n",
        "\n",
        "import torchtext\n",
        "from torchtext import vocab, data\n",
        "from torchtext.datasets import language_modeling\n",
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "import torch\n",
        "from torchtext import data\n",
        "import spacy\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "import zipfile\n",
        "import gzip\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "from nltk import word_tokenize\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Conv1D, Conv2D\n",
        "from keras import optimizers\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NhSwmpxVpCSx",
        "colab_type": "code",
        "outputId": "560d8df7-f572-4c3c-c433-15bdbdd6e19a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/kaggle_toxic_comments/ulmfit\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "data\t     data_save.pkl  LM_data.csv  test_X.csv\n",
            "data_cl.pkl  export.pkl     models\t train_X.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "thldnbWMjHoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d89f90b3-646b-43be-8b0c-5f7ef35cda30"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata/model_data.csv')\n",
        "#df.head()\n",
        "# removed duplicated rows\n",
        "print(df.shape)\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(df.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16981, 2)\n",
            "(8705, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZSnWg5eXmeK0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#misspell correction\n",
        "def build_vocab(texts):\n",
        "    sentences = texts.apply(lambda x: re.split(' |;|,|\\*|\\n|[(]|[)]',x))\n",
        "    dfvocab = {}\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                dfvocab[word] += 1\n",
        "            except KeyError:\n",
        "                dfvocab[word] = 1\n",
        "    return dfvocab\n",
        "dfvocab = build_vocab(df['desc'])\n",
        "\n",
        "#len(vocab.keys()) 3630\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('/content/drive/My Drive/CCP-ICDsearch/wikipedia-pubmed-and-PMC-w2v.bin', binary=True)\n",
        "misspells=[]\n",
        "for k in list(dfvocab.keys()):\n",
        "    if k in model.vocab:\n",
        "        continue\n",
        "    else:\n",
        "        misspells.append(k)\n",
        "\n",
        "#misspells\n",
        "#[i for i in misspells if '/' in i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7Sez81S15AQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#cleaning\n",
        "#replcae + and +ve by ' positive'\n",
        "#replcase r. and l. with right and left\n",
        "#replcae int/int with int#int\n",
        "#split with /:,|()+\\-\n",
        "#misspells dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jt3L1t93rlv6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#np.save('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata/mispell_dict.npy',mispell_dict)\n",
        "#del mispell_dict\n",
        "#mispell_dict = np.load('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata/mispell_dict.npy').item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j-BD39I5B7ZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mispell_dict = np.load('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata/mispell_dict.npy').item()\n",
        "puncts = ['/','\\',':','|','(',')','+','-','*','!']\n",
        "\n",
        "def clean_text(x):\n",
        "    x = x.replace(r'+ve',' positive ')\n",
        "    x = x.replace(r'+',' positive ')\n",
        "    x = re.sub(r\"\\b([l][.])\", \"left \", x)\n",
        "    x = re.sub(r\"\\b([r][.])\", \"right \", x)\n",
        "    x = ((''.join('#'+i+'#'  if i.isdigit() else i for i in x)).replace('#/#','<>')).replace('#','')\n",
        "    x = x.replace(r\"\\n\", r\" \")\n",
        "    x = x.replace(r\"\\t\", r\" \")\n",
        "    x = x.replace(r\"\\b\", r\" \")\n",
        "    x = x.replace(r\"\\r\", r\" \")\n",
        "    x = re.sub(r\"\\s+\", r\" \", x)\n",
        "    return x\n",
        "\n",
        "def replace_n_punc(x):\n",
        "  return re.sub(r'[\\?\\.\\!\\,\\=]+(?=[\\?\\.\\!\\,\\=])', '', x)\n",
        "    \n",
        "  \n",
        "def _get_mispell(mispell_dict):\n",
        "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
        "    return mispell_dict, mispell_re\n",
        "\n",
        "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
        "def replace_typical_misspell(text):\n",
        "    def replace(match):\n",
        "        return mispellings[match.group(0)]\n",
        "    return mispellings_re.sub(replace, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uXDKdq0YpxjL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata/model_data.csv')\n",
        "\n",
        "train_X = train_df\n",
        "test_X = test_df\n",
        "# lower\n",
        "train_X[\"comment_text\"] = train_df[\"comment_text\"].apply(lambda x: x.lower())\n",
        "test_X[\"comment_text\"] = test_df[\"comment_text\"].apply(lambda x: x.lower())\n",
        "\n",
        "# Clean speelings\n",
        "train_X[\"comment_text\"] = train_X[\"comment_text\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
        "test_X[\"comment_text\"] = test_X[\"comment_text\"].apply(lambda x: replace_typical_misspell(x))\n",
        "   \n",
        "# Replcae multiple punct by single\n",
        "train_X[\"comment_text\"] = train_X[\"comment_text\"].progress_apply(lambda x: replace_n_punc(x))\n",
        "test_X[\"comment_text\"] = test_X[\"comment_text\"].apply(lambda x: replace_n_punc(x))    \n",
        "\n",
        "# Clean numbers\n",
        "train_X[\"comment_text\"] = train_X[\"comment_text\"].progress_apply(lambda x: clean_numbers(x))\n",
        "test_X[\"comment_text\"] = test_X[\"comment_text\"].apply(lambda x: clean_numbers(x))\n",
        "\n",
        "# Clean the text\n",
        "train_X[\"comment_text\"] = train_X[\"comment_text\"].progress_apply(lambda x: clean_text(x))\n",
        "test_X[\"comment_text\"] = test_X[\"comment_text\"].apply(lambda x: clean_text(x))\n",
        "\n",
        "## fill up the missing values\n",
        "train_X[\"comment_text\"].fillna(\"_##_\", inplace=True)\n",
        "test_X[\"comment_text\"].fillna(\"_##_\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ocsKxTFDJB2D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "#train/test split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oMBrSI-uJQSc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Embedding matrix"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}