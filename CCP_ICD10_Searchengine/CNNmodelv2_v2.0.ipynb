{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/CCP_ICD10_Searchengine/CNNmodelv2_v2.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QYpecTXf_H6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Builf train and evaluate\n",
        "# Save model for offline scoring on test\n",
        "# Model name: CCP_ICD10_Searchengine/CNNmodel_v1.0.ipynb\n",
        "# References\n",
        "#https://github.com/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments/Model-2-keras_lstmConv.ipynb\n",
        "#https://github.com/njainds/NLP/blob/master/kaggle/QIQC/22nd%20Place%20Solution%20-%206%20models%20%2B%20POS%20tagging.ipynb\n",
        "#https://github.com/Cheneng/DPCNN/blob/master/model/DPCNN.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AL5rrZqLghp",
        "colab_type": "code",
        "outputId": "caa2072d-d039-4487-ecac-bc7b35b4fb26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0zRdXN9yo6k3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import callbacks\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NhSwmpxVpCSx",
        "colab_type": "code",
        "outputId": "6c873229-3ea3-47cb-feb8-13585dcca3f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2\"\n",
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata_v2\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "embedding_matrix.npy  model_data.csv  tokenizer.pickle\tword_index.npy\n",
            "icd_dict.npy\t      test_X.npy      train_X.npy\n",
            "mispell_dict.npy      test_y.npy      train_y.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OiHWhcY9SszU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.load(\"train_X.npy\")\n",
        "x_test = np.load(\"test_X.npy\")\n",
        "y_train = np.load(\"train_y.npy\")\n",
        "y_test = np.load(\"test_y.npy\")\n",
        "features = np.load(\"test_y.npy\")\n",
        "icd_dict = np.load(\"icd_dict.npy\").item()\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "embeddings = np.load(\"embedding_matrix.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nTOOQtvDHeZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=4590., mode='triangular',gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "    \n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size,\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwjoGzOR3m9H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "del check_point, ra_val, early_stop\n",
        "!rm ./best_model.hdf5\n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(x_test, y_test), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D5xLwVe9Bw91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "max_features = embeddings.shape[0]\n",
        "maxlen = x_train.shape[1]\n",
        "embed_size = embeddings.shape[1]\n",
        "n_class = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXiTe8F678Kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    del model\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x   = Embedding(max_features, embed_size, weights=[embeddings], trainable=True)(inp)\n",
        "    x   = SpatialDropout1D(rate=0.2)(x)\n",
        "    x1  = Conv1D(128, kernel_size=1, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x2  = Conv1D(128, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x3  = Conv1D(128, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x4  = Conv1D(128, kernel_size=4, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    x5  = Conv1D(128, kernel_size=5, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "    \n",
        "    x1  = GlobalMaxPooling1D()(x1)\n",
        "    x2  = GlobalMaxPooling1D()(x2)\n",
        "    x3  = GlobalMaxPooling1D()(x3)\n",
        "    x4  = GlobalMaxPooling1D()(x4)\n",
        "    x5  = GlobalMaxPooling1D()(x5)\n",
        "    c   = concatenate([x1,x2,x3,x4,x5])\n",
        "    y   = Dense(512, activation='relu')(c)\n",
        "    y   = Dropout(0.2)(y)\n",
        "    out = Dense(n_class, activation='softmax')(y)\n",
        "    model=Model(inputs=inp,outputs=out)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=[\"accuracy\"])\n",
        "    return model\n",
        "#print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nfrXiC4tB_zt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e55b214-3661-40ad-af6d-a1aa490a2a73"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54151, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "metadata": {
        "id": "8Rej4RS8O1JF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Kfold training of model\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
        "y_test = np.zeros((x_test.shape[0], n_class))\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kfold.split(x_train, np.argmax(y_train, axis=1))):\n",
        "    X_train, X_val, Y_train, Y_val = x_train[train_index], x_train[valid_index], y_train[train_index], y_train[valid_index]\n",
        "    \n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "    ra_val = RocAucEvaluation(validation_data=(X_val, Y_val), interval = 1)\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
        "    \n",
        "    model = get_model()\n",
        "    \n",
        "    print(\\\"### Model: {} with seed: {}  for fold no. {} ####\\\".format(emb, seed, i))\n",
        "    \n",
        "    clr = CyclicLR(base_lr=1e-6, max_lr=5e-4,step_size=11281., mode='exp_range',gamma=0.99994)\n",
        "    model.fit(X_train, Y_train, batch_size = 24, epochs = 10, validation_data = (X_val, Y_val), verbose = 1, callbacks = [clr, ra_val, check_point, early_stop])\n",
        "    \n",
        "    y_pred = model.predict([X_val], batch_size=batch_size, verbose=2)\n",
        "    y_test += model.predict([x_test], batch_size=16, verbose=1)/5\n",
        "    os.remove(file_path)\n",
        "return y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VaWv1RBN7_ER",
        "colab_type": "code",
        "outputId": "761505e7-06fa-4589-c6cb-9d6d8a0bc6ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1091
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size = 24, epochs = 10, validation_data = (x_test, y_test), verbose = 1, callbacks = [ra_val, check_point, early_stop])\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54151 samples, validate on 6017 samples\n",
            "Epoch 1/10\n",
            "54151/54151 [==============================] - 35s 646us/step - loss: 3.8050 - acc: 0.2944 - val_loss: 2.5542 - val_acc: 0.4742\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.956673\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.55424, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "54151/54151 [==============================] - 33s 603us/step - loss: 2.3114 - acc: 0.5035 - val_loss: 1.9375 - val_acc: 0.5828\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.973830\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.55424 to 1.93754, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "54151/54151 [==============================] - 32s 594us/step - loss: 1.8721 - acc: 0.5830 - val_loss: 1.7013 - val_acc: 0.6266\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.978860\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.93754 to 1.70131, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "54151/54151 [==============================] - 33s 603us/step - loss: 1.6411 - acc: 0.6282 - val_loss: 1.5780 - val_acc: 0.6540\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.981327\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.70131 to 1.57804, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "54151/54151 [==============================] - 32s 592us/step - loss: 1.4944 - acc: 0.6596 - val_loss: 1.5028 - val_acc: 0.6693\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.982880\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.57804 to 1.50280, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "54151/54151 [==============================] - 32s 597us/step - loss: 1.3821 - acc: 0.6808 - val_loss: 1.4530 - val_acc: 0.6801\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.983786\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.50280 to 1.45299, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "54151/54151 [==============================] - 32s 593us/step - loss: 1.2937 - acc: 0.6989 - val_loss: 1.4189 - val_acc: 0.6837\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.984316\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.45299 to 1.41893, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "54151/54151 [==============================] - 32s 597us/step - loss: 1.2164 - acc: 0.7134 - val_loss: 1.3914 - val_acc: 0.6871\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.984900\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.41893 to 1.39140, saving model to best_model.hdf5\n",
            "Epoch 9/10\n",
            "54151/54151 [==============================] - 32s 596us/step - loss: 1.1560 - acc: 0.7238 - val_loss: 1.3756 - val_acc: 0.6939\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.985502\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.39140 to 1.37563, saving model to best_model.hdf5\n",
            "Epoch 10/10\n",
            "54151/54151 [==============================] - 33s 603us/step - loss: 1.0950 - acc: 0.7372 - val_loss: 1.3662 - val_acc: 0.6979\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.985262\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.37563 to 1.36618, saving model to best_model.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1982e69ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "metadata": {
        "id": "YTzDAHadI8I6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c17f61de-d607-4467-f4a9-c98f3daf2f01"
      },
      "cell_type": "code",
      "source": [
        "# ROC scores on Test set for different codes\n",
        "\n",
        "y_pred = model.predict(x_test, batch_size = 16, verbose = 1)\n",
        "print(y_pred[:,395].shape)\n",
        "scores=[]\n",
        "for i in range(396):\n",
        "  score = roc_auc_score(y_test[:,i], y_pred[:,i])\n",
        "  scores.append(score)\n",
        "  #print(\"score for index %s is %d\" (i,score))\n",
        "\n",
        "low = list(np.argsort(scores)[:5])\n",
        "high = list(np.argsort(scores)[::-1][:250])\n",
        "print('high scores is {}'.format(np.mean([scores[i] for i in high])))\n",
        "print('low scores is {}'.format(np.mean([scores[i] for i in low])))\n",
        "# ROC is not a problem in multi-class prediction"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6017/6017 [==============================] - 1s 177us/step\n",
            "(6017,)\n",
            "high scores is 0.9967437630437778\n",
            "low scores is 0.8340337086591365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_weiorJZVhZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "417f3fc9-d814-45bf-9ba3-0a0ca8313055"
      },
      "cell_type": "code",
      "source": [
        "# Top Codes with low accuracy on test set\n",
        "test_pred = np.argmax(model.predict(x_test, batch_size = 16, verbose = 1), axis=1)\n",
        "test_act = np.argmax(y_test, axis=1) \n",
        "mdf = pd.DataFrame({'test_act':list(test_act),'test_pred':list(test_pred)})\n",
        "acc = [len(mdf[(mdf['test_pred']==i) & (mdf['test_act']==i)])/len(mdf[mdf['test_act']==i]) for i in mdf['test_act'].values]\n",
        "mdf2 = pd.DataFrame({'class_index': mdf['test_act'].values,'accuracy':acc})\n",
        "print(len(mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()))\n",
        "codes= mdf2[mdf2['accuracy']<0.5].class_index.unique().tolist()\n",
        "#codes"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6017/6017 [==============================] - 1s 206us/step\n",
            "135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OsS4MwoqOvLK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "28852477-5ad4-465f-a9bf-feaef3d7e928"
      },
      "cell_type": "code",
      "source": [
        "# Accuracy on various condifence levels and sample coverage on Test set\n",
        "p = model.predict(x_test, batch_size = 16, verbose = 1)\n",
        "test_pred = np.argmax(p, axis=1)\n",
        "test_pred_proba = np.max(p,axis=1)\n",
        "mdf3 = pd.DataFrame({'test_act':list(test_act),'test_pred':list(test_pred), 'prob': list(test_pred_proba)})\n",
        "CUTOFF=0.8\n",
        "acc = len(mdf3[(mdf3['prob']>CUTOFF) & (mdf3['test_act']==mdf3['test_pred'])])/len(mdf3[(mdf3['prob']>CUTOFF)])\n",
        "print(\"Accuracy on Test dataset is {}\".format(acc))\n",
        "print(\"coverage with this accuracy level on Test dataset is {}\".format(len(mdf3[(mdf3['prob']>CUTOFF)])/len(mdf3)))\n"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6017/6017 [==============================] - 1s 211us/step\n",
            "Accuracy on Test dataset is 0.9067292644757433\n",
            "coverage with this accuracy level on Test dataset is 0.530995512713977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dVM2EqgpX0Lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4dd8722a-6353-4f6f-acf4-092957a2baa0"
      },
      "cell_type": "code",
      "source": [
        "# Steps- for re generating the Data for modeling\n",
        "#removing or balancing some ICDs\n",
        "\n",
        "#datasize for icd codes\n",
        "#strain = np.argmax(y_train, axis=1)\n",
        "#codesize = dict([(i,sum(strain==i)) for i in codes]) \n",
        "#codesize\n"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "metadata": {
        "id": "6DLYUM3s8DDo",
        "colab_type": "code",
        "outputId": "c00938c6-b9a9-4cc5-e213-b4d551e4b74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# Final results for presentation\n",
        "\n",
        "#itoicd = dict((v,k) for k,v in icd_dict.items())\n",
        "test_pred = np.argmax(model.predict(x_test, batch_size = 16, verbose = 1), axis=1)\n",
        "test_act = np.argmax(y_test, axis=1)\n",
        "trn_pred = np.argmax(model.predict(x_train, batch_size = 16, verbose = 1), axis=1)\n",
        "trn_act = np.argmax(y_train, axis=1)\n",
        "\n",
        "print(\"Accuracy on val dataset is {}\".format(sum(test_act==test_pred)/test_pred.shape[0]))\n",
        "print(\"Accuracy on trn dataset is {}\".format(sum(trn_act==trn_pred)/trn_pred.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "871/871 [==============================] - 0s 137us/step\n",
            "7834/7834 [==============================] - 1s 117us/step\n",
            "Accuracy on val dataset is 0.7669345579793341\n",
            "Accuracy on trn dataset is 0.857161092672964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vvc7MWcyLwue",
        "colab_type": "code",
        "outputId": "8c029b8c-8ea5-48b3-cf6b-d991290f63ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Saving Model\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_v1.0.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_v1.0.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n",
        "# later..."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cj0mhWJ0Qg2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model_v1.0.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_v1.0.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "score = np.argmax(loaded_model.predict(DATASET, batch_size = 16, verbose = 1), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}