{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njainds/Colab_notebooks/blob/master/CCP_ICD10_Searchengine/CNNmodel_v3.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QYpecTXf_H6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Builf train and evaluate\n",
        "# Save model for offline scoring on test\n",
        "# Model name: CCP_ICD10_Searchengine/CNNmodel_v2.0.ipynb\n",
        "# References\n",
        "#https://github.com/njainds/Colab_notebooks/blob/master/Kaggle_Toxic_Comments/Model-2-keras_lstmConv.ipynb\n",
        "#https://github.com/njainds/NLP/blob/master/kaggle/QIQC/22nd%20Place%20Solution%20-%206%20models%20%2B%20POS%20tagging.ipynb\n",
        "#https://github.com/Cheneng/DPCNN/blob/master/model/DPCNN.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AL5rrZqLghp",
        "colab_type": "code",
        "outputId": "9c231835-c66c-42d0-889a-9de52d7caa60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Name of GPU : {}\".format(torch.cuda.get_device_name(0)))\n",
        "print(\"# of GPU : {}\".format(torch.cuda.device_count()))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of GPU : Tesla K80\n",
            "# of GPU : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0zRdXN9yo6k3",
        "colab_type": "code",
        "outputId": "e08fd786-c932-4e21-fca6-d0d007afbd2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "tqdm.pandas(desc='Progress')\n",
        "\n",
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from keras import callbacks\n",
        "\n",
        "# cross validation and metrics\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection,linear_model,metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NhSwmpxVpCSx",
        "colab_type": "code",
        "outputId": "8d117396-c813-4af0-e553-b7615a57f75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "embedding_matrix.npy  mispell_dict.npy\ttest_X.npy  train_X.npy  word_index.npy\n",
            "icd_dict.npy\t      model_data.csv\ttest_y.npy  train_y.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OiHWhcY9SszU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/My Drive/CCP-ICDsearch/desc-icd9-modeldata/\")\n",
        "x_train = np.load(\"train_X.npy\")\n",
        "x_test = np.load(\"test_X.npy\")\n",
        "y_train = np.load(\"train_y.npy\")\n",
        "y_test = np.load(\"test_y.npy\")\n",
        "features = np.load(\"test_y.npy\")\n",
        "icd_dict = np.load(\"icd_dict.npy\").item()\n",
        "word_index = np.load(\"word_index.npy\").item()\n",
        "embeddings = np.load(\"embedding_matrix.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwjoGzOR3m9H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(keras.callbacks.Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "          \n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,save_best_only = True, mode = \"min\")\n",
        "ra_val = RocAucEvaluation(validation_data=(x_test, y_test), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D5xLwVe9Bw91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#configs\n",
        "max_features = embeddings.shape[0]\n",
        "maxlen = x_train.shape[1]\n",
        "embed_size = embeddings.shape[1]\n",
        "n_class = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXiTe8F678Kg",
        "colab_type": "code",
        "outputId": "716bf70b-ba5f-4c54-95d0-78d505788173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "cell_type": "code",
      "source": [
        "#del model\n",
        "inp = Input(shape=(maxlen,))\n",
        "x   = Embedding(max_features, embed_size, weights=[embeddings], trainable=False)(inp)\n",
        "x   = SpatialDropout1D(rate=0.2)(x)\n",
        "x1  = Conv1D(64, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "x2  = Conv1D(64, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "x3  = Conv1D(64, kernel_size=4, padding='valid', kernel_initializer='he_uniform')(x)\n",
        "x1  = GlobalMaxPooling1D()(x1)\n",
        "x2  = GlobalMaxPooling1D()(x2)\n",
        "x3  = GlobalMaxPooling1D()(x3)\n",
        "c   = concatenate([x1,x2,x3])\n",
        "y   = Dense(128, activation='relu')(c)\n",
        "y   = Dropout(0.2)(y)\n",
        "out = Dense(n_class, activation='softmax')(y)\n",
        "model=Model(inputs=inp,outputs=out)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 6, 200)       595400      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 6, 200)       0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 5, 64)        25664       spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 4, 64)        38464       spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 3, 64)        51264       spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 64)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 64)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 192)          0           global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_max_pooling1d_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          24704       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 126)          16254       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 751,750\n",
            "Trainable params: 156,350\n",
            "Non-trainable params: 595,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VaWv1RBN7_ER",
        "colab_type": "code",
        "outputId": "0cdb55e1-15b3-4b41-9566-ad30750ee1c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1193
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size = 48, epochs = 10, validation_data = (x_test, y_test), verbose = 1, callbacks = [ra_val, check_point, early_stop])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 7834 samples, validate on 871 samples\n",
            "Epoch 1/10\n",
            "7834/7834 [==============================] - 3s 392us/step - loss: 3.6092 - acc: 0.2494 - val_loss: 2.2086 - val_acc: 0.5063\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.965584\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.20859, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "7834/7834 [==============================] - 2s 201us/step - loss: 1.9280 - acc: 0.5361 - val_loss: 1.3719 - val_acc: 0.6682\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.985411\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.20859 to 1.37191, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "7834/7834 [==============================] - 2s 199us/step - loss: 1.3763 - acc: 0.6451 - val_loss: 1.1099 - val_acc: 0.7164\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.989623\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.37191 to 1.10993, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "7834/7834 [==============================] - 2s 199us/step - loss: 1.1105 - acc: 0.7099 - val_loss: 1.0104 - val_acc: 0.7509\n",
            "\n",
            " ROC-AUC - epoch: 4 - score: 0.991284\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.10993 to 1.01043, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "7834/7834 [==============================] - 2s 202us/step - loss: 0.9594 - acc: 0.7425 - val_loss: 0.9403 - val_acc: 0.7692\n",
            "\n",
            " ROC-AUC - epoch: 5 - score: 0.991755\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.01043 to 0.94033, saving model to best_model.hdf5\n",
            "Epoch 6/10\n",
            "7834/7834 [==============================] - 2s 198us/step - loss: 0.8582 - acc: 0.7706 - val_loss: 0.9241 - val_acc: 0.7589\n",
            "\n",
            " ROC-AUC - epoch: 6 - score: 0.992319\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.94033 to 0.92413, saving model to best_model.hdf5\n",
            "Epoch 7/10\n",
            "7834/7834 [==============================] - 2s 196us/step - loss: 0.7664 - acc: 0.7944 - val_loss: 0.8657 - val_acc: 0.7910\n",
            "\n",
            " ROC-AUC - epoch: 7 - score: 0.992555\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.92413 to 0.86569, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "7834/7834 [==============================] - 2s 201us/step - loss: 0.7031 - acc: 0.8110 - val_loss: 0.8748 - val_acc: 0.7807\n",
            "\n",
            " ROC-AUC - epoch: 8 - score: 0.993064\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.86569\n",
            "Epoch 9/10\n",
            "7834/7834 [==============================] - 2s 199us/step - loss: 0.6234 - acc: 0.8258 - val_loss: 0.8804 - val_acc: 0.7819\n",
            "\n",
            " ROC-AUC - epoch: 9 - score: 0.992692\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.86569\n",
            "Epoch 10/10\n",
            "7834/7834 [==============================] - 2s 197us/step - loss: 0.5771 - acc: 0.8376 - val_loss: 0.8587 - val_acc: 0.7945\n",
            "\n",
            " ROC-AUC - epoch: 10 - score: 0.992666\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.86569 to 0.85866, saving model to best_model.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b471b6ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "6DLYUM3s8DDo",
        "colab_type": "code",
        "outputId": "48e8aea3-c658-4532-b243-bccf7735798a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "#itoicd = dict((v,k) for k,v in icd_dict.items())\n",
        "test_pred = np.argmax(model.predict(x_test, batch_size = 16, verbose = 1), axis=1)\n",
        "test_act = np.argmax(y_test, axis=1)\n",
        "trn_pred = np.argmax(model.predict(x_train, batch_size = 16, verbose = 1), axis=1)\n",
        "trn_act = np.argmax(y_train, axis=1)\n",
        "\n",
        "print(\"Accuracy on val dataset is {}\".format(sum(test_act==test_pred)/test_pred.shape[0]))\n",
        "print(\"Accuracy on trn dataset is {}\".format(sum(trn_act==trn_pred)/trn_pred.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "871/871 [==============================] - 0s 144us/step\n",
            "7834/7834 [==============================] - 1s 127us/step\n",
            "Accuracy on val dataset is 0.7944890929965557\n",
            "Accuracy on trn dataset is 0.9257084503446515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vvc7MWcyLwue",
        "colab_type": "code",
        "outputId": "2aa35370-75ef-474b-dd70-3bf28829fdc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Saving Model\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model_v2.0.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_v2.0.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n",
        "# later...\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cj0mhWJ0Qg2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model_v2.0.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_v2.0.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])\n",
        "score = np.argmax(loaded_model.predict(DATASET, batch_size = 16, verbose = 1), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}